#!/usr/bin/env python3
"""
å·¥ä½œæµå‘½ä»¤è¡Œå·¥å…·
æä¾›ä¾¿æ·çš„å‘½ä»¤è¡Œæ¥å£æ¥ç®¡ç†å·¥ä½œæµ
"""

import sys
import json
import yaml
import os
from pathlib import Path
from typing import Dict, List, Optional, Any, Set, Callable, Tuple
try:
    # Try importing from the same package
    from .core.engine import (
        WorkflowEngine, 
        WorkflowError, 
        ValidationError, 
        StageStatus,
        ProjectScanner,
        AgentOrchestrator,
        TeamManager,
        RoleExecutor
    )
    from .core.llm_client_loader import LLMClientLoader
    from .core.execution_mode_analyzer import ExecutionModeAnalyzer
    from .core.tool_mapper import ToolMapper
    _agents_available = True
except (ImportError, ValueError):
    # Fallback: try from .engine (forwarding module)
    try:
        from .engine import (
            WorkflowEngine, 
            WorkflowError, 
            ValidationError, 
            StageStatus,
            ProjectScanner,
            AgentOrchestrator,
            TeamManager,
            RoleExecutor
        )
        from .core.llm_client_loader import LLMClientLoader
        from .core.execution_mode_analyzer import ExecutionModeAnalyzer
        from .core.tool_mapper import ToolMapper
        _agents_available = True
    except (ImportError, ValueError):
        # Final fallback: try absolute import from core.engine
        try:
            from work_by_roles.core.engine import (
                WorkflowEngine, 
                WorkflowError, 
                ValidationError, 
                StageStatus,
                ProjectScanner,
                AgentOrchestrator,
                TeamManager,
                RoleExecutor
            )
            try:
                from work_by_roles.core.llm_client_loader import LLMClientLoader
            except ImportError:
                LLMClientLoader = None
            try:
                from work_by_roles.core.execution_mode_analyzer import ExecutionModeAnalyzer
                from work_by_roles.core.tool_mapper import ToolMapper
            except ImportError:
                ExecutionModeAnalyzer = None
                ToolMapper = None
            _agents_available = True
        except (ImportError, ValueError):
            # If all imports fail, set to unavailable
            _agents_available = False
            WorkflowEngine = None
            WorkflowError = Exception
            ValidationError = Exception
            StageStatus = None
            ProjectScanner = None
            AgentOrchestrator = None
            TeamManager = None
            RoleExecutor = None
            LLMClientLoader = None
            ExecutionModeAnalyzer = None
            ToolMapper = None


def print_status(engine: WorkflowEngine):
    """æ‰“å°å·¥ä½œæµçŠ¶æ€"""
    print("\n" + "=" * 60)
    print("å·¥ä½œæµçŠ¶æ€")
    print("=" * 60)
    
    if not engine.workflow or not engine.executor:
        print("å½“å‰é˜¶æ®µ: æ— ")
        print("\nâš ï¸  å·¥ä½œæµæœªåˆå§‹åŒ–æˆ–æœªåŠ è½½æ‰§è¡Œå™¨")
        return
    
    current = engine.get_current_stage()
    if current:
        print(f"å½“å‰é˜¶æ®µ: {current.name} (ID: {current.id})")
        print(f"å½“å‰è§’è‰²: {engine.executor.state.current_role}")
    else:
        print("å½“å‰é˜¶æ®µ: æ— ")
    
    print("\næ‰€æœ‰é˜¶æ®µ:")
    for stage in engine.workflow.stages:
        status = engine.get_stage_status(stage.id)
        status_str = status.value if status else "pending"
        marker = "â†’" if current and current.id == stage.id else " "
        print(f"  {marker} [{status_str:12}] {stage.name} (è§’è‰²: {stage.role})")
    
    if engine.executor:
        completed = engine.executor.get_completed_stages()
        if completed:
            print(f"\nå·²å®Œæˆé˜¶æ®µ: {', '.join(completed)}")


def _init_engine(args) -> Tuple[WorkflowEngine, Path, Path]:
    """Initialize engine with skill library, supporting team context"""
    workspace = Path(args.workspace or ".")
    workflow_dir = workspace / ".workflow"
    workflow_dir.mkdir(exist_ok=True)
    temp_dir = workflow_dir / "temp"
    temp_dir.mkdir(exist_ok=True)
    
    # åˆå§‹åŒ–å›¢é˜Ÿç®¡ç†å™¨
    team_manager = TeamManager(workspace)
    
    # å¦‚æœæŒ‡å®šäº†å›¢é˜Ÿï¼Œä½¿ç”¨å›¢é˜Ÿé…ç½®ï¼›å¦åˆ™ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æˆ–é»˜è®¤é…ç½®
    team_id = getattr(args, 'team', None)
    if team_id:
        # ä½¿ç”¨æŒ‡å®šçš„å›¢é˜Ÿé…ç½®
        team_config = team_manager.get_team_config(team_id)
        skill_file = team_config["skills"]
        roles_file = team_config["roles"]
        workflow_file = team_config["workflow"]
        context_file = team_config["context"]
        state_file = team_config["state"]
    else:
        # æ£€æŸ¥æ˜¯å¦æœ‰å½“å‰æ´»åŠ¨å›¢é˜Ÿ
        current_team = team_manager.get_current_team()
        if current_team and not (args.workflow or args.roles or args.skills):
            # ä½¿ç”¨å½“å‰å›¢é˜Ÿé…ç½®ï¼ˆå¦‚æœæ²¡æœ‰æ˜¾å¼æŒ‡å®šå‘½ä»¤è¡Œå‚æ•°ï¼‰
            team_config = team_manager.get_team_config(current_team)
            skill_file = team_config["skills"]
            roles_file = team_config["roles"]
            workflow_file = team_config["workflow"]
            context_file = team_config["context"]
            state_file = team_config["state"]
        else:
            # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æˆ–é»˜è®¤é…ç½®
            skill_file = Path(args.skills) if args.skills else workflow_dir / "skills"
            roles_file = Path(args.roles) if args.roles else workflow_dir / "role_schema.yaml"
            workflow_file = Path(args.workflow) if args.workflow else workflow_dir / "workflow_schema.yaml"
            context_file = Path(args.context) if args.context else workflow_dir / "project_context.yaml"
            state_file = Path(args.state) if args.state else workflow_dir / "state.yaml"
    
    # Check if auto-restore is disabled
    auto_restore = not getattr(args, 'no_restore_state', False)
    auto_save = not getattr(args, 'no_auto_save', False)

    engine = WorkflowEngine(
        workspace,
        auto_save_state=auto_save,
        state_file=state_file
    )
    
    # Load context if exists
    if context_file.exists():
        engine.load_context(context_file)
        
    if not skill_file.exists():
        raise WorkflowError(f"Skill library not found: {skill_file}")
    engine.load_skill_library(skill_file)
    engine.load_roles(roles_file)
    engine.load_workflow(workflow_file)
    
    # State is now auto-restored in load_workflow if auto_restore is True
    # Manual load_state call is no longer needed, but kept for explicit control
    if not auto_restore and state_file.exists():
        engine.load_state(state_file, auto_restore=False)
        
    return engine, workflow_file, state_file


def _load_llm_client(workspace: Path) -> Optional[Any]:
    """
    Load LLM client from environment variables or configuration file.
    
    Args:
        workspace: Workspace root path
        
    Returns:
        LLM client instance or None if not configured
    """
    loader = LLMClientLoader(workspace)
    return loader.load()


def _get_templates_dir() -> Path:
    """Get templates directory path"""
    # Try from package
    try:
        import work_by_roles
        pkg_path = Path(work_by_roles.__file__).parent
        template_dir = pkg_path / "templates"
        if template_dir.exists():
            return template_dir
    except ImportError:
        pass
    
    # Fallback to local (development mode)
    return Path(__file__).parent / "templates"


def cmd_init(args):
    """Initialize project context with template selection"""
    workspace = Path(args.workspace or ".")
    print(f"ğŸ” æ­£åœ¨åˆå§‹åŒ–é¡¹ç›®: {workspace.absolute()}")

    # Ensure .workflow directory exists and create temp subdirectory
    workflow_dir = workspace / ".workflow"
    workflow_dir.mkdir(exist_ok=True)
    temp_dir = workflow_dir / "temp"
    temp_dir.mkdir(exist_ok=True)

    # 0. æ£€æŸ¥å¿«é€Ÿæ¨¡å¼æˆ–æŒ‡å®šæ¨¡æ¿
    template_name = getattr(args, 'template', None)
    quick_mode = getattr(args, 'quick', False)
    
    # å¿«é€Ÿæ¨¡å¼é»˜è®¤ä½¿ç”¨vibe-codingæ¨¡æ¿
    if quick_mode and not template_name:
        template_name = "vibe-coding"
    
    # 1. ä¼˜å…ˆæ£€æŸ¥ teams/ ç›®å½•ä¸­çš„æ¨¡æ¿ï¼ˆåŒ…æ‹¬vibe-codingï¼‰
    template_applied = False
    
    if template_name:
        # æ£€æŸ¥teamsç›®å½•
        teams_template = workspace / "teams" / template_name
        if teams_template.exists() and teams_template.is_dir():
            print(f"\nâœ… æ£€æµ‹åˆ°å›¢é˜Ÿæ¨¡æ¿: teams/{template_name}/")
            print(f"   ä½¿ç”¨ {template_name} å›¢é˜Ÿé…ç½®")
            
            workflow_file = workflow_dir / "workflow_schema.yaml"
            roles_file = workflow_dir / "role_schema.yaml"
            skills_dir = workflow_dir / "skills"
            
            if not (workflow_file.exists() and roles_file.exists() and skills_dir.exists()):
                import shutil
                for f in teams_template.iterdir():
                    if f.is_file() and f.suffix in ['.yaml', '.yml']:
                        shutil.copy(f, workflow_dir / f.name)
                    elif f.is_dir() and f.name == "skills":
                        # Copy skills directory
                        shutil.copytree(f, skills_dir, dirs_exist_ok=True)
                print(f"âœ… å·²å°† {template_name} é…ç½®å¤åˆ¶åˆ° .workflow/ ç›®å½•")
                template_applied = True
            else:
                print("   âš ï¸  .workflow/ ç›®å½•å·²å­˜åœ¨é…ç½®æ–‡ä»¶ï¼Œè·³è¿‡å¤åˆ¶")
    
    # 1.5. å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡æ¿ï¼Œä¼˜å…ˆæ£€æŸ¥ teams/standard-delivery/ é…ç½®ï¼ˆé¡¹ç›®è§„èŒƒï¼‰
    if not template_applied:
        teams_standard_delivery = workspace / "teams" / "standard-delivery"
        
        if teams_standard_delivery.exists() and teams_standard_delivery.is_dir():
            print("\nâœ… æ£€æµ‹åˆ°é¡¹ç›®æ ‡å‡†é…ç½®: teams/standard-delivery/")
            print("   è‡ªåŠ¨ä½¿ç”¨æ ‡å‡†äº¤ä»˜å›¢é˜Ÿé…ç½®ï¼ˆç¬¦åˆé¡¹ç›®è§„èŒƒï¼‰")
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰é…ç½®æ–‡ä»¶ï¼Œé¿å…è¦†ç›–
            workflow_file = workflow_dir / "workflow_schema.yaml"
            roles_file = workflow_dir / "role_schema.yaml"
            skills_dir = workflow_dir / "skills"
            
            if not (workflow_file.exists() and roles_file.exists() and skills_dir.exists()):
                # å¤åˆ¶é…ç½®æ–‡ä»¶åˆ° .workflow ç›®å½•
                import shutil
                for f in teams_standard_delivery.iterdir():
                    if f.is_file() and f.suffix in ['.yaml', '.yml']:
                        shutil.copy(f, workflow_dir / f.name)
                    elif f.is_dir() and f.name == "skills":
                        # å¤åˆ¶skillsç›®å½•
                        shutil.copytree(f, skills_dir, dirs_exist_ok=True)
                print(f"âœ… å·²å°†æ ‡å‡†é…ç½®å¤åˆ¶åˆ° .workflow/ ç›®å½•")
                template_applied = True
            else:
                print("   âš ï¸  .workflow/ ç›®å½•å·²å­˜åœ¨é…ç½®æ–‡ä»¶ï¼Œè·³è¿‡å¤åˆ¶")
                print("   ğŸ’¡ å¦‚éœ€é‡æ–°åˆå§‹åŒ–ï¼Œè¯·å…ˆåˆ é™¤ç°æœ‰é…ç½®æ–‡ä»¶")
                template_applied = True  # æ ‡è®°ä¸ºå·²åº”ç”¨ï¼Œé¿å…ç»§ç»­æ‰§è¡Œæ¨¡æ¿é€‰æ‹©
    
    # 2. å¦‚æœæ²¡æœ‰ä½¿ç”¨ teams/standard-deliveryï¼Œä½¿ç”¨åŸæ¥çš„æ¨¡æ¿é€‰æ‹©é€»è¾‘
    if not template_applied:
        templates_dir = _get_templates_dir()
        if templates_dir.exists():
            templates = sorted([d for d in templates_dir.iterdir() if d.is_dir()])
            if templates:
                print("\nè¯·é€‰æ‹©å›¢é˜Ÿæ¨¡æ¿:")
                for i, t in enumerate(templates, 1):
                    # Try to get a nicer name from the directory name
                    display_name = t.name.replace("_", " ").title()
                    print(f"  {i}. {display_name} ({t.name})")
                print(f"  {len(templates)+1}. ä»…æ‰«æç»“æ„ (ä¸åº”ç”¨æ¨¡æ¿)")
                
                try:
                    choice = input(f"\né€‰æ‹©ç¼–å· [1-{len(templates)+1}]: ").strip()
                    if choice and choice.isdigit():
                        idx = int(choice) - 1
                        if 0 <= idx < len(templates):
                            selected = templates[idx]
                            print(f"âœ… å·²é€‰æ‹©æ¨¡æ¿: {selected.name}")
                            # Copy files to .workflow directory
                            import shutil
                            for f in selected.iterdir():
                                if f.is_file() and f.suffix in ['.yaml', '.yml', '.md']:
                                    shutil.copy(f, workflow_dir / f.name)
                                elif f.is_dir() and f.name == "skills":
                                    # Copy skills directory
                                    skills_dir = workflow_dir / "skills"
                                    shutil.copytree(f, skills_dir, dirs_exist_ok=True)
                            print(f"âœ… å·²å°†æ¨¡æ¿æ–‡ä»¶å¤åˆ¶åˆ° .workflow/ ç›®å½•")
                            template_applied = True
                except (KeyboardInterrupt, EOFError):
                    print("\nâŒ å·²å–æ¶ˆé€‰æ‹©")
    
    # 2. Project scanning
    print(f"\nğŸ” æ­£åœ¨æ‰«æé¡¹ç›®ç»“æ„...")
    scanner = ProjectScanner(workspace)
    context = scanner.scan()
    
    context_file = workflow_dir / "project_context.yaml"
    
    with open(context_file, 'w', encoding='utf-8') as f:
        yaml.dump(context.to_dict(), f, default_flow_style=False, allow_unicode=True)
        
    print(f"âœ… é¡¹ç›®ä¸Šä¸‹æ–‡å·²ä¿å­˜åˆ°: {context_file}")
    
    # 2.5. Check for spec files and prompt user
    if not context.specs:
        print("\nâš ï¸  æœªæ£€æµ‹åˆ°é¡¹ç›®è§„èŒƒæ–‡ä»¶ (spec files)")
        print("   è§„èŒƒæ–‡ä»¶æœ‰åŠ©äºå·¥ä½œæµæ›´å¥½åœ°ç†è§£é¡¹ç›®éœ€æ±‚")
        try:
            generate_spec = input("æ˜¯å¦ç”Ÿæˆåˆå§‹è§„èŒƒæ–‡ä»¶æ¨¡æ¿? [y/N]: ").strip().lower()
            if generate_spec in ['y', 'yes']:
                _generate_spec_template(workspace)
        except (KeyboardInterrupt, EOFError):
            print("\nè·³è¿‡è§„èŒƒæ–‡ä»¶ç”Ÿæˆ")
    else:
        print(f"\nâœ… æ£€æµ‹åˆ° {len(context.specs)} ä¸ªè§„èŒƒæ–‡ä»¶:")
        for spec_name, spec_path in list(context.specs.items())[:5]:  # Show first 5
            print(f"   - {spec_name}: {spec_path}")
        if len(context.specs) > 5:
            print(f"   ... è¿˜æœ‰ {len(context.specs) - 5} ä¸ª")
    
    # 3. Generate .cursorrules (only in Cursor IDE, merges autopilot.md content)
    if generate_cursorrules(workspace):
        print(f"âœ… å·²ç”Ÿæˆ/æ›´æ–° .cursorrules æ–‡ä»¶ï¼Œå¢å¼º AI è§’è‰²æ„ŸçŸ¥ï¼ˆåŒ…å«è‡ªåŠ¨æ‰§è¡Œè§„åˆ™ï¼‰")
    else:
        print(f"â„¹ï¸  æœªæ£€æµ‹åˆ° Cursor IDE ç¯å¢ƒï¼Œè·³è¿‡ .cursorrules ç”Ÿæˆ")
    
    # 4. Generate initial TEAM_CONTEXT.md if workflow files exist
    workflow_file = workflow_dir / "workflow_schema.yaml"
    roles_file = workflow_dir / "role_schema.yaml"
    skills_dir = workflow_dir / "skills"
    state_file = workflow_dir / "state.yaml"
    
    if workflow_file.exists() and roles_file.exists():
        try:
            # Initialize engine to generate TEAM_CONTEXT.md
            engine = WorkflowEngine(
                workspace_path=workspace,
                auto_save_state=True  # Enable auto-save to create initial state
            )
            # Try to load workflow if files exist
            try:
                # Load skill library if exists
                if skills_dir.exists() and skills_dir.is_dir():
                    engine.load_skill_library(skills_dir)
                else:
                    print("âš ï¸  æœªæ‰¾åˆ° skills ç›®å½•ï¼Œè·³è¿‡æŠ€èƒ½åº“åŠ è½½")
                
                engine.load_roles(roles_file)
                engine.load_workflow(workflow_file)
                
                # Ensure executor is created (should be created by load_workflow)
                if not engine.executor:
                    raise WorkflowError("Failed to create workflow executor")
                
                # Always create/update state file after loading workflow
                # This ensures workflow is "initialized" even without an active stage
                # Note: load_workflow may have called load_state, but it won't create file if it doesn't exist
                # So we explicitly save state here to ensure the file exists
                try:
                    engine.save_state(state_file)
                    if state_file.exists():
                        print(f"âœ… å·²åˆ›å»º/æ›´æ–°å·¥ä½œæµçŠ¶æ€æ–‡ä»¶: {state_file}")
                    else:
                        print(f"âš ï¸  è­¦å‘Š: çŠ¶æ€æ–‡ä»¶åˆ›å»ºå¯èƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™: {state_file}")
                except Exception as e:
                    print(f"âš ï¸  è­¦å‘Š: ä¿å­˜çŠ¶æ€æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                
                # Auto-start first stage if no active stage exists
                # This ensures workflow is truly "initialized" and ready to use
                if engine.workflow and engine.workflow.stages:
                    current_stage = engine.get_current_stage()
                    
                    if not current_stage:
                        # Find first stage (lowest order)
                        first_stage = min(engine.workflow.stages, key=lambda s: s.order)
                        
                        # Check if we can start the first stage
                        can_transition, errors = engine.executor.can_transition_to(first_stage.id)
                        if can_transition:
                            try:
                                engine.start_stage(first_stage.id, first_stage.role)
                                engine.save_state(state_file)  # Save state after starting stage
                                print(f"âœ… å·²è‡ªåŠ¨å¯åŠ¨ç¬¬ä¸€ä¸ªé˜¶æ®µ: {first_stage.name} ({first_stage.id})")
                                print(f"   è§’è‰²: {first_stage.role}")
                            except Exception as e:
                                print(f"âš ï¸  è­¦å‘Š: è‡ªåŠ¨å¯åŠ¨ç¬¬ä¸€ä¸ªé˜¶æ®µå¤±è´¥: {e}")
                                print(f"   è¯·æ‰‹åŠ¨è¿è¡Œ: workflow start {first_stage.id}")
                        else:
                            # First stage has prerequisites that aren't met (unusual but possible)
                            print(f"ğŸ’¡ æç¤º: ç¬¬ä¸€ä¸ªé˜¶æ®µ '{first_stage.name}' éœ€è¦æ»¡è¶³å‰ç½®æ¡ä»¶:")
                            for error in errors:
                                print(f"   - {error}")
                            print(f"   è¯·æ‰‹åŠ¨è¿è¡Œ: workflow start {first_stage.id}")
                    else:
                        # Already has an active stage
                        print(f"âœ… å½“å‰æ´»åŠ¨é˜¶æ®µ: {current_stage.name} ({current_stage.id})")
                
                # Generate initial TEAM_CONTEXT.md (if not already generated by load_workflow)
                # load_workflow may have called update_vibe_context if auto_save_state=True,
                # but we call it again to ensure it's up-to-date
                context_file = engine.update_vibe_context()
                generate_cursorrules(engine.workspace_path, engine)
                print(f"âœ… å·²ç”Ÿæˆåˆå§‹å›¢é˜Ÿä¸Šä¸‹æ–‡: {context_file}")
                
                # Show summary
                current_stage = engine.get_current_stage()
                if current_stage:
                    print(f"\nâœ… åˆå§‹åŒ–å®Œæˆï¼å½“å‰æ´»åŠ¨é˜¶æ®µ: {current_stage.name} ({current_stage.id})")
                elif engine.workflow and engine.workflow.stages:
                    first_stage = min(engine.workflow.stages, key=lambda s: s.order)
                    print(f"\nâœ… åˆå§‹åŒ–å®Œæˆï¼ä¸‹ä¸€æ­¥: è¿è¡Œ 'workflow start {first_stage.id}' å¯åŠ¨ç¬¬ä¸€ä¸ªé˜¶æ®µ")
            except Exception as e:
                # If workflow files exist but can't be loaded, create a minimal TEAM_CONTEXT.md
                team_context_file = workspace / ".workflow" / "TEAM_CONTEXT.md"
                minimal_content = """# Team Context - Current Workflow State

**Generated**: {timestamp}

## Current Active Stage

- **Status**: No active stage

**Action Required**: Run `workflow start <stage> <role>` to begin.

## Workflow Overview

Workflow files detected but not yet initialized. Please run:
```bash
workflow start <stage> <role>
```

---
*This file is auto-generated. Do not edit manually.*
""".format(timestamp=__import__('datetime').datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                team_context_file.write_text(minimal_content, encoding='utf-8')
                print(f"âœ… å·²ç”Ÿæˆåˆå§‹å›¢é˜Ÿä¸Šä¸‹æ–‡: {team_context_file}")
                print(f"âš ï¸  å·¥ä½œæµåŠ è½½å¤±è´¥: {e}")
        except Exception as e:
            # If engine initialization fails, create a minimal TEAM_CONTEXT.md
            team_context_file = workspace / ".workflow" / "TEAM_CONTEXT.md"
            minimal_content = """# Team Context - Current Workflow State

**Generated**: {timestamp}

## Current Active Stage

- **Status**: No active stage

**Action Required**: Run `workflow start <stage> <role>` to begin.

---
*This file is auto-generated. Do not edit manually.*
""".format(timestamp=__import__('datetime').datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            team_context_file.write_text(minimal_content, encoding='utf-8')
            print(f"âœ… å·²ç”Ÿæˆåˆå§‹å›¢é˜Ÿä¸Šä¸‹æ–‡: {team_context_file}")
            print(f"âš ï¸  å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
    else:
        # Create minimal TEAM_CONTEXT.md even if workflow files don't exist
        team_context_file = workspace / ".workflow" / "TEAM_CONTEXT.md"
        minimal_content = """# Team Context - Current Workflow State

**Generated**: {timestamp}

## Current Active Stage

- **Status**: No active stage

**Action Required**: 
1. Ensure `.workflow/workflow_schema.yaml` and `.workflow/role_schema.yaml` exist
2. Run `workflow start <stage> <role>` to begin

---
*This file is auto-generated. Do not edit manually.*
""".format(timestamp=__import__('datetime').datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        team_context_file.write_text(minimal_content, encoding='utf-8')
        print(f"âœ… å·²ç”Ÿæˆåˆå§‹å›¢é˜Ÿä¸Šä¸‹æ–‡: {team_context_file}")


def _prompt_skill_accumulation(engine: WorkflowEngine, workspace: Path):
    """
    æç¤ºç”¨æˆ·è¿›è¡ŒæŠ€èƒ½æ²‰æ·€ï¼ˆSkill Accumulationï¼‰
    
    åœ¨å·¥ä½œæµæ‰€æœ‰é˜¶æ®µå®Œæˆåï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦è¦å°†æœ¬æ¬¡å®ç°çš„èƒ½åŠ›æ²‰æ·€ä¸ºæŠ€èƒ½
    """
    try:
        print("\nğŸ’¡ æŠ€èƒ½æ²‰æ·€ï¼ˆSkill Accumulationï¼‰")
        print("   æœ¬æ¬¡å·¥ä½œæµå·²å®Œæˆï¼Œæ‚¨å¯ä»¥å°†å®ç°çš„èƒ½åŠ›æ²‰æ·€ä¸ºæŠ€èƒ½ï¼Œä¾›åç»­å¤ç”¨ã€‚")
        
        response = input("\næ˜¯å¦è¦å°†æœ¬æ¬¡èƒ½åŠ›æ²‰æ·€ä¸ºæŠ€èƒ½? [y/N]: ").strip().lower()
        if response not in ['y', 'yes']:
            print("   å·²è·³è¿‡æŠ€èƒ½æ²‰æ·€")
            return
        
        # Ask for skills directory path
        default_skills_dir = workspace / ".workflow" / "skills"
        skills_dir_input = input(f"\næŠ€èƒ½ç›®å½•è·¯å¾„ [é»˜è®¤: {default_skills_dir}]: ").strip()
        
        if skills_dir_input:
            skills_dir = Path(skills_dir_input)
        else:
            skills_dir = default_skills_dir
        
        # Ensure directory exists
        skills_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ“‚ æŠ€èƒ½ç›®å½•: {skills_dir}")
        print("   æ­£åœ¨åˆ†æç°æœ‰æŠ€èƒ½å’Œæœ¬æ¬¡å®ç°...")
        
        # Analyze existing skills
        existing_skills = {}
        if skills_dir.exists():
            for skill_file in skills_dir.glob("*.yaml"):
                try:
                    with open(skill_file, 'r', encoding='utf-8') as f:
                        skill_data = yaml.safe_load(f)
                        if skill_data and 'id' in skill_data:
                            existing_skills[skill_data['id']] = {
                                'file': skill_file,
                                'data': skill_data
                            }
                except Exception as e:
                    print(f"   âš ï¸  æ— æ³•è¯»å–æŠ€èƒ½æ–‡ä»¶ {skill_file}: {e}")
        
        print(f"   âœ… å‘ç° {len(existing_skills)} ä¸ªç°æœ‰æŠ€èƒ½")
        
        # Analyze project outputs to suggest skill
        # This is a simplified version - in practice, you might want to analyze:
        # - Generated files
        # - Implemented features
        # - Used tools and patterns
        
        # Get completed stages info
        completed_stages = []
        if engine.executor and engine.workflow:
            for stage_id in engine.executor.get_completed_stages():
                stage = engine.executor._get_stage_by_id(stage_id)
                if stage:
                    completed_stages.append({
                        'id': stage.id,
                        'name': stage.name,
                        'role': stage.role
                    })
        
        print(f"\nğŸ“‹ æœ¬æ¬¡å®Œæˆçš„å·¥ä½œæµé˜¶æ®µ:")
        for stage_info in completed_stages:
            print(f"   - {stage_info['name']} ({stage_info['id']}) - è§’è‰²: {stage_info['role']}")
        
        # Prompt for skill details
        print("\nğŸ“ è¯·è¾“å…¥æŠ€èƒ½ä¿¡æ¯:")
        skill_id = input("   æŠ€èƒ½ ID (å¦‚: user_auth_implementation): ").strip()
        if not skill_id:
            print("   âš ï¸  æŠ€èƒ½ ID ä¸èƒ½ä¸ºç©ºï¼Œå·²å–æ¶ˆ")
            return
        
        skill_name = input("   æŠ€èƒ½åç§° (å¦‚: User Authentication Implementation): ").strip() or skill_id.replace("_", " ").title()
        skill_description = input("   æŠ€èƒ½æè¿°: ").strip() or f"Implementation skill for {skill_name}"
        
        # Check for duplicates
        if skill_id in existing_skills:
            print(f"\nâš ï¸  æŠ€èƒ½ '{skill_id}' å·²å­˜åœ¨")
            update = input("   æ˜¯å¦æ›´æ–°ç°æœ‰æŠ€èƒ½? [y/N]: ").strip().lower()
            if update not in ['y', 'yes']:
                print("   å·²å–æ¶ˆ")
                return
        
        # Generate skill YAML
        skill_data = {
            'id': skill_id,
            'name': skill_name,
            'description': skill_description,
            'dimensions': ['implementation', 'quality', 'testing'],
            'tools': ['python', 'pytest', 'ruff', 'mypy'],
            'levels': {
                1: {
                    'name': 'Basic',
                    'description': 'Basic implementation with minimal testing'
                },
                2: {
                    'name': 'Intermediate',
                    'description': 'Well-structured implementation with comprehensive tests'
                },
                3: {
                    'name': 'Advanced',
                    'description': 'Production-ready implementation with full test coverage and documentation'
                }
            },
            'constraints': [
                'must_use_type_hints',
                'must_cover_tests',
                'must_pass_linter'
            ],
            'metadata': {
                'created_from_workflow': True,
                'workflow_id': engine.workflow.id if engine.workflow else None,
                'completed_stages': [s['id'] for s in completed_stages],
                'created_at': __import__('datetime').datetime.now().isoformat()
            }
        }
        
        # Save skill file
        skill_file = skills_dir / f"{skill_id}_skill.yaml"
        with open(skill_file, 'w', encoding='utf-8') as f:
            yaml.dump(skill_data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        print(f"\nâœ… æŠ€èƒ½å·²ä¿å­˜åˆ°: {skill_file}")
        print(f"   ID: {skill_id}")
        print(f"   åç§°: {skill_name}")
        print(f"\nğŸ’¡ æç¤º: æ‚¨å¯ä»¥åœ¨ role_schema.yaml ä¸­å¼•ç”¨æ­¤æŠ€èƒ½")
        
    except KeyboardInterrupt:
        print("\n\n   å·²å–æ¶ˆæŠ€èƒ½æ²‰æ·€")
    except Exception as e:
        print(f"\nâš ï¸  æŠ€èƒ½æ²‰æ·€è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def _generate_spec_template(workspace: Path):
    """Generate a basic spec template file"""
    workflow_dir = workspace / ".workflow"
    workflow_dir.mkdir(exist_ok=True)
    temp_dir = workflow_dir / "temp"
    temp_dir.mkdir(exist_ok=True)
    
    spec_template = """# Project Specification

## Overview
Describe your project's purpose and goals here.

## Requirements

### Functional Requirements
- [ ] Requirement 1
- [ ] Requirement 2

### Non-Functional Requirements
- Performance: ...
- Security: ...
- Scalability: ...

## API Specification
(If applicable, describe your API endpoints here)

## Architecture
(Describe system architecture and components)

## Success Criteria
- [ ] Criterion 1
- [ ] Criterion 2

## Notes
Add any additional notes or constraints here.
"""
    
    spec_file = workflow_dir / "project.spec.md"
    spec_file.write_text(spec_template, encoding='utf-8')
    print(f"âœ… å·²ç”Ÿæˆè§„èŒƒæ–‡ä»¶æ¨¡æ¿: {spec_file}")
    print("   è¯·ç¼–è¾‘æ­¤æ–‡ä»¶ä»¥æè¿°æ‚¨çš„é¡¹ç›®éœ€æ±‚")


def is_cursor_ide() -> bool:
    """
    æ£€æµ‹æ˜¯å¦åœ¨ Cursor IDE ç¯å¢ƒä¸­
    
    Returns:
        bool: å¦‚æœåœ¨ Cursor IDE ä¸­è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
    """
    # æ–¹æ³•1: æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼ˆCursor å¯èƒ½ä¼šè®¾ç½®ï¼‰
    if os.environ.get('CURSOR_APP') or os.environ.get('CURSOR'):
        return True
    
    # æ–¹æ³•2: æ£€æŸ¥çˆ¶è¿›ç¨‹åç§°ï¼ˆå¦‚æœå¯èƒ½ï¼‰
    try:
        import psutil
        current_process = psutil.Process()
        parent = current_process.parent()
        if parent:
            parent_name = parent.name().lower()
            if 'cursor' in parent_name:
                return True
    except ImportError:
        # psutil æœªå®‰è£…ï¼Œå¿½ç•¥
        pass
    except (AttributeError, psutil.NoSuchProcess, psutil.AccessDenied):
        # psutil å¯ç”¨ä½†æ— æ³•è®¿é—®çˆ¶è¿›ç¨‹ï¼Œå¿½ç•¥
        pass
    
    # æ–¹æ³•3: æ£€æŸ¥æ˜¯å¦åœ¨ Cursor çš„ç»ˆç«¯ä¸­ï¼ˆé€šè¿‡ TERM_PROGRAM ç­‰ç¯å¢ƒå˜é‡ï¼‰
    term_program = os.environ.get('TERM_PROGRAM', '').lower()
    if 'cursor' in term_program:
        return True
    
    return False


def generate_cursorrules(workspace: Path, engine=None):
    """Generate .cursorrules file for AI awareness with dynamic context support
    
    Only generates if running in Cursor IDE environment.
    Merges autopilot.md content into .cursorrules to avoid duplication.
    """
    # æ£€æŸ¥æ˜¯å¦åœ¨ Cursor IDE ç¯å¢ƒä¸­
    if not is_cursor_ide():
        return False
    
    # æ£€æŸ¥å½“å‰å›¢é˜Ÿ
    team_manager = TeamManager(workspace)
    current_team = team_manager.get_current_team()
    team_context = ""
    
    if current_team:
        try:
            team_config = team_manager.get_team_config(current_team)
            team_info = team_manager.teams[current_team]
            team_dir = team_config['workflow'].parent
            team_context = f"""
# CURRENT_TEAM: {current_team}
# Team Name: {team_info.get('name', current_team)}
# Team Directory: {team_dir}
"""
        except Exception:
            # å¦‚æœè·å–å›¢é˜Ÿé…ç½®å¤±è´¥ï¼Œå¿½ç•¥å›¢é˜Ÿä¸Šä¸‹æ–‡
            pass
    
    # è·å–å¯ç”¨è§’è‰²åˆ—è¡¨å’Œæ‰§è¡Œæ¨¡å¼ï¼ˆä»æŠ€èƒ½å®šä¹‰ä¸­è¯»å–ï¼‰
    roles_list = ""
    role_execution_modes = {}  # role_id -> execution_mode info
    
    try:
        if engine and engine.role_manager and engine.role_manager.roles:
            roles = list(engine.role_manager.roles.keys())
            roles_list = f"\nAvailable roles (use @role_name to invoke): {', '.join(roles)}"
            
            # ä½¿ç”¨ ExecutionModeAnalyzer åˆ†æè§’è‰²æ‰§è¡Œæ¨¡å¼
            for role_id, role in engine.role_manager.roles.items():
                if engine.role_manager.skill_library:
                    mode_info = ExecutionModeAnalyzer.get_execution_mode_info(
                        role=role,
                        skill_library=engine.role_manager.skill_library,
                        environment="cursor"
                    )
                    role_execution_modes[role_id] = {
                        'mode': mode_info['mode'],
                        'tools': mode_info['tools'] if mode_info['tools'] else None,
                        'generic_tools': mode_info['generic_tools'] if mode_info['generic_tools'] else None,
                        'capabilities': mode_info['capabilities'] if mode_info['capabilities'] else None
                    }
        else:
            # å°è¯•ä»é…ç½®æ–‡ä»¶è¯»å–
            roles_file = workspace / ".workflow" / "role_schema.yaml"
            if not roles_file.exists():
                roles_file = workspace / "teams" / "standard-delivery" / "role_schema.yaml"
            if roles_file.exists():
                import yaml
                with open(roles_file, 'r', encoding='utf-8') as f:
                    roles_data = yaml.safe_load(f)
                    if roles_data and 'roles' in roles_data:
                        roles = [r.get('id', '') for r in roles_data['roles'] if r.get('id')]
                        roles_list = f"\nAvailable roles (use @role_name to invoke): {', '.join(roles)}"
    except Exception as e:
        # å¦‚æœå‡ºé”™ï¼Œä½¿ç”¨é»˜è®¤å€¼
        pass
    
    # æ ¹æ®æŠ€èƒ½å®šä¹‰ç”Ÿæˆè§’è‰²æ‰§è¡Œè§„åˆ™
    role_execution_rules = ""
    if role_execution_modes:
        role_execution_rules = "\n1. **Role Invocation via @mention**:\n"
        role_execution_rules += "   - When user types `@role_name`, you MUST:\n"
        role_execution_rules += "     a. Load the role configuration from `.workflow/role_schema.yaml`\n"
        role_execution_rules += "     b. Identify the role's `required_skills` from skill definitions\n"
        role_execution_rules += "     c. **Execution mode is determined by skills' `execution_mode` metadata** (generic, not Cursor-specific):\n\n"
        
        # æŒ‰æ‰§è¡Œæ¨¡å¼åˆ†ç»„è§’è‰²
        mode_groups = {}
        for role_id, mode_info in role_execution_modes.items():
            mode = mode_info['mode']
            if mode not in mode_groups:
                mode_groups[mode] = []
            mode_groups[mode].append((role_id, mode_info))
        
        # ç”Ÿæˆæ¯ä¸ªæ¨¡å¼çš„è§„åˆ™
        for mode, roles in mode_groups.items():
            if mode == 'analysis':
                role_execution_rules += f"   **Analysis Mode** (skills define: `execution_mode: analysis`):\n"
                role_execution_rules += f"   - Roles: {', '.join([r[0] for r in roles])}\n"
                role_execution_rules += "   - These roles focus on analysis, design, and documentation\n"
                role_execution_rules += "   - Use `workflow role-execute <role_id> \"<requirement>\" --use-llm` to execute\n"
                role_execution_rules += "   - Skills define capabilities like: write_documentation, create_requirements_doc, write_architecture_doc\n"
                role_execution_rules += "   - Example: `@product_analyst åˆ†æç”¨æˆ·éœ€æ±‚` â†’ Execute `workflow role-execute product_analyst \"åˆ†æç”¨æˆ·éœ€æ±‚\" --use-llm`\n\n"
            
            elif mode == 'implementation':
                role_execution_rules += f"   **Implementation Mode** (skills define: `execution_mode: implementation`):\n"
                role_execution_rules += f"   - Roles: {', '.join([r[0] for r in roles])}\n"
                role_execution_rules += "   - **CRITICAL: These roles MUST directly execute code operations, NOT just analysis**\n"
                role_execution_rules += "   - When mentioned, you MUST:\n"
                role_execution_rules += "     1. Understand the requirement\n"
                role_execution_rules += "     2. **Directly use Cursor's tools** (mapped from skills' generic `execution_tools`):\n"
                
                # æ”¶é›†æ‰€æœ‰å®ç°è§’è‰²çš„å·¥å…·
                all_tools = set()
                all_capabilities = []
                for role_id, mode_info in roles:
                    if mode_info.get('tools'):
                        all_tools.update(mode_info['tools'])
                    if mode_info.get('capabilities'):
                        all_capabilities.extend(mode_info['capabilities'])
                
                if all_tools:
                    role_execution_rules += f"        - Available tools: {', '.join(sorted(all_tools))}\n"
                if all_capabilities:
                    role_execution_rules += f"     3. Use capabilities defined in skills: {', '.join(set(all_capabilities))}\n"
                
                role_execution_rules += "     4. **Actually implement** - create/modify files, write code, write tests\n"
                role_execution_rules += "     5. Do NOT just call `workflow role-execute` and return analysis - you must ACTUALLY WRITE CODE\n"
                role_execution_rules += "   - Example: `@core_framework_engineer å®ç°ç”¨æˆ·è®¤è¯æ¨¡å—` â†’ \n"
                role_execution_rules += "     * Read requirements/architecture docs\n"
                role_execution_rules += "     * Use `write` to create Python files in appropriate directories\n"
                role_execution_rules += "     * Use `search_replace` to modify existing code\n"
                role_execution_rules += "     * Write tests using defined test tools\n\n"
            
            elif mode == 'validation':
                role_execution_rules += f"   **Validation Mode** (skills define: `execution_mode: validation`):\n"
                role_execution_rules += f"   - Roles: {', '.join([r[0] for r in roles])}\n"
                role_execution_rules += "   - These roles focus on testing, validation, and quality assurance\n"
                role_execution_rules += "   - Use tools defined in skills' `execution_tools` (mapped to Cursor tools) to run tests and validate functionality\n"
                
                all_tools = set()
                all_capabilities = []
                for role_id, mode_info in roles:
                    if mode_info.get('tools'):
                        all_tools.update(mode_info['tools'])
                    if mode_info.get('capabilities'):
                        all_capabilities.extend(mode_info['capabilities'])
                
                if all_tools:
                    role_execution_rules += f"   - Available tools: {', '.join(sorted(all_tools))}\n"
                if all_capabilities:
                    role_execution_rules += f"   - Capabilities: {', '.join(set(all_capabilities))}\n"
                role_execution_rules += "\n"
        
        role_execution_rules += "   **Note**: Execution mode is automatically determined from skill metadata. Tools are automatically mapped to Cursor-specific tools.\n"
    else:
        # å›é€€åˆ°é»˜è®¤è§„åˆ™
        role_execution_rules = "\n1. **Role Invocation via @mention**:\n"
        role_execution_rules += "   - Load role configuration and identify required skills\n"
        role_execution_rules += "   - Check skill definitions for `cursor_execution_mode` and `cursor_tools` metadata\n"
        role_execution_rules += "   - Execute according to skill-defined execution mode\n"
    
    # Static base rules
    static_rules = f"""# Multi-Role Workflow Rules
{team_context}
You are operating within a structured Multi-Role Skills Workflow. 
To ensure project stability and follow best practices, adhere to these rules:

## ğŸ­ Role-Based Execution (Cursor IDE Integration)

**CRITICAL: When user mentions @role_name, automatically use that role's skills**

{role_execution_rules}

2. **Team Workflow via @team**:
   - When user mentions `@team` or `@[team]`, immediately execute `workflow wfauto` to run the complete workflow
   - This triggers all stages sequentially: requirements â†’ architecture â†’ implementation â†’ validation
   - Example: `@team å®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½` â†’ Execute `workflow wfauto --intent "å®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½"`

{roles_list}

## ğŸ“‹ Core Rules

1. **Role Awareness**: Before making changes, check the workflow state file to identify the current active stage and role.
2. **Constraint Enforcement**: Respect the `allowed_actions` and `forbidden_actions` defined in the role schema for the current role.
3. **Stage Boundaries**: 
   - Do not skip stages.
   - Do not perform implementation tasks while in the `requirements` or `architecture` stages.
   - If the current stage does not match the task, advise the user to run `workflow start <stage> <role>`.
4. **Quality Gates**: Ensure all quality gates and required outputs defined in the workflow schema are satisfied before attempting to complete a stage.
5. **Skill-Based Execution**:
   - Execution mode is automatically determined from skill metadata
   - **Analysis skills**: Use `workflow role-execute` for analysis and documentation
   - **Implementation skills**: Directly use Cursor tools to write/modify code files (do NOT just call commands)
   - **Validation skills**: Use tools to run tests and validate functionality
7. **Agent Execution**:
   - For automated execution, use `workflow agent-execute [stage]`.
   - When acting as an agent, follow the `instruction_template` in the role definition and the `goal_template` in the stage definition.
7. **Team Context & Auto Workflow Execution**: 
   - **CRITICAL: Fully Automated Execution**:
     - **Every @[team] mention**: When user mentions `@[team]` or `@team`, **immediately execute** `workflow wfauto` to run the complete workflow with Agent + Skills automation. This is the default behavior - no explicit request needed.
     - **Fully Automated**: Execute the complete workflow automatically without asking for confirmation at each step. Only pause if critical issues arise (e.g., API keys, environment configuration, external dependencies).
     - **No User Intervention**: The workflow runs end-to-end automatically, similar to Lovable/MetaGPT. Do not ask "Should I proceed?" or "Is this okay?" - just execute.
   - When user mentions `@[team]`, `@team`, or asks about "team workflow", **immediately read** the TEAM_CONTEXT.md file (if exists).
   - Current team configuration is loaded from the active team context.
   - The `workflow wfauto` command automatically:
     - Uses AgentOrchestrator for multi-agent collaboration
     - Automatically selects and executes relevant skills for each stage
     - Runs skill workflows with auto-trigger
     - Uses relaxed quality gates (won't block on failures)
     - Completes all stages without user intervention (except for critical issues)

## ğŸš€ Autonomous Workflow Pilot (Autopilot Mode)

You are the **Workflow Pilot**. Your mission is to execute user requests end-to-end while adhering to the Multi-Role Skills Workflow framework.

### Intent Recognition & Auto-Trigger
- **Default Behavior**: When the user uses the slash command `/wfauto [goal]` or expresses a desire for you to "just do it" or "handle the whole process", immediately transition into **Autopilot Mode**.
- **CRITICAL**: When the user mentions `@[team]` or `@team`, **immediately execute** `workflow wfauto` - this is the default behavior, no explicit request needed.
- **Every conversation**: When the user expresses any task, goal, or starts a conversation, automatically execute the full workflow to analyze requirements through all stages.

### Autopilot Execution Protocol
Follow this exact sequence without asking for permission for each step:

**Note**: When triggered via `@[team]` or any user conversation, **always execute** `workflow wfauto` to run all stages sequentially. This automatically uses **Agent + Skills** for fully automated execution (similar to Lovable/MetaGPT).

**CRITICAL**: The `workflow wfauto` command automatically:
- Uses AgentOrchestrator for multi-agent collaboration
- Automatically selects and executes relevant skills
- Runs skill workflows with auto-trigger
- Uses relaxed quality gates (won't block on failures)

1. **Preparation**: If the `.workflow/` directory or state file doesn't exist, run `workflow init --quick` (uses vibe-coding template by default).
2. **Automatic Execution**: Run `workflow wfauto` - this will automatically:
   - Execute all stages sequentially using Agent + Skills
   - For each stage:
     - Create Agent for the stage role
     - Automatically select relevant skills based on stage goal
     - Execute selected skills
     - Complete stage with relaxed quality gates
   - No manual intervention needed - fully automated like Lovable/MetaGPT
3. **Self-Healing**: If any stage fails, the system will:
   - Show warnings but continue (relaxed mode)
   - Retry failed skills if configured
   - Fall back to traditional mode if Agent system unavailable
4. **Skill Accumulation Phase (Optional)**:
   - After the project is successfully validated, skill accumulation is **optional and non-blocking**.
   - In automated mode (Agent + Skills), skill accumulation is skipped automatically.
   - Users can manually run `workflow skill-accumulate` if they want to persist capabilities as skills.

### Communication Guidelines
- **Silent Mode**: Do not ask "Should I move to the next stage?" or "Is this requirement okay?". Just proceed.
- **Fully Automated**: When triggered via `@team`, execute the complete workflow automatically without asking for confirmation at each step.
- **Progress Updates**: Provide brief, one-line updates after completing each major stage (e.g., "âœ… Requirements finalized. Moving to Architecture...").
- **Exception Awakening**: ONLY stop and ask the user if:
  - You are stuck in a self-healing loop for more than 3 attempts.
  - There is a critical contradiction in the requirements.
  - **Critical external dependencies**: API keys, environment-specific credentials, or other external resources that cannot be automatically configured.

### Constraint Awareness
- Always respect the `allowed_actions` and `forbidden_actions` in `.workflow/role_schema.yaml`.
- Use the tools provided in the environment (Python, Ruff, Pytest, etc.) to verify your work.

**Start your execution now by running the first necessary command.**
"""
    
    # Dynamic context anchor
    current_stage_id = "None"
    current_role_id = "None"
    
    if engine and engine.executor and engine.executor.state:
        current_stage = engine.get_current_stage()
        if current_stage:
            current_stage_id = current_stage.id
        current_role_id = engine.executor.state.current_role or "None"
        
    dynamic_anchor = f"\n# DYNAMIC_CONTEXT_ANCHOR\nCURRENT_STAGE: {current_stage_id}\nCURRENT_ROLE: {current_role_id}\n"
    
    footer = """
Current project status can be viewed at any time by running `workflow status`.
"""
    
    content = static_rules + dynamic_anchor + footer
    cursorrules_path = workspace / ".cursorrules"
    cursorrules_path.write_text(content, encoding='utf-8')
    return True


def cmd_start(args):
    """å¯åŠ¨é˜¶æ®µ"""
    try:
        engine, workflow_file, state_file = _init_engine(args)
        
        # Smart inference: if stage not provided, show status and available options
        stage_id = args.stage
        role_id = args.role_alt or args.role  # Support --as flag
        
        if not stage_id:
            # Show current status and available stages/roles instead of auto-starting
            print("\n" + "=" * 60)
            print("å·¥ä½œæµçŠ¶æ€ä¸å¯ç”¨é€‰é¡¹")
            print("=" * 60)
            
            # Show current status
            current = engine.get_current_stage()
            if current:
                print(f"\nå½“å‰æ´»åŠ¨é˜¶æ®µ: {current.name} (ID: {current.id})")
                print(f"å½“å‰è§’è‰²: {engine.executor.state.current_role if engine.executor else 'None'}")
                print(f"\nâš ï¸  å·²æœ‰æ´»åŠ¨é˜¶æ®µï¼Œè¯·å…ˆå®Œæˆå½“å‰é˜¶æ®µ:")
                print(f"   workflow complete {current.id}")
                print(f"\næˆ–æŸ¥çœ‹çŠ¶æ€:")
                print(f"   workflow status")
                sys.exit(0)
            else:
                print("\nå½“å‰é˜¶æ®µ: æ— æ´»åŠ¨é˜¶æ®µ")
            
            # Show available stages
            print("\nå¯ç”¨é˜¶æ®µ:")
            print("-" * 60)
            completed = engine.executor.get_completed_stages() if engine.executor else set()
            
            for stage in sorted(engine.workflow.stages, key=lambda s: s.order):
                status = engine.get_stage_status(stage.id) if engine.executor else None
                status_icon = "âœ…" if stage.id in completed else ("ğŸ”„" if status == StageStatus.IN_PROGRESS else "â³")
                
                # Check if can transition
                can_start = False
                if engine.executor:
                    can_transition, errors = engine.executor.can_transition_to(stage.id)
                    can_start = can_transition
                elif not completed:
                    # First stage can always start if nothing completed
                    can_start = (stage.order == 1)
                
                print(f"\n{status_icon} é˜¶æ®µ {stage.order}: {stage.name}")
                print(f"   ID: {stage.id}")
                print(f"   è§’è‰²: {stage.role}")
                if stage.prerequisites:
                    print(f"   å‰ç½®æ¡ä»¶: {', '.join(stage.prerequisites)}")
                if can_start:
                    print(f"   ğŸ’¡ å¯ä»¥å¯åŠ¨: workflow start {stage.id}")
                elif stage.id in completed:
                    print(f"   âœ… å·²å®Œæˆ")
                elif engine.executor:
                    can_transition, errors = engine.executor.can_transition_to(stage.id)
                    if not can_transition:
                        print(f"   âš ï¸  æ— æ³•å¯åŠ¨: {', '.join(errors[:2])}")
            
            # Show available roles
            print("\nå¯ç”¨è§’è‰²:")
            print("-" * 60)
            for role_id_item, role in engine.role_manager.roles.items():
                print(f"   - {role.name} (ID: {role_id_item})")
                desc = role.description[:60] + "..." if len(role.description) > 60 else role.description
                print(f"     æè¿°: {desc}")
            
            # Show next suggested action
            print("\n" + "=" * 60)
            if not completed:
                first_stage = min(engine.workflow.stages, key=lambda s: s.order)
                print(f"ğŸ’¡ å»ºè®®: å¯åŠ¨ç¬¬ä¸€ä¸ªé˜¶æ®µ")
                print(f"   workflow start {first_stage.id}")
            else:
                # Find next uncompleted stage
                next_suggested = False
                for stage in sorted(engine.workflow.stages, key=lambda s: s.order):
                    if stage.id not in completed:
                        if engine.executor:
                            can_transition, errors = engine.executor.can_transition_to(stage.id)
                            if can_transition:
                                print(f"ğŸ’¡ å»ºè®®: å¯åŠ¨ä¸‹ä¸€é˜¶æ®µ")
                                print(f"   workflow start {stage.id}")
                                next_suggested = True
                                break
                        else:
                            print(f"ğŸ’¡ å»ºè®®: å¯åŠ¨é˜¶æ®µ")
                            print(f"   workflow start {stage.id}")
                            next_suggested = True
                            break
                if not next_suggested:
                    print("âœ… æ‰€æœ‰é˜¶æ®µå·²å®Œæˆï¼")
            
            print("\nå…¶ä»–å‘½ä»¤:")
            print("   workflow status          - æŸ¥çœ‹è¯¦ç»†çŠ¶æ€")
            print("   workflow list-stages     - åˆ—å‡ºæ‰€æœ‰é˜¶æ®µ")
            print("   workflow list-roles      - åˆ—å‡ºæ‰€æœ‰è§’è‰²")
            sys.exit(0)
        
        # Original logic for when stage_id is provided
        if not role_id:
            # Infer role from stage
            stage = engine.executor._get_stage_by_id(stage_id) if engine.executor else None
            if stage:
                role_id = stage.role
                print(f"ğŸ’¡ è‡ªåŠ¨æ¨æ–­è§’è‰²: {role_id}")
            else:
                print(f"âŒ æ— æ³•æ¨æ–­è§’è‰²ï¼Œè¯·æ˜ç¡®æŒ‡å®š: workflow start {stage_id} <role>", file=sys.stderr)
                sys.exit(1)
        
        engine.start_stage(stage_id, role_id)
        generate_cursorrules(engine.workspace_path, engine)
        # State is now auto-saved, but keep manual save for explicit control
        if getattr(args, 'no_auto_save', False):
            engine.save_state(state_file)
        print(f"âœ… é˜¶æ®µ '{stage_id}' å·²å¯åŠ¨ (è§’è‰²: {role_id})")
        
        if args.status:
            print_status(engine)
            
    except WorkflowError as e:
        print(f"âŒ å·¥ä½œæµé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)



def cmd_complete(args):
    """å®Œæˆé˜¶æ®µ"""
    try:
        engine, workflow_file, state_file = _init_engine(args)
        
        stage_id = args.stage
        
        if not stage_id:
            # Show available stages to complete
            print("\n" + "=" * 60)
            print("å¯å®Œæˆçš„é˜¶æ®µ")
            print("=" * 60)
            
            current = engine.get_current_stage()
            if not current:
                print("\nâš ï¸  å½“å‰æ²¡æœ‰æ´»åŠ¨é˜¶æ®µ")
                print("   è¯·å…ˆå¯åŠ¨ä¸€ä¸ªé˜¶æ®µ: workflow start <stage>")
                print("\næˆ–æŸ¥çœ‹æ‰€æœ‰é˜¶æ®µ:")
                print("   workflow list-stages")
                sys.exit(1)
            
            print(f"\nå½“å‰æ´»åŠ¨é˜¶æ®µ: {current.name} (ID: {current.id})")
            print(f"å½“å‰è§’è‰²: {engine.executor.state.current_role if engine.executor else 'None'}")
            
            # Show required outputs
            if current.outputs:
                print("\nå¿…éœ€è¾“å‡º:")
                workflow_id = engine.workflow.id if engine.workflow else "default"
                for output in current.outputs:
                    # Get output path using unified path calculation
                    if output.type in ("document", "report"):
                        output_path = engine.workspace_path / ".workflow" / "outputs" / workflow_id / current.id / output.name
                    else:
                        output_path = engine.workspace_path / output.name
                    exists = output_path.exists()
                    marker = "âœ…" if exists else "â³"
                    print(f"  {marker} {output.name} ({'å·²å­˜åœ¨' if exists else 'ç¼ºå¤±'})")
            
            # Show quality gates
            if current.quality_gates:
                print("\nè´¨é‡é—¨ç¦:")
                for gate in current.quality_gates:
                    print(f"  - {gate.type}: {', '.join(gate.criteria)}")
            
            print(f"\nğŸ’¡ å®Œæˆå½“å‰é˜¶æ®µ:")
            print(f"   workflow complete {current.id}")
            print(f"\næˆ–æŸ¥çœ‹è¯¦ç»†åˆ†æ:")
            print(f"   workflow analyze")
            sys.exit(0)
        
        passed, errors = engine.complete_stage(stage_id)
        generate_cursorrules(engine.workspace_path, engine)
        
        if passed:
            # State is now auto-saved, but keep manual save for explicit control
            if getattr(args, 'no_auto_save', False):
                engine.save_state(state_file)
            print(f"âœ… é˜¶æ®µ '{stage_id}' å·²å®Œæˆ")
            
            # Check if all stages are completed (skill accumulation trigger)
            if engine.executor and engine.workflow:
                completed = engine.executor.get_completed_stages()
                all_stages = {s.id for s in engine.workflow.stages}
                
                # If all stages are completed, prompt for skill accumulation
                if completed == all_stages:
                    print("\n" + "=" * 60)
                    print("ğŸ‰ æ­å–œï¼æ‰€æœ‰å·¥ä½œæµé˜¶æ®µå·²å®Œæˆ")
                    print("=" * 60)
                    _prompt_skill_accumulation(engine, engine.workspace_path)
        else:
            print(f"âŒ é˜¶æ®µ '{stage_id}' è´¨é‡é—¨ç¦å¤±è´¥:", file=sys.stderr)
            for error in errors:
                print(f"   - {error}", file=sys.stderr)
            sys.exit(1)
        
        if args.status:
            print_status(engine)
            
    except WorkflowError as e:
        print(f"âŒ å·¥ä½œæµé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_status(args):
    """æ˜¾ç¤ºçŠ¶æ€"""
    try:
        engine, workflow_file, state_file = _init_engine(args)
        print_status(engine)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_validate(args):
    """éªŒè¯åŠ¨ä½œ"""
    try:
        engine, _, _ = _init_engine(args)
        
        result = engine.validate_action(args.role, args.action)
        
        if result:
            print(f"âœ… è§’è‰² '{args.role}' å¯ä»¥æ‰§è¡ŒåŠ¨ä½œ '{args.action}'")
        else:
            print(f"âŒ è§’è‰² '{args.role}' ä¸èƒ½æ‰§è¡ŒåŠ¨ä½œ '{args.action}'")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_list_stages(args):
    """åˆ—å‡ºæ‰€æœ‰é˜¶æ®µ"""
    try:
        engine, workflow_file, _ = _init_engine(args)
        
        print("\nå·¥ä½œæµé˜¶æ®µåˆ—è¡¨:")
        print("=" * 60)
        for stage in engine.workflow.stages:
            print(f"\né˜¶æ®µ {stage.order}: {stage.name}")
            print(f"  ID: {stage.id}")
            print(f"  è§’è‰²: {stage.role}")
            print(f"  å‰ç½®æ¡ä»¶: {', '.join(stage.prerequisites) if stage.prerequisites else 'æ— '}")
            print(f"  è´¨é‡é—¨ç¦: {len(stage.quality_gates)} ä¸ª")
            print(f"  å¿…éœ€è¾“å‡º: {len([o for o in stage.outputs if o.required])} ä¸ª")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_list_roles(args):
    """åˆ—å‡ºæ‰€æœ‰è§’è‰²"""
    try:
        engine, _, _ = _init_engine(args)
        
        print("\nè§’è‰²åˆ—è¡¨:")
        print("=" * 60)
        for role_id, role in engine.role_manager.roles.items():
            print(f"\nè§’è‰²: {role.name}")
            print(f"  ID: {role_id}")
            print(f"  æè¿°: {role.description}")
            print(f"  å…è®¸çš„åŠ¨ä½œ: {len(role.constraints.get('allowed_actions', []))} ä¸ª")
            print(f"  ç¦æ­¢çš„åŠ¨ä½œ: {len(role.constraints.get('forbidden_actions', []))} ä¸ª")
            print(f"  æ‰€éœ€æŠ€èƒ½:")
            # Roleæ¨¡å‹ä½¿ç”¨skillså­—æ®µï¼ˆæŠ€èƒ½IDåˆ—è¡¨ï¼‰ï¼Œä¸æ˜¯required_skills
            if hasattr(role, 'required_skills') and role.required_skills:
                # å…¼å®¹æ—§æ ¼å¼
                for req in role.required_skills:
                    skill = engine.role_manager.skill_library.get(req.skill_id) if engine.role_manager.skill_library else None
                    if skill:
                        print(f"    - {skill.name} (ç­‰çº§â‰¥{req.min_level})")
                    else:
                        print(f"    - {req.skill_id}")
            elif hasattr(role, 'skills') and role.skills:
                # æ–°æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨æŠ€èƒ½IDåˆ—è¡¨
                for skill_id in role.skills:
                    skill = engine.role_manager.skill_library.get(skill_id) if engine.role_manager.skill_library else None
                    if skill:
                        print(f"    - {skill.name}")
                    else:
                        print(f"    - {skill_id}")
            else:
                print("    - æ— ")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_export_graph(args):
    """Export workflow graph to Mermaid or HTML"""
    try:
        engine, _, _ = _init_engine(args)
        mermaid_code = engine.to_mermaid(include_roles=not args.no_roles)
        
        if args.format == "html":
            html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Workflow Visualization</title>
    <style>
        body {{ font-family: sans-serif; margin: 2em; line-height: 1.5; }}
        .mermaid {{ margin-top: 2em; }}
        h1 {{ color: #333; }}
        .desc {{ color: #666; font-style: italic; }}
    </style>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({{startOnLoad:true, theme: 'default'}});</script>
</head>
<body>
    <h1>{engine.workflow.name if engine.workflow else 'Workflow'}</h1>
    <p class="desc">{engine.workflow.description if engine.workflow else ''}</p>
    <div class="mermaid">
{mermaid_code}
    </div>
</body>
</html>"""
            output_file = Path(args.output or "workflow_viz.html")
            output_file.write_text(html_content, encoding='utf-8')
            print(f"âœ… å¯è§†åŒ– HTML å·²ä¿å­˜åˆ°: {output_file}")
        else:
            if args.output:
                output_file = Path(args.output)
                output_file.write_text(mermaid_code, encoding='utf-8')
                print(f"âœ… Mermaid ä»£ç å·²ä¿å­˜åˆ°: {output_file}")
            else:
                print("\nMermaid ä»£ç :")
                print("=" * 60)
                print(mermaid_code)
                print("=" * 60)
                
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_check_team(args):
    """Perform a health check of the team and workflow configuration"""
    try:
        engine, _, _ = _init_engine(args)
        
        print("\n" + "=" * 60)
        print("å›¢é˜Ÿä¸å·¥ä½œæµå¥åº·æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 60)
        
        issues = []
        
        # 1. Role Coverage
        print("\n1. è§’è‰²è¦†ç›–æ£€æŸ¥:")
        if not engine.workflow:
            print("  - âŒ é”™è¯¯: æœªåŠ è½½å·¥ä½œæµå®šä¹‰")
            return
            
        stages = engine.workflow.stages
        stage_roles = set(s.role for s in stages)
        all_roles = set(engine.role_manager.roles.keys())
        
        print(f"  - é˜¶æ®µå®šä¹‰çš„è§’è‰²: {', '.join(stage_roles)}")
        print(f"  - ç³»ç»Ÿå®šä¹‰çš„è§’è‰²: {', '.join(all_roles)}")
        
        unused_roles = all_roles - stage_roles
        if unused_roles:
            print(f"  - âš ï¸ è­¦å‘Š: ä»¥ä¸‹è§’è‰²æœªåœ¨ä»»ä½•é˜¶æ®µä¸­ä½¿ç”¨: {', '.join(unused_roles)}")
        
        # 2. Skill Gap Analysis
        print("\n2. æŠ€èƒ½ç¼ºå£åˆ†æ:")
        for role_id, role in engine.role_manager.roles.items():
            if not role.required_skills:
                print(f"  - âš ï¸ è­¦å‘Š: è§’è‰² '{role_id}' æœªå®šä¹‰ä»»ä½•æ‰€éœ€æŠ€èƒ½")
            else:
                for req in role.required_skills:
                    if not engine.role_manager.skill_library or req.skill_id not in engine.role_manager.skill_library:
                        issues.append(f"è§’è‰² '{role_id}' è¦æ±‚çš„æŠ€èƒ½ '{req.skill_id}' ä¸å­˜åœ¨")
        
        # 3. Workflow Continuity
        print("\n3. å·¥ä½œæµè¿ç»­æ€§æ£€æŸ¥:")
        orders = sorted([s.order for s in stages])
        if orders:
            expected_orders = list(range(min(orders), max(orders) + 1))
            if orders != expected_orders:
                issues.append(f"å·¥ä½œæµé˜¶æ®µé¡ºåºä¸è¿ç»­: {orders}")
            else:
                print("  - âœ… é˜¶æ®µé¡ºåºè¿ç»­")
        
        # 4. Quality Gate Check
        print("\n4. è´¨é‡é—¨ç¦æ£€æŸ¥:")
        for stage in stages:
            if not stage.quality_gates:
                print(f"  - âš ï¸ è­¦å‘Š: é˜¶æ®µ '{stage.id}' æœªå®šä¹‰ä»»ä½•è´¨é‡é—¨ç¦")
            if not stage.outputs:
                print(f"  - âš ï¸ è­¦å‘Š: é˜¶æ®µ '{stage.id}' æœªå®šä¹‰ä»»ä½•å¿…éœ€è¾“å‡º")

        print("\næ€»ç»“:")
        if not issues:
            print("  - âœ… æœªå‘ç°ä¸¥é‡é…ç½®é—®é¢˜ã€‚å›¢é˜Ÿé…ç½®ç¬¦åˆåŸºæœ¬è¦æ±‚ã€‚")
        else:
            print(f"  - âŒ å‘ç° {len(issues)} ä¸ªæ½œåœ¨é—®é¢˜:")
            for issue in issues:
                print(f"    - {issue}")
                
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_team_list(args):
    """åˆ—å‡ºæ‰€æœ‰å›¢é˜Ÿ"""
    try:
        workspace = Path(args.workspace or ".")
        team_manager = TeamManager(workspace)
        teams = team_manager.list_teams()
        
        if not teams:
            print("ğŸ“‹ æœªæ‰¾åˆ°ä»»ä½•å›¢é˜Ÿé…ç½®")
            print("\nğŸ’¡ æç¤º: ä½¿ç”¨ 'workflow team create <team_id>' åˆ›å»ºæ–°å›¢é˜Ÿ")
            return
        
        print("\n" + "=" * 60)
        print("è™šæ‹Ÿå›¢é˜Ÿåˆ—è¡¨")
        print("=" * 60)
        
        current = team_manager.get_current_team()
        for team in teams:
            marker = "â†’" if team["is_current"] else " "
            status = "ã€å½“å‰ã€‘" if team["is_current"] else ""
            print(f"\n{marker} {team['id']} {status}")
            print(f"   åç§°: {team['name']}")
            if team['description']:
                print(f"   æè¿°: {team['description']}")
            print(f"   ç›®å½•: {team['dir']}")
        
        if not current:
            print("\nâš ï¸  æœªè®¾ç½®å½“å‰æ´»åŠ¨å›¢é˜Ÿï¼Œä½¿ç”¨é»˜è®¤é…ç½® (.workflow/)")
            print("ğŸ’¡ æç¤º: ä½¿ç”¨ 'workflow team switch <team_id>' åˆ‡æ¢å›¢é˜Ÿ")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_team_templates(args):
    """åˆ—å‡ºå¯ç”¨çš„å›¢é˜Ÿé…ç½®æ¨¡æ¿"""
    try:
        workspace = Path(args.workspace or ".")
        
        print("\n" + "=" * 60)
        print("å¯ç”¨çš„å›¢é˜Ÿé…ç½®æ¨¡æ¿")
        print("=" * 60)
        
        # æŸ¥æ‰¾ teams ç›®å½•
        teams_dir = workspace / "teams"
        templates_found = False
        
        if teams_dir.exists() and teams_dir.is_dir():
            templates = sorted([d for d in teams_dir.iterdir() if d.is_dir()])
            if templates:
                print("\nğŸ“‚ é¡¹ç›®å›¢é˜Ÿé…ç½® (teams/):")
                for template in templates:
                    readme_file = template / "README.md"
                    description = ""
                    if readme_file.exists():
                        # è¯»å–ç¬¬ä¸€è¡Œä½œä¸ºæè¿°
                        try:
                            first_line = readme_file.read_text(encoding='utf-8').split('\n')[0]
                            if first_line.startswith('#'):
                                description = first_line.lstrip('#').strip()
                        except Exception:
                            pass
                    
                    print(f"  â€¢ {template.name}")
                    if description:
                        print(f"    {description}")
                templates_found = True
        
        # æŸ¥æ‰¾å†…ç½® templates
        try:
            from .engine import TeamManager
            import work_by_roles
            builtin_templates_dir = Path(work_by_roles.__file__).parent / "templates"
            if builtin_templates_dir.exists():
                builtin_templates = sorted([d for d in builtin_templates_dir.iterdir() if d.is_dir()])
                if builtin_templates:
                    print("\nğŸ“¦ å†…ç½®æ¨¡æ¿ (work_by_roles/templates/):")
                    for template in builtin_templates:
                        print(f"  â€¢ {template.name}")
                    templates_found = True
        except Exception:
            pass
        
        if not templates_found:
            print("\nâš ï¸  æœªæ‰¾åˆ°ä»»ä½•å›¢é˜Ÿé…ç½®æ¨¡æ¿")
            print("\nğŸ’¡ æç¤º:")
            print("   1. åœ¨ teams/ ç›®å½•ä¸‹åˆ›å»ºå›¢é˜Ÿé…ç½®")
            print("   2. ä½¿ç”¨ 'workflow team create <team_id> --template <template_name>' åˆ›å»ºå›¢é˜Ÿ")
        else:
            print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
            print("   workflow team create <team_id> --template <template_name>")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_team_switch(args):
    """åˆ‡æ¢åˆ°æŒ‡å®šå›¢é˜Ÿ"""
    try:
        workspace = Path(args.workspace or ".")
        team_manager = TeamManager(workspace)
        
        team_id = args.team_id
        if team_id not in team_manager.teams:
            print(f"âŒ å›¢é˜Ÿ '{team_id}' ä¸å­˜åœ¨", file=sys.stderr)
            print("\nå¯ç”¨å›¢é˜Ÿ:")
            for team in team_manager.list_teams():
                print(f"  - {team['id']}: {team['name']}")
            sys.exit(1)
        
        team_manager.set_current_team(team_id)
        team_config = team_manager.get_team_config(team_id)
        team_info = team_manager.teams[team_id]
        
        print(f"âœ… å·²åˆ‡æ¢åˆ°å›¢é˜Ÿ: {team_id}")
        print(f"   åç§°: {team_info.get('name', team_id)}")
        print(f"   å·¥ä½œæµ: {team_config['workflow']}")
        print(f"   è§’è‰²: {team_config['roles']}")
        print(f"   æŠ€èƒ½: {team_config['skills']}")
        print(f"\nğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ 'workflow start' ç­‰å‘½ä»¤ï¼Œå°†è‡ªåŠ¨ä½¿ç”¨è¯¥å›¢é˜Ÿé…ç½®")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_team_create(args):
    """åˆ›å»ºæ–°å›¢é˜Ÿ"""
    try:
        workspace = Path(args.workspace or ".")
        team_manager = TeamManager(workspace)
        
        team_id = args.team_id
        name = args.name or team_id.replace("_", " ").title()
        description = args.description or ""
        template = args.template
        dir_name = args.dir
        
        team_dir = team_manager.create_team(
            team_id=team_id,
            name=name,
            description=description,
            template=template,
            dir_name=dir_name
        )
        
        print(f"âœ… å·²åˆ›å»ºå›¢é˜Ÿ: {team_id}")
        print(f"   åç§°: {name}")
        print(f"   ç›®å½•: {team_dir}")
        
        if template:
            print(f"   æ¨¡æ¿: {template}")
        
        print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print(f"   1. ç¼–è¾‘å›¢é˜Ÿé…ç½®: {team_dir}/")
        print(f"   2. åˆ‡æ¢åˆ°è¯¥å›¢é˜Ÿ: workflow team switch {team_id}")
        print(f"   3. å¼€å§‹ä½¿ç”¨: workflow start <stage>")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_team_current(args):
    """æ˜¾ç¤ºå½“å‰æ´»åŠ¨å›¢é˜Ÿ"""
    try:
        workspace = Path(args.workspace or ".")
        team_manager = TeamManager(workspace)
        
        current = team_manager.get_current_team()
        if current:
            team_config = team_manager.get_team_config(current)
            team_info = team_manager.teams[current]
            
            print("\n" + "=" * 60)
            print("å½“å‰æ´»åŠ¨å›¢é˜Ÿ")
            print("=" * 60)
            print(f"å›¢é˜Ÿ ID: {current}")
            print(f"åç§°: {team_info.get('name', current)}")
            if team_info.get('description'):
                print(f"æè¿°: {team_info['description']}")
            print(f"\né…ç½®æ–‡ä»¶:")
            print(f"  å·¥ä½œæµ: {team_config['workflow']}")
            print(f"  è§’è‰²: {team_config['roles']}")
            print(f"  æŠ€èƒ½: {team_config['skills']}")
            print(f"  çŠ¶æ€: {team_config['state']}")
        else:
            print("âš ï¸  æœªè®¾ç½®å½“å‰æ´»åŠ¨å›¢é˜Ÿ")
            print("   ä½¿ç”¨é»˜è®¤é…ç½®: .workflow/")
            print("\nğŸ’¡ æç¤º: ä½¿ç”¨ 'workflow team switch <team_id>' åˆ‡æ¢å›¢é˜Ÿ")
            print("   ä½¿ç”¨ 'workflow team list' æŸ¥çœ‹æ‰€æœ‰å›¢é˜Ÿ")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_team_delete(args):
    """åˆ é™¤å›¢é˜Ÿ"""
    try:
        workspace = Path(args.workspace or ".")
        team_manager = TeamManager(workspace)
        
        team_id = args.team_id
        if team_id not in team_manager.teams:
            print(f"âŒ å›¢é˜Ÿ '{team_id}' ä¸å­˜åœ¨", file=sys.stderr)
            sys.exit(1)
        
        # ç¡®è®¤åˆ é™¤
        if not args.force:
            confirm = input(f"âš ï¸  ç¡®å®šè¦åˆ é™¤å›¢é˜Ÿ '{team_id}' å—? [y/N]: ").strip().lower()
            if confirm not in ['y', 'yes']:
                print("å·²å–æ¶ˆ")
                return
        
        team_manager.delete_team(team_id, remove_files=args.remove_files)
        print(f"âœ… å·²åˆ é™¤å›¢é˜Ÿ: {team_id}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_analyze(args):
    """Perform comprehensive workflow analysis for current stage"""
    try:
        engine, _, _ = _init_engine(args)
        
        current_stage = engine.get_current_stage()
        if not current_stage:
            print("âš ï¸  å½“å‰æ²¡æœ‰æ´»åŠ¨é˜¶æ®µ")
            print("   è¿è¡Œ 'workflow start' å¼€å§‹å·¥ä½œæµ")
            sys.exit(0)
        
        print("\n" + "=" * 60)
        print(f"å·¥ä½œæµåˆ†ææŠ¥å‘Š - {current_stage.name}")
        print("=" * 60)
        
        # 1. Stage Overview
        print("\nğŸ“‹ é˜¶æ®µæ¦‚è§ˆ:")
        print(f"  - é˜¶æ®µID: {current_stage.id}")
        print(f"  - é˜¶æ®µåç§°: {current_stage.name}")
        print(f"  - é¡ºåº: {current_stage.order}")
        print(f"  - è§’è‰²: {engine.executor.state.current_role}")
        
        # 2. Role Analysis
        role_id = engine.executor.state.current_role
        if role_id:
            role = engine.role_manager.get_role(role_id)
            if role:
                print("\nğŸ‘¤ è§’è‰²åˆ†æ:")
                print(f"  - è§’è‰²åç§°: {role.name}")
                print(f"  - æè¿°: {role.description}")
                
                # Skills
                if role.required_skills:
                    print("\n  ğŸ“š æ‰€éœ€æŠ€èƒ½:")
                    for req in role.required_skills:
                        skill = engine.role_manager.skill_library.get(req.skill_id) if engine.role_manager.skill_library else None
                        if skill:
                            level_desc = skill.levels.get(req.min_level, f"Level {req.min_level}")
                            print(f"    - {skill.name} (â‰¥{req.min_level}): {level_desc}")
                            if skill.tools:
                                print(f"      å·¥å…·: {', '.join(skill.tools)}")
                
                # Constraints
                allowed = role.constraints.get('allowed_actions', [])
                forbidden = role.constraints.get('forbidden_actions', [])
                print(f"\n  âœ… å…è®¸çš„åŠ¨ä½œ ({len(allowed)}):")
                for action in allowed[:5]:  # Show first 5
                    print(f"    - {action}")
                if len(allowed) > 5:
                    print(f"    ... è¿˜æœ‰ {len(allowed) - 5} ä¸ª")
                
                if forbidden:
                    print(f"\n  âŒ ç¦æ­¢çš„åŠ¨ä½œ ({len(forbidden)}):")
                    for action in forbidden[:5]:
                        print(f"    - {action}")
                    if len(forbidden) > 5:
                        print(f"    ... è¿˜æœ‰ {len(forbidden) - 5} ä¸ª")
        
        # 3. Requirements Analysis
        print("\nğŸ“ é˜¶æ®µè¦æ±‚:")
        
        # Required Outputs
        if current_stage.outputs:
            print("\n  å¿…éœ€è¾“å‡º:")
            workflow_id = engine.workflow.id if engine.workflow else "default"
            for output in current_stage.outputs:
                # Get output path using unified path calculation
                if output.type in ("document", "report"):
                    output_path = engine.workspace_path / ".workflow" / "outputs" / workflow_id / current_stage.id / output.name
                else:
                    output_path = engine.workspace_path / output.name
                status = "âœ… å·²å®Œæˆ" if output_path.exists() else "â³ å¾…å®Œæˆ"
                print(f"    - {status}: {output.name} ({output.type})")
        
        # Quality Gates
        if current_stage.quality_gates:
            print("\n  è´¨é‡é—¨ç¦:")
            for gate in current_stage.quality_gates:
                print(f"    - {gate.type}: {', '.join(gate.criteria)}")
                # Evaluate gate
                passed, errors = engine.quality_gates.evaluate_gate(gate, current_stage, engine.workspace_path)
                if passed:
                    print(f"      âœ… é€šè¿‡")
                else:
                    print(f"      âŒ æœªé€šè¿‡:")
                    for error in errors[:3]:  # Show first 3 errors
                        print(f"        - {error}")
                    if len(errors) > 3:
                        print(f"        ... è¿˜æœ‰ {len(errors) - 3} ä¸ªé”™è¯¯")
        
        # 4. Prerequisites Check
        if current_stage.prerequisites:
            print("\nğŸ”— å‰ç½®æ¡ä»¶:")
            completed = engine.executor.get_completed_stages()
            for prereq in current_stage.prerequisites:
                status = "âœ…" if prereq in completed else "â³"
                prereq_stage = next((s for s in engine.workflow.stages if s.id == prereq), None)
                prereq_name = prereq_stage.name if prereq_stage else prereq
                print(f"    {status} {prereq_name} ({prereq})")
        
        # 5. Next Steps
        print("\nğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®:")
        completed = engine.executor.get_completed_stages()
        
        # Check if current stage can be completed
        can_complete = True
        missing_outputs = []
        workflow_id = engine.workflow.id if engine.workflow else "default"
        for output in current_stage.outputs:
            if output.required:
                # Get output path using unified path calculation
                if output.type in ("document", "report"):
                    output_path = engine.workspace_path / ".workflow" / "outputs" / workflow_id / current_stage.id / output.name
                else:
                    output_path = engine.workspace_path / output.name
                if not output_path.exists():
                    can_complete = False
                    missing_outputs.append(output.name)
        
        if can_complete:
            print("  âœ… å½“å‰é˜¶æ®µå¯ä»¥å®Œæˆ:")
            print(f"     workflow complete {current_stage.id}")
        else:
            print("  â³ éœ€è¦å®Œæˆä»¥ä¸‹è¾“å‡ºæ‰èƒ½å®Œæˆé˜¶æ®µ:")
            for output in missing_outputs:
                print(f"     - {output}")
        
        # Suggest next stage
        next_stages = [s for s in engine.workflow.stages 
                      if s.order > current_stage.order 
                      and s.id not in completed]
        if next_stages:
            next_stage = min(next_stages, key=lambda s: s.order)
            can_transition, errors = engine.executor.can_transition_to(next_stage.id)
            if can_transition:
                print(f"\n  â¡ï¸  ä¸‹ä¸€é˜¶æ®µ: {next_stage.name} ({next_stage.id})")
                print(f"     è§’è‰²: {next_stage.role}")
                print(f"     å‘½ä»¤: workflow start {next_stage.id} --as {next_stage.role}")
        
        # 6. Team Context Reference
        print("\nğŸ’¡ AI åä½œæç¤º:")
        print("  åœ¨ Cursor ä¸­ä½¿ç”¨ '@[team]' æˆ– '@team' è®© AI è‡ªåŠ¨åº”ç”¨å½“å‰è§’è‰²çº¦æŸ")
        print(f"  AI ä¼šè‡ªåŠ¨è¯»å–: .workflow/TEAM_CONTEXT.md")
        print("  ä½¿ç”¨ '@[team] wfauto' æˆ– '@[team] è¿è¡Œå®Œæ•´å·¥ä½œæµ' å¯è‡ªåŠ¨æ‰§è¡Œæ‰€æœ‰é˜¶æ®µ")
        
        print("\n" + "=" * 60)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_add_role(args):
    """Add a new role interactively"""
    try:
        workspace = Path(args.workspace or ".")
        roles_file = Path(args.roles or "role_schema.yaml")
        
        if not roles_file.exists():
            print(f"âŒ è§’è‰²æ–‡ä»¶ä¸å­˜åœ¨: {roles_file}", file=sys.stderr)
            sys.exit(1)
        
        # Load existing roles
        with open(roles_file, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        
        # Interactive input
        role_id = args.role_id or input("è§’è‰² ID (å¦‚: frontend_dev): ").strip()
        name = args.name or input("è§’è‰²åç§°: ").strip()
        description = args.description or input("è§’è‰²æè¿°: ").strip()
        
        # Get allowed actions
        print("\nå…è®¸çš„åŠ¨ä½œ (æ¯è¡Œä¸€ä¸ªï¼Œç©ºè¡Œç»“æŸ):")
        allowed = []
        while True:
            action = input("  > ").strip()
            if not action:
                break
            allowed.append(action)
        
        # Get forbidden actions
        print("\nç¦æ­¢çš„åŠ¨ä½œ (æ¯è¡Œä¸€ä¸ªï¼Œç©ºè¡Œç»“æŸ):")
        forbidden = []
        while True:
            action = input("  > ").strip()
            if not action:
                break
            forbidden.append(action)
        
        # Create role entry
        new_role = {
            "id": role_id,
            "name": name,
            "description": description,
            "extends": None,
            "constraints": {
                "allowed_actions": allowed,
                "forbidden_actions": forbidden
            },
            "required_skills": [],
            "validation_rules": []
        }
        
        # Add to roles list
        if 'roles' not in data:
            data['roles'] = []
        data['roles'].append(new_role)
        
        # Save
        with open(roles_file, 'w', encoding='utf-8') as f:
            yaml.dump(data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        print(f"\nâœ… è§’è‰² '{role_id}' å·²æ·»åŠ åˆ° {roles_file}")
        
    except KeyboardInterrupt:
        print("\n\nâŒ å·²å–æ¶ˆ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_add_stage(args):
    """Add a new stage interactively"""
    # ... existing implementation ...


def cmd_migrate_skills(args):
    """Migrate skill_library.yaml to Anthropic Skill.md format
    
    Note: This command is deprecated. The system now uses Skill.md files exclusively.
    skill_library.yaml files are no longer supported.
    """
    import subprocess
    from pathlib import Path
    
    print("âš ï¸  Warning: skill_library.yaml is deprecated. The system now uses Skill.md files exclusively.", file=sys.stderr)
    print("   This migration tool is provided for legacy support only.\n", file=sys.stderr)
    
    yaml_file = Path(args.yaml_file)
    output_dir = Path(args.output) if args.output else Path("skills")
    
    if not yaml_file.exists():
        print(f"âŒ File not found: {yaml_file}", file=sys.stderr)
        sys.exit(1)
    
    # Run migration tool
    tool_path = Path(__file__).parent.parent / "tools" / "migrate_to_anthropic_skills.py"
    if not tool_path.exists():
        print(f"âŒ Migration tool not found: {tool_path}", file=sys.stderr)
        sys.exit(1)
    
    cmd = [sys.executable, str(tool_path), str(yaml_file), "--output", str(output_dir)]
    result = subprocess.run(cmd)
    
    if result.returncode == 0:
        print(f"\nâœ… Migration complete! Update your config to use: {output_dir}")
    else:
        sys.exit(result.returncode)


def cmd_setup(args):
    """ä¸€é”®æ¥å…¥ï¼šè‡ªåŠ¨è®¾ç½®é¡¹ç›®ï¼Œè®©ç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨è§’è‰²"""
    workspace = Path(args.workspace or ".")
    print("=" * 60)
    print("ğŸš€ ä¸€é”®æ¥å…¥ Multi-Role Skills Workflow")
    print("=" * 60)
    print(f"\nç›®æ ‡é¡¹ç›®: {workspace.absolute()}\n")
    
    # åˆ›å»º .workflow ç›®å½•å’Œ temp å­ç›®å½•
    workflow_dir = workspace / ".workflow"
    workflow_dir.mkdir(exist_ok=True)
    temp_dir = workflow_dir / "temp"
    temp_dir.mkdir(exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨é…ç½®
    roles_file = workflow_dir / "role_schema.yaml"
    skills_dir = workflow_dir / "skills"
    
    if roles_file.exists() and skills_dir.exists():
        print("âš ï¸  é¡¹ç›®å·²æ¥å…¥ï¼Œé…ç½®å·²å­˜åœ¨")
        print(f"   - è§’è‰²é…ç½®: {roles_file}")
        print(f"   - æŠ€èƒ½ç›®å½•: {skills_dir}")
        print("\nğŸ’¡ å¦‚éœ€é‡æ–°æ¥å…¥ï¼Œè¯·å…ˆåˆ é™¤ .workflow/ ç›®å½•")
        return
    
    # æŸ¥æ‰¾æ ‡å‡†æ¨¡æ¿ï¼ˆä¼˜å…ˆä½¿ç”¨ teams/standard-deliveryï¼‰
    template_sources = [
        workspace / "teams" / "standard-delivery",  # é¡¹ç›®å†…å›¢é˜Ÿé…ç½®
        Path(__file__).parent.parent / "teams" / "standard-delivery",  # æ¡†æ¶å†…ç½®
        Path(__file__).parent / "templates" / "standard_agile",  # å†…ç½®æ¨¡æ¿
    ]
    
    template_dir = None
    for source in template_sources:
        if source.exists() and source.is_dir():
            template_dir = source
            break
    
    if not template_dir:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°æ ‡å‡†æ¨¡æ¿")
        print("   è¯·ç¡®ä¿é¡¹ç›®åŒ…å« teams/standard-delivery/ é…ç½®")
        sys.exit(1)
    
    print(f"âœ… ä½¿ç”¨æ¨¡æ¿: {template_dir.relative_to(workspace) if template_dir.is_relative_to(workspace) else template_dir}")
    
    # å¤åˆ¶è§’è‰²é…ç½®
    import shutil
    template_roles = template_dir / "role_schema.yaml"
    if template_roles.exists():
        shutil.copy(template_roles, roles_file)
        print(f"  âœ… å·²å¤åˆ¶è§’è‰²é…ç½®: {roles_file.name}")
    else:
        print(f"  âš ï¸  è­¦å‘Š: æ¨¡æ¿ä¸­æœªæ‰¾åˆ° role_schema.yaml")
    
    # å¤åˆ¶æŠ€èƒ½ç›®å½•
    template_skills = template_dir / "skills"
    if template_skills.exists() and template_skills.is_dir():
        if skills_dir.exists():
            shutil.rmtree(skills_dir)
        shutil.copytree(template_skills, skills_dir)
        skill_count = len(list(skills_dir.rglob("Skill.md")))
        print(f"  âœ… å·²å¤åˆ¶æŠ€èƒ½ç›®å½•: {skill_count} ä¸ªæŠ€èƒ½")
    else:
        print(f"  âš ï¸  è­¦å‘Š: æ¨¡æ¿ä¸­æœªæ‰¾åˆ° skills/ ç›®å½•")
    
    # å¯é€‰ï¼šå¤åˆ¶ workflow_schema.yamlï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    template_workflow = template_dir / "workflow_schema.yaml"
    workflow_file = workflow_dir / "workflow_schema.yaml"
    if template_workflow.exists() and not workflow_file.exists():
        shutil.copy(template_workflow, workflow_file)
        print(f"  âœ… å·²å¤åˆ¶å·¥ä½œæµé…ç½®ï¼ˆå¯é€‰ï¼‰: {workflow_file.name}")
    
    # ç”Ÿæˆé¡¹ç›®ä¸Šä¸‹æ–‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
    from work_by_roles.core.engine import ProjectScanner
    print("\nğŸ” æ­£åœ¨æ‰«æé¡¹ç›®ç»“æ„...")
    scanner = ProjectScanner(workspace)
    context = scanner.scan()
    
    context_file = workflow_dir / "project_context.yaml"
    with open(context_file, 'w', encoding='utf-8') as f:
        yaml.dump(context.to_dict(), f, default_flow_style=False, allow_unicode=True)
    print(f"  âœ… å·²ç”Ÿæˆé¡¹ç›®ä¸Šä¸‹æ–‡: {context_file.name}")
    
    # ç”Ÿæˆä½¿ç”¨è¯´æ˜
    usage_file = workflow_dir / "USAGE.md"
    usage_content = """# å¿«é€Ÿä½¿ç”¨æŒ‡å—

## âœ… æ¥å…¥å®Œæˆï¼

é¡¹ç›®å·²æˆåŠŸæ¥å…¥ Multi-Role Skills Workflow æ¡†æ¶ã€‚

## ğŸš€ ç«‹å³å¼€å§‹ä½¿ç”¨

### æ–¹å¼ 1: åœ¨ Cursor IDE ä¸­ä½¿ç”¨ï¼ˆæ¨èï¼‰

åœ¨ Cursor çš„å¯¹è¯ä¸­ç›´æ¥ä½¿ç”¨ï¼š

```
@product_analyst åˆ†æç”¨æˆ·ç™»å½•åŠŸèƒ½çš„éœ€æ±‚
@system_architect è®¾è®¡å¾®æœåŠ¡æ¶æ„
@core_framework_engineer å®ç°ç”¨æˆ·è®¤è¯æ¨¡å—
@qa_reviewer æ£€æŸ¥ä»£ç è´¨é‡å’Œæµ‹è¯•è¦†ç›–ç‡
```

æˆ–è€…ä½¿ç”¨ `@team` è§¦å‘å®Œæ•´å·¥ä½œæµï¼š

```
@team å®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½
```

### æ–¹å¼ 2: å‘½ä»¤è¡Œä½¿ç”¨

```bash
# ä½¿ç”¨äº§å“åˆ†æå¸ˆè§’è‰²åˆ†æéœ€æ±‚
workflow role-execute product_analyst "åˆ†æç”¨æˆ·ç™»å½•åŠŸèƒ½çš„éœ€æ±‚"

# ä½¿ç”¨ç³»ç»Ÿæ¶æ„å¸ˆè§’è‰²è®¾è®¡æ¶æ„
workflow role-execute system_architect "è®¾è®¡å¾®æœåŠ¡æ¶æ„"

# ä½¿ç”¨æ ¸å¿ƒæ¡†æ¶å·¥ç¨‹å¸ˆå®ç°åŠŸèƒ½
workflow role-execute core_framework_engineer "å®ç°ç”¨æˆ·è®¤è¯æ¨¡å—"

# ä½¿ç”¨QAå®¡æŸ¥å‘˜è¿›è¡Œè´¨é‡æ£€æŸ¥
workflow role-execute qa_reviewer "æ£€æŸ¥ä»£ç è´¨é‡å’Œæµ‹è¯•è¦†ç›–ç‡"
```

### æ–¹å¼ 3: ä½¿ç”¨å·¥ä½œæµï¼ˆå¯é€‰ï¼Œé€‚åˆå¤§å‹é¡¹ç›®ï¼‰

```bash
# æŸ¥çœ‹å¯ç”¨è§’è‰²
workflow list-roles

# æŸ¥çœ‹å¯ç”¨æŠ€èƒ½
workflow list-skills

# å¯åŠ¨å·¥ä½œæµï¼ˆå¦‚æœé…ç½®äº† workflow_schema.yamlï¼‰
workflow wfauto
```

## ğŸ“‹ å¯ç”¨è§’è‰²

è¿è¡Œ `workflow list-roles` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨è§’è‰²åŠå…¶æŠ€èƒ½ã€‚

## ğŸ› ï¸ å¯ç”¨æŠ€èƒ½

è¿è¡Œ `workflow list-skills` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æŠ€èƒ½ã€‚

## ğŸ’¡ æç¤º

- **åœ¨ Cursor ä¸­ä½¿ç”¨**: ä½¿ç”¨ `@è§’è‰²å` æˆ– `@team` æ¥è®© AI è‡ªåŠ¨ä½¿ç”¨å¯¹åº”çš„è§’è‰²å’ŒæŠ€èƒ½
- **è‡ªå®šä¹‰æŠ€èƒ½**: ä½¿ç”¨ `workflow generate-skill` åˆ›å»ºæ–°æŠ€èƒ½
- **è‡ªå®šä¹‰è§’è‰²**: ç¼–è¾‘ `.workflow/role_schema.yaml` æ·»åŠ æ–°è§’è‰²

## ğŸ“š æ›´å¤šä¿¡æ¯

æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£äº†è§£æ›´å¤šåŠŸèƒ½ï¼š
- `README.md` - å®Œæ•´æ–‡æ¡£
- `docs/CURSOR_GUIDE.md` - Cursor IDE ä½¿ç”¨æŒ‡å—
- `docs/SKILLS_GUIDE.md` - æŠ€èƒ½ä½¿ç”¨æŒ‡å—
- `docs/USAGE_GUIDE.md` - ä½¿ç”¨æŒ‡å—
"""
    usage_file.write_text(usage_content, encoding='utf-8')
    print(f"  âœ… å·²ç”Ÿæˆä½¿ç”¨è¯´æ˜: {usage_file.name}")
    
    # ç”Ÿæˆ Cursor é…ç½®æ–‡ä»¶ï¼ˆä»…å½“åœ¨ Cursor IDE ä¸­æ—¶ï¼‰
    from work_by_roles.cli import generate_cursorrules
    if generate_cursorrules(workspace):
        print(f"  âœ… å·²ç”Ÿæˆ Cursor IDE é…ç½®æ–‡ä»¶ï¼ˆ.cursorrulesï¼ŒåŒ…å«è‡ªåŠ¨æ‰§è¡Œè§„åˆ™ï¼‰")
    else:
        print(f"  â„¹ï¸  æœªæ£€æµ‹åˆ° Cursor IDE ç¯å¢ƒï¼Œè·³è¿‡é…ç½®æ–‡ä»¶ç”Ÿæˆ")
    
    # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
    print("\n" + "=" * 60)
    print("âœ… æ¥å…¥å®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
    print("  1. æŸ¥çœ‹å¯ç”¨è§’è‰²: workflow list-roles")
    print("  2. æŸ¥çœ‹å¯ç”¨æŠ€èƒ½: workflow list-skills")
    print("  3. ä½¿ç”¨è§’è‰²æ‰§è¡Œä»»åŠ¡:")
    print("     workflow role-execute <role_id> \"<requirement>\"")
    print("\nğŸ’¡ ç¤ºä¾‹:")
    print("   workflow role-execute product_analyst \"åˆ†æç”¨æˆ·éœ€æ±‚\"")
    print("   workflow role-execute system_architect \"è®¾è®¡ç³»ç»Ÿæ¶æ„\"")
    print(f"\nğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜: {usage_file}")
    print("=" * 60)


def cmd_role_execute(args):
    """
    ä½¿ç”¨æŒ‡å®šè§’è‰²å¤„ç†éœ€æ±‚ï¼ˆç®€åŒ–æ¨¡å¼ï¼Œæ— éœ€workflowï¼‰
    
    è¿™æ˜¯é‡æ„åçš„ç®€åŒ–æ¥å£ï¼Œé€‚ç”¨äºIDEç¯å¢ƒï¼ˆå¦‚Cursorï¼‰ã€‚
    ç”¨æˆ·æŒ‡å®šè§’è‰²å’Œéœ€æ±‚ï¼Œè§’è‰²ä½¿ç”¨skillsæ¥å¤„ç†å¹¶è¿”å›ç»“æœã€‚
    """
    if not _agents_available:
        print("âŒ Agent ç³»ç»Ÿæœªå¯ç”¨ï¼Œè¯·ç¡®ä¿å·²å®‰è£…å®Œæ•´åŒ…", file=sys.stderr)
        sys.exit(1)
    
    try:
        engine, _, _ = _init_engine(args)
        workspace = Path(args.workspace or ".")
        
        # è·å–è§’è‰²ä¿¡æ¯ï¼ˆåœ¨æ‰§è¡Œå‰ï¼‰
        role = engine.role_manager.get_role(args.role_id)
        if not role:
            print(f"âŒ è§’è‰² '{args.role_id}' æœªæ‰¾åˆ°", file=sys.stderr)
            sys.exit(1)
        
        # è·å–æ‰§è¡Œæ¨¡å¼ä¿¡æ¯
        execution_mode_info = None
        if engine.role_manager.skill_library:
            execution_mode_info = ExecutionModeAnalyzer.get_execution_mode_info(
                role=role,
                skill_library=engine.role_manager.skill_library,
                environment="cursor"
            )
        
        # åŠ è½½ LLM å®¢æˆ·ç«¯
        llm_client = _load_llm_client(workspace)
        
        # å¦‚æœä½¿ç”¨ --use-llm ä½†æœªé…ç½® LLM å®¢æˆ·ç«¯ï¼ŒæŠ›å‡ºé”™è¯¯
        if args.use_llm and not llm_client:
            error_msg = (
                "âŒ LLM client not configured. Please:\n"
                "  1. Set environment variable (e.g., OPENAI_API_KEY or ANTHROPIC_API_KEY)\n"
                "  2. Or create .workflow/config.yaml with llm configuration\n"
                "  3. Or remove --use-llm flag to use lightweight mode\n"
                "\n"
                "Example environment variables:\n"
                "  export OPENAI_API_KEY='your-api-key'\n"
                "  export ANTHROPIC_API_KEY='your-api-key'\n"
                "\n"
                "Example config file (.workflow/config.yaml):\n"
                "  llm:\n"
                "    provider: openai\n"
                "    api_key: your-api-key\n"
                "    model: gpt-4\n"
                "    base_url: https://api.openai.com/v1  # å¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰ç«¯ç‚¹"
            )
            print(error_msg, file=sys.stderr)
            raise WorkflowError("LLM client not configured but --use-llm flag is set")
        
        # è§£æè¾“å…¥æ•°æ®
        inputs = {}
        if args.inputs:
            try:
                inputs = json.loads(args.inputs)
            except json.JSONDecodeError as e:
                print(f"âŒ è¾“å…¥æ•°æ®JSONæ ¼å¼é”™è¯¯: {e}", file=sys.stderr)
                sys.exit(1)
        
        # åˆ›å»ºæ²‰æµ¸å¼æ˜¾ç¤ºï¼ˆå¦‚æœæ”¯æŒï¼‰
        immersive_display = None
        try:
            from .core.immersive_workflow_display import ImmersiveWorkflowDisplay
            immersive_display = ImmersiveWorkflowDisplay(workspace, use_streaming=True)
        except Exception:
            # å¦‚æœæ²‰æµ¸å¼æ˜¾ç¤ºä¸å¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨æ™®é€šæ¨¡å¼
            pass
        
        # æ˜¾ç¤ºé†’ç›®çš„è§’è‰²ä¿¡æ¯æ¨ªå¹…ï¼ˆæ™®é€šæ¨¡å¼ï¼‰
        if not immersive_display:
            print("\n" + "=" * 70)
            print("ğŸ­ è§’è‰²æ‰§è¡Œæ¨¡å¼".center(70))
            print("=" * 70)
            print(f"\nğŸ‘¤ è§’è‰²: {role.name} ({args.role_id})")
            print(f"ğŸ“ æè¿°: {role.description}")
            
            if execution_mode_info:
                mode_icons = {
                    'analysis': 'ğŸ“Š',
                    'implementation': 'ğŸ’»',
                    'validation': 'âœ…'
                }
                mode_names = {
                    'analysis': 'åˆ†ææ¨¡å¼',
                    'implementation': 'å®ç°æ¨¡å¼',
                    'validation': 'éªŒè¯æ¨¡å¼'
                }
                icon = mode_icons.get(execution_mode_info['mode'], 'ğŸ”§')
                mode_name = mode_names.get(execution_mode_info['mode'], execution_mode_info['mode'])
                print(f"{icon} æ‰§è¡Œæ¨¡å¼: {mode_name}")
                
                if execution_mode_info.get('tools'):
                    print(f"ğŸ› ï¸  å¯ç”¨å·¥å…·: {', '.join(execution_mode_info['tools'][:5])}")
                    if len(execution_mode_info['tools']) > 5:
                        print(f"   ... è¿˜æœ‰ {len(execution_mode_info['tools']) - 5} ä¸ªå·¥å…·")
            
            print(f"\nğŸ“‹ ä»»åŠ¡éœ€æ±‚: {args.requirement}")
            print(f"ğŸ¤– LLMæ¨¡å¼: {'å¯ç”¨' if args.use_llm else 'ç¦ç”¨ï¼ˆè½»é‡æ¨¡å¼ï¼‰'}")
            if inputs:
                print(f"ğŸ“¥ è¾“å…¥æ•°æ®: {len(inputs)} é¡¹")
            
            print("\n" + "-" * 70)
            print("ğŸš€ å¼€å§‹æ‰§è¡Œ...")
            print("-" * 70 + "\n")
        
        # åˆ›å»ºRoleExecutor
        role_executor = RoleExecutor(engine, llm_client=llm_client)
        
        # æ‰§è¡Œè§’è‰²ï¼ˆä¼ å…¥æ²‰æµ¸å¼æ˜¾ç¤ºï¼‰
        result = role_executor.execute_role(
            role_id=args.role_id,
            requirement=args.requirement,
            inputs=inputs,
            use_llm=args.use_llm,
            immersive_display=immersive_display
        )
        
        # æ˜¾ç¤ºç»“æœï¼ˆå¦‚æœä½¿ç”¨æ²‰æµ¸å¼æ˜¾ç¤ºï¼Œå¤§éƒ¨åˆ†ä¿¡æ¯å·²ç»åœ¨æµå¼è¾“å‡ºä¸­æ˜¾ç¤ºï¼‰
        if not immersive_display:
            print("\n" + "=" * 70)
            print(f"ğŸ“Š {role.name} æ‰§è¡Œç»“æœ".center(70))
            print("=" * 70)
            print(f"\nâœ… æ‰§è¡Œçš„æŠ€èƒ½: {', '.join(result['skills_executed'])}")
            
            # æ˜¾ç¤ºæŠ€èƒ½æ‰§è¡Œç»“æœï¼ˆå¸¦è§’è‰²æ ‡è¯†ï¼‰
            print(f"\nğŸ”§ {role.name} çš„æŠ€èƒ½æ‰§è¡Œè¯¦æƒ…:")
            for skill_result in result['skill_results']:
                skill_id = skill_result['skill_id']
                if 'result' in skill_result:
                    if skill_result['result'].get('success'):
                        print(f"  âœ… [{role.name}] {skill_id}: æ‰§è¡ŒæˆåŠŸ")
                    else:
                        print(f"  âŒ [{role.name}] {skill_id}: æ‰§è¡Œå¤±è´¥")
                        if skill_result['result'].get('error'):
                            print(f"     é”™è¯¯: {skill_result['result']['error']}")
                elif 'error' in skill_result:
                    print(f"  âŒ [{role.name}] {skill_id}: é”™è¯¯ - {skill_result['error']}")
            
            # æ˜¾ç¤ºæœ€ç»ˆå“åº”ï¼ˆä»¥è§’è‰²èº«ä»½å‘ˆç°ï¼‰
            print(f"\nğŸ’¬ {role.name} çš„å“åº”:")
            print("-" * 70)
            # æ·»åŠ è§’è‰²æ ‡è¯†å‰ç¼€
            response_with_role = f"[{role.name}] {result['response']}"
            print(response_with_role)
            print("-" * 70)
            
            # å¦‚æœä½¿ç”¨LLMï¼Œæ˜¾ç¤ºæç¤º
            if args.use_llm:
                print(f"\nğŸ’¡ æç¤º: {role.name} å·²ä½¿ç”¨LLMç”Ÿæˆå“åº”")
            else:
                print(f"\nğŸ’¡ æç¤º: å½“å‰ä¸ºè½»é‡æ¨¡å¼ï¼Œä½¿ç”¨ --use-llm è®© {role.name} ç”Ÿæˆæ›´è¯¦ç»†çš„å“åº”")
        else:
            # å³ä½¿ä½¿ç”¨æ²‰æµ¸å¼æ˜¾ç¤ºï¼Œä¹Ÿè¦æ˜¾ç¤ºæœ€ç»ˆå“åº”
            if result.get('response'):
                print("\n" + "=" * 70)
                print(f"ğŸ’¬ {role.name} çš„å“åº”:")
                print("-" * 70)
                response_with_role = f"[{role.name}] {result['response']}"
                print(response_with_role)
                print("-" * 70)
        
        return result
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
def cmd_agent_execute(args):
    """ä½¿ç”¨ Agent æ‰§è¡Œå·¥ä½œæµé˜¶æ®µï¼ˆç±»ä¼¼ MetaGPTï¼‰"""
    if not _agents_available:
        print("âŒ Agent ç³»ç»Ÿæœªå¯ç”¨ï¼Œè¯·ç¡®ä¿å·²å®‰è£…å®Œæ•´åŒ…", file=sys.stderr)
        sys.exit(1)
    
    try:
        engine, _, _ = _init_engine(args)
        workspace = Path(args.workspace or ".")
        
        # åŠ è½½ LLM å®¢æˆ·ç«¯
        llm_client = _load_llm_client(workspace)
        
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨LLM
        use_llm = getattr(args, 'use_llm', False) and not getattr(args, 'no_llm', False)
        
        # å¦‚æœä½¿ç”¨ --use-llm ä½†æœªé…ç½® LLM å®¢æˆ·ç«¯ï¼ŒæŠ›å‡ºé”™è¯¯
        if use_llm and not llm_client:
            error_msg = (
                "âŒ LLM client not configured. Please:\n"
                "  1. Set environment variable (e.g., OPENAI_API_KEY or ANTHROPIC_API_KEY)\n"
                "  2. Or create .workflow/config.yaml with llm configuration\n"
                "  3. Or remove --use-llm flag to use lightweight mode\n"
                "\n"
                "Example environment variables:\n"
                "  export OPENAI_API_KEY='your-api-key'\n"
                "  export ANTHROPIC_API_KEY='your-api-key'\n"
                "\n"
                "Example config file (.workflow/config.yaml):\n"
                "  llm:\n"
                "    provider: openai\n"
                "    api_key: your-api-key\n"
                "    model: gpt-4\n"
                "    base_url: https://api.openai.com/v1  # å¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰ç«¯ç‚¹"
            )
            print(error_msg, file=sys.stderr)
            raise WorkflowError("LLM client not configured but --use-llm flag is set")
        
        orchestrator = AgentOrchestrator(engine, llm_client=llm_client)
        
        stage_id = args.stage
        if not stage_id:
            # Auto-infer next stage
            current = engine.get_current_stage()
            completed = engine.executor.get_completed_stages() if engine.executor else set()
            
            if not completed:
                first_stage = min(engine.workflow.stages, key=lambda s: s.order)
                stage_id = first_stage.id
            else:
                for stage in sorted(engine.workflow.stages, key=lambda s: s.order):
                    if stage.id not in completed:
                        can_transition, _ = engine.executor.can_transition_to(stage.id)
                        if can_transition:
                            stage_id = stage.id
                            break
        
        if not stage_id:
            print("âœ… æ‰€æœ‰é˜¶æ®µå·²å®Œæˆï¼")
            sys.exit(0)
        
        # ç¡®ä¿é˜¶æ®µå·²å¯åŠ¨
        stage = engine.executor._get_stage_by_id(stage_id)
        if not stage:
            print(f"âŒ é˜¶æ®µ '{stage_id}' ä¸å­˜åœ¨", file=sys.stderr)
            sys.exit(1)
        
        # å¯åŠ¨é˜¶æ®µï¼ˆå¦‚æœæœªå¯åŠ¨ï¼‰
        current = engine.get_current_stage()
        if not current or current.id != stage_id:
            engine.start_stage(stage_id, stage.role)
        
        collaborate = getattr(args, 'collaborate', False)
        
        print(f"\nğŸ¤– Agent æ‰§è¡Œæ¨¡å¼ - {stage.name}")
        print("=" * 60)
        print(f"é˜¶æ®µ: {stage.name} ({stage_id})")
        print(f"Agent: {stage.role}")
        print(f"æ¨¡å¼: {'LLMæ‰§è¡Œ' if use_llm else 'çº¦æŸæ£€æŸ¥ï¼ˆè½»é‡æ¨¡å¼ï¼‰'}")
        if collaborate:
            print(f"åä½œæ¨¡å¼: å·²å¯ç”¨ï¼ˆAgent é—´æ¶ˆæ¯ä¼ é€’å’Œåé¦ˆï¼‰")
        
        # æ‰§è¡Œé˜¶æ®µ
        result = orchestrator.execute_stage(stage_id, use_llm=use_llm)
        
        # å¦‚æœå¯ç”¨åä½œæ¨¡å¼ï¼Œæ£€æŸ¥æ¶ˆæ¯
        if collaborate and result.get("agent"):
            agent = result["agent"]
            messages = agent.check_messages()
            if messages:
                print(f"\nğŸ“¨ æ”¶åˆ° {len(messages)} æ¡æ¥è‡ªå…¶ä»– Agent çš„æ¶ˆæ¯")
                for msg in messages[:3]:  # åªæ˜¾ç¤ºå‰3æ¡
                    print(f"  - æ¥è‡ª {msg.from_agent}: {msg.message_type}")
                if len(messages) > 3:
                    print(f"  ... è¿˜æœ‰ {len(messages) - 3} æ¡æ¶ˆæ¯")
        agent = result["agent"]
        context = result["context"]
        
        if use_llm and result.get("llm_used", False):
            print(f"\nâœ… Agent '{agent.role.name}' å·²å‡†å¤‡å°±ç»ªï¼ˆLLMæ¨¡å¼ï¼‰")
            if "prompt" in result:
                print(f"ğŸ“ å·²ç”ŸæˆLLMæç¤ºï¼ˆ{len(result['prompt'])} å­—ç¬¦ï¼‰")
        else:
            print(f"\nâœ… çº¦æŸæ£€æŸ¥å®Œæˆ - Agent '{agent.role.name}'")
            if result.get("can_start", True):
                print("âœ… é˜¶æ®µå¯ä»¥å¯åŠ¨")
            else:
                print("âŒ é˜¶æ®µæ— æ³•å¯åŠ¨:")
                for error in result.get("errors", []):
                    print(f"   - {error}")
        
        print(f"ğŸ“¥ è¾“å…¥ä¸Šä¸‹æ–‡: {len(context.inputs)} é¡¹")
        
        # æ˜¾ç¤ºå¯ç”¨æ“ä½œ
        print("\nğŸ’¡ Agent å¯ç”¨æ“ä½œ:")
        allowed = agent.role.constraints.get('allowed_actions', [])
        for action in allowed[:5]:
            print(f"  - {action}")
        if len(allowed) > 5:
            print(f"  ... è¿˜æœ‰ {len(allowed) - 5} ä¸ª")
        
        if not use_llm:
            print("\nğŸ’¡ æç¤º:")
            print("  - å½“å‰ä¸ºè½»é‡æ¨¡å¼ï¼ˆæ— LLMè°ƒç”¨ï¼‰")
            print("  - ä½¿ç”¨ --use-llm å¯ç”¨LLMæ‰§è¡Œï¼ˆéœ€è¦é…ç½®llm_clientï¼‰")
            print("  - ä½¿ç”¨ Python API è°ƒç”¨ agent çš„æ–¹æ³•:")
            print("    agent.make_decision('...')")
            print("    agent.produce_output('file.md', content)")
        else:
            print("\nğŸ“ æç¤º:")
            print("  - ä½¿ç”¨ Python API è°ƒç”¨ agent çš„æ–¹æ³•:")
            print("    agent.make_decision('...')")
            print("    agent.produce_output('file.md', content)")
            print("    agent.review('item', 'feedback')")
        print("  - å®Œæˆåè¿è¡Œ: workflow agent-complete " + stage_id)
        
        return result
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        # traceback.print_exc()
        sys.exit(1)


def cmd_agent_complete(args):
    """å®Œæˆ Agent æ‰§è¡Œçš„ä»»åŠ¡"""
    if not _agents_available:
        print("âŒ Agent ç³»ç»Ÿæœªå¯ç”¨", file=sys.stderr)
        sys.exit(1)
    
    try:
        engine, _, _ = _init_engine(args)
        orchestrator = AgentOrchestrator(engine)
        
        stage_id = args.stage
        if not stage_id:
            current = engine.get_current_stage()
            if current:
                stage_id = current.id
            else:
                print("âŒ æ²¡æœ‰æ´»åŠ¨é˜¶æ®µ", file=sys.stderr)
                sys.exit(1)
        
        print(f"\nğŸ¤– å®Œæˆ Agent ä»»åŠ¡ - {stage_id}")
        print("=" * 60)
        
        result = orchestrator.complete_stage(stage_id)
        
        if result["quality_gates_passed"]:
            print("âœ… é˜¶æ®µå®Œæˆ")
            # print(f"ğŸ“Š è¾“å‡ºæ–‡ä»¶: {len(result['result']['outputs'])} ä¸ª")
            # print(f"ğŸ’­ å†³ç­–è®°å½•: {len(result['result']['decisions'])} æ¡")
        else:
            print("âŒ è´¨é‡é—¨ç¦æœªé€šè¿‡:")
            for error in result["errors"]:
                print(f"  - {error}")
            sys.exit(1)
        
        # æ˜¾ç¤ºæ‰§è¡Œæ‘˜è¦
        summary = orchestrator.get_execution_summary()
        print(f"\nğŸ“ˆ æ‰§è¡Œæ‘˜è¦:")
        print(f"  - å·²å®Œæˆé˜¶æ®µ: {summary['total_stages_executed']}")
        print(f"  - ä½¿ç”¨çš„ Agents: {', '.join(summary['agents_used'])}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_team_collaborate(args):
    """å¯åŠ¨å¤š Agent åä½œæ¨¡å¼æ‰§è¡Œä»»åŠ¡"""
    if not _agents_available:
        print("âŒ Agent ç³»ç»Ÿæœªå¯ç”¨ï¼Œè¯·ç¡®ä¿å·²å®‰è£…å®Œæ•´åŒ…", file=sys.stderr)
        sys.exit(1)
    
    try:
        engine, _, _ = _init_engine(args)
        workspace = Path(args.workspace or ".")
        
        goal = args.goal
        role_ids = getattr(args, 'roles', None)
        use_llm = getattr(args, 'use_llm', False)
        
        # åŠ è½½ LLM å®¢æˆ·ç«¯
        llm_client = _load_llm_client(workspace)
        
        # å¦‚æœä½¿ç”¨ --use-llm ä½†æœªé…ç½® LLM å®¢æˆ·ç«¯ï¼ŒæŠ›å‡ºé”™è¯¯
        if use_llm and not llm_client:
            error_msg = (
                "âŒ LLM client not configured. Please:\n"
                "  1. Set environment variable (e.g., OPENAI_API_KEY or ANTHROPIC_API_KEY)\n"
                "  2. Or create .workflow/config.yaml with llm configuration\n"
                "  3. Or remove --use-llm flag to use rule-based decomposition\n"
                "\n"
                "Example environment variables:\n"
                "  export OPENAI_API_KEY='your-api-key'\n"
                "  export ANTHROPIC_API_KEY='your-api-key'\n"
                "\n"
                "Example config file (.workflow/config.yaml):\n"
                "  llm:\n"
                "    provider: openai\n"
                "    api_key: your-api-key\n"
                "    model: gpt-4\n"
                "    base_url: https://api.openai.com/v1  # å¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰ç«¯ç‚¹"
            )
            print(error_msg, file=sys.stderr)
            raise WorkflowError("LLM client not configured but --use-llm flag is set")
        
        orchestrator = AgentOrchestrator(engine, llm_client=llm_client)
        
        print(f"\nğŸ¤ å¤š Agent åä½œæ¨¡å¼")
        print("=" * 60)
        print(f"ç›®æ ‡: {goal}")
        if role_ids:
            print(f"å‚ä¸è§’è‰²: {', '.join(role_ids)}")
        else:
            print(f"å‚ä¸è§’è‰²: æ‰€æœ‰å¯ç”¨è§’è‰²")
        print(f"ä»»åŠ¡åˆ†è§£: {'LLMæ™ºèƒ½åˆ†è§£' if use_llm else 'è§„åˆ™å¼•æ“åˆ†è§£'}")
        print()
        
        # æ‰§è¡Œåä½œ
        result = orchestrator.execute_with_collaboration(
            goal=goal,
            role_ids=role_ids,
            inputs=None,
            use_llm=use_llm
        )
        
        # æ˜¾ç¤ºç»“æœ
        print("\nâœ… åä½œæ‰§è¡Œå®Œæˆ")
        print("=" * 60)
        
        decomposition = result["decomposition"]
        print(f"\nğŸ“‹ ä»»åŠ¡åˆ†è§£:")
        print(f"  - æ€»ä»»åŠ¡æ•°: {len(decomposition.tasks)}")
        print(f"  - æ‰§è¡Œé¡ºåº: {' â†’ '.join(decomposition.execution_order)}")
        
        print(f"\nğŸ‘¥ å‚ä¸çš„ Agents:")
        for agent_id, agent_info in result["agents"].items():
            print(f"  - {agent_info['role']} ({agent_id})")
        
        summary = result["collaboration_summary"]
        print(f"\nğŸ“Š æ‰§è¡Œæ‘˜è¦:")
        print(f"  - å®Œæˆä»»åŠ¡: {summary['completed_tasks']}/{summary['total_tasks']}")
        print(f"  - å¤±è´¥ä»»åŠ¡: {summary['failed_tasks']}")
        print(f"  - æ´»è·ƒ Agents: {len(summary['active_agents'])}")
        
        # æ˜¾ç¤ºä»»åŠ¡ç»“æœ
        if result["task_results"]:
            print(f"\nğŸ“ ä»»åŠ¡ç»“æœ:")
            for task_id, task_result in result["task_results"].items():
                status_icon = "âœ…" if task_result["status"] == "completed" else "âŒ"
                print(f"  {status_icon} {task_id}: {task_result['status']}")
                if task_result.get("error"):
                    print(f"     é”™è¯¯: {task_result['error']}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_decompose_task(args):
    """åˆ†è§£ç›®æ ‡ä¸ºå­ä»»åŠ¡"""
    if not _agents_available:
        print("âŒ Agent ç³»ç»Ÿæœªå¯ç”¨ï¼Œè¯·ç¡®ä¿å·²å®‰è£…å®Œæ•´åŒ…", file=sys.stderr)
        sys.exit(1)
    
    try:
        engine, _, _ = _init_engine(args)
        workspace = Path(args.workspace or ".")
        from work_by_roles.core.task_decomposer import TaskDecomposer
        
        goal = args.goal
        role_ids = getattr(args, 'roles', None)
        use_llm = getattr(args, 'use_llm', False)
        output_json = getattr(args, 'json', False)
        
        # åŠ è½½ LLM å®¢æˆ·ç«¯
        llm_client = _load_llm_client(workspace)
        
        # å¦‚æœä½¿ç”¨ --use-llm ä½†æœªé…ç½® LLM å®¢æˆ·ç«¯ï¼ŒæŠ›å‡ºé”™è¯¯
        if use_llm and not llm_client:
            error_msg = (
                "âŒ LLM client not configured. Please:\n"
                "  1. Set environment variable (e.g., OPENAI_API_KEY or ANTHROPIC_API_KEY)\n"
                "  2. Or create .workflow/config.yaml with llm configuration\n"
                "  3. Or remove --use-llm flag to use rule-based decomposition\n"
                "\n"
                "Example environment variables:\n"
                "  export OPENAI_API_KEY='your-api-key'\n"
                "  export ANTHROPIC_API_KEY='your-api-key'\n"
                "\n"
                "Example config file (.workflow/config.yaml):\n"
                "  llm:\n"
                "    provider: openai\n"
                "    api_key: your-api-key\n"
                "    model: gpt-4\n"
                "    base_url: https://api.openai.com/v1  # å¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰ç«¯ç‚¹"
            )
            print(error_msg, file=sys.stderr)
            raise WorkflowError("LLM client not configured but --use-llm flag is set")
        
        # Get available roles
        if role_ids:
            available_roles = [
                engine.role_manager.get_role(role_id)
                for role_id in role_ids
                if engine.role_manager.get_role(role_id)
            ]
        else:
            available_roles = list(engine.role_manager.roles.values())
        
        # Create decomposer
        decomposer = TaskDecomposer(engine, llm_client)
        
        # Decompose
        decomposition = decomposer.decompose(goal, available_roles, None)
        
        if output_json:
            import json
            output = {
                "goal": goal,
                "tasks": [
                    {
                        "id": task.id,
                        "description": task.description,
                        "assigned_role": task.assigned_role,
                        "dependencies": task.dependencies,
                        "status": task.status,
                        "priority": task.priority
                    }
                    for task in decomposition.tasks
                ],
                "execution_order": decomposition.execution_order,
                "dependencies": decomposition.dependencies
            }
            print(json.dumps(output, indent=2, ensure_ascii=False))
        else:
            print(f"\nğŸ“‹ ä»»åŠ¡åˆ†è§£ç»“æœ")
            print("=" * 60)
            print(f"ç›®æ ‡: {goal}")
            print(f"\nä»»åŠ¡åˆ—è¡¨ ({len(decomposition.tasks)} ä¸ª):")
            
            for i, task in enumerate(decomposition.tasks, 1):
                deps_str = f" (ä¾èµ–: {', '.join(task.dependencies)})" if task.dependencies else ""
                print(f"\n{i}. {task.id}")
                print(f"   æè¿°: {task.description}")
                print(f"   è§’è‰²: {task.assigned_role}")
                print(f"   çŠ¶æ€: {task.status}{deps_str}")
                if task.priority > 0:
                    print(f"   ä¼˜å…ˆçº§: {task.priority}")
            
            print(f"\næ‰§è¡Œé¡ºåº:")
            print(f"  {' â†’ '.join(decomposition.execution_order)}")
            
            if decomposition.total_estimated_time:
                print(f"\né¢„è®¡æ€»æ—¶é—´: {decomposition.total_estimated_time:.1f} ç§’")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_generate_skill(args):
    """Generate a skill template"""
    try:
        from tools.generate_skill_template import build_skill_template, write_template

        output_file = Path(args.output) if args.output else Path(f"{args.skill_id}_skill.yaml")
        
        template = build_skill_template(
            args.skill_id,
            args.name
        )
        
        write_template(template, output_file)
        print(f"âœ… æŠ€èƒ½æ¨¡æ¿å·²ç”Ÿæˆ: {output_file}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_validate_skills(args):
    """Validate a skill library definition"""
    try:
        from tools.validate_skills import run_validation

        skill_file = Path(args.file)

        if not skill_file.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {skill_file}", file=sys.stderr)
            sys.exit(1)

        success, errors = run_validation(skill_file, quiet=args.quiet)
        if not success:
            for error in errors:
                print(f"  - {error}", file=sys.stderr)
            sys.exit(1)

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_list_skills(args):
    """List all loaded skills"""
    try:
        engine, _, _ = _init_engine(args)

        if not engine.role_manager.skill_library:
            print("âš ï¸ æœªåŠ è½½æŠ€èƒ½åº“ï¼Œè¯·ä½¿ç”¨ --skills æŒ‡å®š skills ç›®å½•")
            sys.exit(0)

        print("\næŠ€èƒ½åº“åˆ—è¡¨:")
        print("=" * 60)
        for skill_id, skill in engine.role_manager.skill_library.items():
            print(f"\næŠ€èƒ½: {skill.name}")
            print(f"  ID: {skill_id}")
            print(f"  æè¿°: {skill.description}")
            print(f"  ç»´åº¦: {', '.join(skill.dimensions)}")
            print(f"  å·¥å…·: {', '.join(skill.tools)}")
            print(f"  ç­‰çº§æ•°: {len(skill.levels)}")
            if skill.constraints:
                print(f"  çº¦æŸ: {', '.join(skill.constraints)}")

        if hasattr(engine.role_manager, 'skill_bundles') and engine.role_manager.skill_bundles:
            print("\næŠ€èƒ½åŒ… (Bundles):")
            print("-" * 60)
            for bundle_id, bundle in engine.role_manager.skill_bundles.items():
                print(f"\næŠ€èƒ½åŒ…: {bundle.name}")
                print(f"  ID: {bundle_id}")
                print(f"  æè¿°: {bundle.description}")
                print(f"  åŒ…å«æŠ€èƒ½:")
                for s in bundle.skills:
                    print(f"    - {s.skill_id} (ç­‰çº§â‰¥{s.min_level})")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_interactive_skill(args):
    """Interactive skill wizard"""
    try:
        from tools.interactive_skill_creator import interactive_main

        interactive_main()
    except KeyboardInterrupt:
        print("\n\nâŒ å·²å–æ¶ˆ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_skill_trace(args):
    """View skill execution history"""
    try:
        engine, _, _ = _init_engine(args)
        
        if not hasattr(engine, 'create_orchestrator'):
            # Create orchestrator if not available
            from work_by_roles.core.engine import AgentOrchestrator
            orchestrator = AgentOrchestrator(engine)
        else:
            orchestrator = engine.create_orchestrator()
        
        skill_id = args.skill_id
        history = orchestrator.execution_tracker.get_skill_history(skill_id)
        
        if not history:
            print(f"âš ï¸ æŠ€èƒ½ '{skill_id}' æ²¡æœ‰æ‰§è¡Œå†å²")
            sys.exit(0)
        
        print(f"\næŠ€èƒ½æ‰§è¡Œå†å²: {skill_id}")
        print("=" * 60)
        for i, execution in enumerate(history, 1):
            print(f"\næ‰§è¡Œ #{i}:")
            print(f"  çŠ¶æ€: {execution.status}")
            print(f"  æ‰§è¡Œæ—¶é—´: {execution.execution_time:.2f}s")
            print(f"  æ—¶é—´æˆ³: {execution.timestamp}")
            if execution.retry_count > 0:
                print(f"  é‡è¯•æ¬¡æ•°: {execution.retry_count}")
            if execution.error_type:
                print(f"  é”™è¯¯ç±»å‹: {execution.error_type}")
            if execution.error_message:
                print(f"  é”™è¯¯æ¶ˆæ¯: {execution.error_message}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_skill_stats(args):
    """View skill execution statistics"""
    try:
        engine, _, _ = _init_engine(args)
        
        if not hasattr(engine, 'create_orchestrator'):
            from work_by_roles.core.engine import AgentOrchestrator
            orchestrator = AgentOrchestrator(engine)
        else:
            orchestrator = engine.create_orchestrator()
        
        stats = orchestrator.execution_tracker.get_statistics()
        
        print("\næŠ€èƒ½æ‰§è¡Œç»Ÿè®¡")
        print("=" * 60)
        print(f"æ€»æ‰§è¡Œæ¬¡æ•°: {stats['total_executions']}")
        print(f"å”¯ä¸€æŠ€èƒ½æ•°: {stats['unique_skills']}")
        print("\nå„æŠ€èƒ½ç»Ÿè®¡:")
        print("-" * 60)
        
        for skill_id, skill_stats in stats['skills'].items():
            print(f"\n{skill_id}:")
            print(f"  æ€»æ‰§è¡Œæ¬¡æ•°: {skill_stats['total_executions']}")
            print(f"  æˆåŠŸç‡: {skill_stats['success_rate']:.2%}")
            print(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {skill_stats['avg_execution_time']:.2f}s")
            print(f"  æ€»é‡è¯•æ¬¡æ•°: {skill_stats['total_retries']}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_export_trace(args):
    """Export execution trace data"""
    try:
        engine, _, _ = _init_engine(args)
        
        if not hasattr(engine, 'create_orchestrator'):
            from work_by_roles.core.engine import AgentOrchestrator
            orchestrator = AgentOrchestrator(engine)
        else:
            orchestrator = engine.create_orchestrator()
        
        format_type = args.format or "json"
        trace_data = orchestrator.execution_tracker.export_trace(format_type)
        
        if args.output:
            output_file = Path(args.output)
            output_file.write_text(trace_data, encoding='utf-8')
            print(f"âœ… è¿½è¸ªæ•°æ®å·²å¯¼å‡ºåˆ°: {output_file}")
        else:
            print(trace_data)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_benchmark_skill(args):
    """Benchmark a skill with test cases"""
    try:
        engine, _, _ = _init_engine(args)
        
        if not hasattr(engine, 'create_orchestrator'):
            from work_by_roles.core.engine import AgentOrchestrator, SkillBenchmark
            orchestrator = AgentOrchestrator(engine)
        else:
            orchestrator = engine.create_orchestrator()
            from work_by_roles.core.engine import SkillBenchmark
        
        benchmark = SkillBenchmark(engine, orchestrator)
        
        # Load test cases
        test_cases_file = Path(args.test_cases)
        if not test_cases_file.exists():
            print(f"âŒ æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {test_cases_file}", file=sys.stderr)
            sys.exit(1)
        
        import yaml
        with test_cases_file.open('r', encoding='utf-8') as f:
            test_data = yaml.safe_load(f)
        
        test_cases = test_data.get('test_cases', [])
        if not test_cases:
            print("âš ï¸ æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ä¸ºç©º", file=sys.stderr)
            sys.exit(1)
        
        # Check if multi-model comparison requested (P2 optimization)
        if args.models:
            from work_by_roles.core.skill_benchmark import SkillBenchmark
            benchmark = SkillBenchmark(engine, orchestrator)
            results = benchmark.benchmark_with_models(args.skill_id, args.models, test_cases)
            print(f"\nå¤šæ¨¡å‹åŸºå‡†æµ‹è¯•ç»“æœ: {args.skill_id}")
            print("=" * 60)
            for model_name, model_results in results['models'].items():
                if 'error' in model_results:
                    print(f"{model_name}: âŒ {model_results['error']}")
                else:
                    print(f"{model_name}:")
                    print(f"  æˆåŠŸç‡: {model_results['success_rate']:.2%}")
                    print(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {model_results['avg_execution_time']:.2f}s")
            if results['best_model']:
                print(f"\næœ€ä½³æ¨¡å‹: {results['best_model']}")
        else:
            results = benchmark.benchmark_skill(args.skill_id, test_cases)
            
            if args.report:
                report = benchmark.generate_report(results)
                print(report)
            else:
                print(f"\nåŸºå‡†æµ‹è¯•ç»“æœ: {args.skill_id}")
                print("=" * 60)
                print(f"æ€»æµ‹è¯•æ•°: {results['total_tests']}")
                print(f"æˆåŠŸæµ‹è¯•æ•°: {results['successful_tests']}")
                print(f"æˆåŠŸç‡: {results['success_rate']:.2%}")
                print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {results['avg_execution_time']:.2f}s")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_skill_test(args):
    """Test a skill with input and expected output/schema"""
    try:
        engine, _, _ = _init_engine(args)
        
        if not hasattr(engine, 'create_orchestrator'):
            from work_by_roles.core.agent_orchestrator import AgentOrchestrator
            from work_by_roles.core.skill_benchmark import SkillBenchmark
            orchestrator = AgentOrchestrator(engine)
        else:
            orchestrator = engine.create_orchestrator()
            from work_by_roles.core.skill_benchmark import SkillBenchmark
        
        benchmark = SkillBenchmark(engine, orchestrator)
        
        # Load input data
        input_data = {}
        if args.input:
            input_file = Path(args.input)
            if input_file.exists():
                import json
                import yaml
                with input_file.open('r', encoding='utf-8') as f:
                    if input_file.suffix in ['.yaml', '.yml']:
                        input_data = yaml.safe_load(f) or {}
                    else:
                        input_data = json.load(f)
            else:
                print(f"âš ï¸ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}", file=sys.stderr)
        
        # Load expected output if provided
        expected_output = None
        if args.expect:
            expect_file = Path(args.expect)
            if expect_file.exists():
                import json
                import yaml
                with expect_file.open('r', encoding='utf-8') as f:
                    if expect_file.suffix in ['.yaml', '.yml']:
                        expected_output = yaml.safe_load(f)
                    else:
                        expected_output = json.load(f)
            else:
                print(f"âš ï¸ æœŸæœ›è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {expect_file}", file=sys.stderr)
        
        # Load expected schema if provided
        expected_schema = None
        if args.schema:
            schema_file = Path(args.schema)
            if schema_file.exists():
                import json
                import yaml
                with schema_file.open('r', encoding='utf-8') as f:
                    if schema_file.suffix in ['.yaml', '.yml']:
                        expected_schema = yaml.safe_load(f)
                    else:
                        expected_schema = json.load(f)
            else:
                print(f"âš ï¸ Schema æ–‡ä»¶ä¸å­˜åœ¨: {schema_file}", file=sys.stderr)
        
        # Determine snapshot file path
        snapshot_file = None
        if args.snapshot:
            snapshot_file = Path(args.snapshot)
        
        # Run test
        result = benchmark.test_skill(
            args.skill_id,
            input_data,
            expected_output,
            expected_schema,
            snapshot_file
        )
        
        # Print results
        print(f"\næŠ€èƒ½æµ‹è¯•ç»“æœ: {args.skill_id}")
        print("=" * 60)
        print(f"æ‰§è¡ŒæˆåŠŸ: {'âœ…' if result['success'] else 'âŒ'}")
        print(f"æ‰§è¡Œæ—¶é—´: {result['execution_time']:.2f}s")
        
        if 'error' in result:
            print(f"é”™è¯¯: {result['error']}")
        
        validation = result.get('validation', {})
        if validation:
            print(f"\néªŒè¯ç»“æœ:")
            print(f"  æ•´ä½“æœ‰æ•ˆ: {'âœ…' if validation['valid'] else 'âŒ'}")
            if 'snapshot_match' in validation:
                print(f"  Snapshot åŒ¹é…: {'âœ…' if validation['snapshot_match'] else 'âŒ'}")
            if 'schema_valid' in validation:
                print(f"  Schema éªŒè¯: {'âœ…' if validation['schema_valid'] else 'âŒ'}")
            
            if validation.get('differences'):
                print(f"\nå·®å¼‚:")
                for diff in validation['differences']:
                    print(f"  - {diff}")
            
            if validation.get('schema_errors'):
                print(f"\nSchema é”™è¯¯:")
                for error in validation['schema_errors']:
                    print(f"  - {error}")
        
        if result.get('snapshot_saved'):
            print(f"\nâœ… Snapshot å·²ä¿å­˜åˆ°: {snapshot_file}")
        
        if not result['success']:
            sys.exit(1)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_replay_workflow(args):
    """Replay workflow from event log"""
    try:
        engine, _, _ = _init_engine(args)
        
        if not engine.executor:
            print("âŒ å·¥ä½œæµæœªåˆå§‹åŒ–", file=sys.stderr)
            sys.exit(1)
        
        # Load event log
        event_log_file = Path(args.event_log)
        if not event_log_file.exists():
            print(f"âŒ äº‹ä»¶æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {event_log_file}", file=sys.stderr)
            sys.exit(1)
        
        from work_by_roles.core.workflow_events import WorkflowEvent
        import json
        import yaml
        
        with event_log_file.open('r', encoding='utf-8') as f:
            if event_log_file.suffix in ['.yaml', '.yml']:
                events_data = yaml.safe_load(f)
            else:
                events_data = json.load(f)
        
        events = [WorkflowEvent.from_dict(e) for e in events_data]
        
        # Replay events
        engine.executor.replay_from_events(events)
        
        print(f"âœ… å·²å›æ”¾ {len(events)} ä¸ªäº‹ä»¶")
        print(f"å½“å‰é˜¶æ®µ: {engine.executor.state.current_stage}")
        print(f"å·²å®Œæˆé˜¶æ®µ: {', '.join(engine.executor.state.completed_stages)}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_dry_run_stage(args):
    """Dry-run a stage without executing skills"""
    try:
        engine, _, _ = _init_engine(args)
        
        if not engine.executor:
            print("âŒ å·¥ä½œæµæœªåˆå§‹åŒ–", file=sys.stderr)
            sys.exit(1)
        
        result = engine.executor.dry_run(args.stage_id)
        
        print(f"\né˜¶æ®µå¹²è¿è¡Œç»“æœ: {result['stage_name']}")
        print("=" * 60)
        print(f"å¯ä»¥è½¬æ¢: {'âœ…' if result['can_transition'] else 'âŒ'}")
        print(f"å‰ææ¡ä»¶æ»¡è¶³: {'âœ…' if result['prerequisites_met'] else 'âŒ'}")
        
        if result['errors']:
            print(f"\né”™è¯¯:")
            for error in result['errors']:
                print(f"  - {error}")
        
        print(f"\nå½“å‰çŠ¶æ€:")
        print(f"  å½“å‰é˜¶æ®µ: {result['current_state']['current_stage'] or 'None'}")
        print(f"  å·²å®Œæˆé˜¶æ®µ: {', '.join(result['current_state']['completed_stages']) or 'None'}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_import_sop(args):
    """Import SOP document and generate configurations"""
    try:
        from work_by_roles.core.sop_importer import SOPImporter
        
        sop_file = Path(args.sop_file)
        if not sop_file.exists():
            print(f"âŒ SOP æ–‡ä»¶ä¸å­˜åœ¨: {sop_file}", file=sys.stderr)
            sys.exit(1)
        
        output_dir = Path(args.output) if args.output else Path.cwd() / ".workflow"
        
        importer = SOPImporter()
        generated_files = importer.generate_config_files(
            sop_file,
            output_dir,
            overwrite=args.overwrite
        )
        
        print(f"\nâœ… SOP å¯¼å…¥å®Œæˆ")
        print("=" * 60)
        for config_type, file_path in generated_files.items():
            print(f"  {config_type}: {file_path}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


# ============================================================================
# Skill Workflow Commands - å¤šæŠ€èƒ½å·¥ä½œæµå‘½ä»¤
# ============================================================================

def cmd_list_skill_workflows(args):
    """åˆ—å‡ºæ‰€æœ‰æŠ€èƒ½å·¥ä½œæµ"""
    try:
        engine, _, _ = _init_engine(args)
        orchestrator = AgentOrchestrator(engine)
        
        workflows = orchestrator.list_skill_workflows()
        
        if not workflows:
            print("âš ï¸ æœªå®šä¹‰ä»»ä½•æŠ€èƒ½å·¥ä½œæµ")
            print("   åœ¨ skills ç›®å½•ä¸­çš„ Skill.md æ–‡ä»¶ä¸­æ·»åŠ  skill_workflows éƒ¨åˆ†")
            sys.exit(0)
        
        print("\næŠ€èƒ½å·¥ä½œæµåˆ—è¡¨:")
        print("=" * 60)
        
        for wf in workflows:
            print(f"\nğŸ“‹ {wf['name']} (ID: {wf['id']})")
            print(f"   æè¿°: {wf['description']}")
            print(f"   æ­¥éª¤æ•°: {wf['steps']}")
            trigger = wf['trigger']
            if trigger['stage_id']:
                print(f"   è§¦å‘: é˜¶æ®µ '{trigger['stage_id']}' ({trigger['condition']})")
            else:
                print(f"   è§¦å‘: {trigger['condition']}")
        
        print("\n" + "=" * 60)
        print("ğŸ’¡ ä½¿ç”¨ 'workflow skill-workflow-detail <id>' æŸ¥çœ‹è¯¦æƒ…")
        print("ğŸ’¡ ä½¿ç”¨ 'workflow run-skill-workflow <id>' æ‰§è¡Œå·¥ä½œæµ")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_skill_workflow_detail(args):
    """æ˜¾ç¤ºæŠ€èƒ½å·¥ä½œæµè¯¦æƒ…"""
    try:
        engine, _, _ = _init_engine(args)
        orchestrator = AgentOrchestrator(engine)
        
        workflow_id = args.workflow_id
        details = orchestrator.get_workflow_details(workflow_id)
        
        if not details:
            print(f"âŒ å·¥ä½œæµ '{workflow_id}' ä¸å­˜åœ¨", file=sys.stderr)
            sys.exit(1)
        
        print(f"\nğŸ“‹ æŠ€èƒ½å·¥ä½œæµè¯¦æƒ…: {details['name']}")
        print("=" * 60)
        print(f"ID: {details['id']}")
        print(f"æè¿°: {details['description']}")
        
        # Trigger
        trigger = details['trigger']
        print(f"\nè§¦å‘æ¡ä»¶:")
        print(f"  - è§¦å‘æ–¹å¼: {trigger['condition']}")
        if trigger['stage_id']:
            print(f"  - è§¦å‘é˜¶æ®µ: {trigger['stage_id']}")
        
        # Config
        config = details['config']
        print(f"\né…ç½®:")
        print(f"  - æœ€å¤§å¹¶è¡Œ: {config['max_parallel']}")
        print(f"  - å¿«é€Ÿå¤±è´¥: {'æ˜¯' if config['fail_fast'] else 'å¦'}")
        print(f"  - é‡è¯•å¤±è´¥æ­¥éª¤: {'æ˜¯' if config['retry_failed_steps'] else 'å¦'}")
        print(f"  - è¶…æ—¶: {config['timeout']}ç§’")
        
        # Steps
        print(f"\næ­¥éª¤ ({len(details['steps'])} ä¸ª):")
        print("-" * 60)
        for step in details['steps']:
            deps = f" [ä¾èµ–: {', '.join(step['depends_on'])}]" if step['depends_on'] else ""
            print(f"\n  {step['order']}. {step['name']} (ID: {step['step_id']}){deps}")
            print(f"     æŠ€èƒ½: {step['skill_id']}")
            if step['inputs']:
                print(f"     è¾“å…¥: {list(step['inputs'].keys())}")
            if step['outputs']:
                print(f"     è¾“å‡º: {step['outputs']}")
        
        # Execution order
        print(f"\næ‰§è¡Œé¡ºåº:")
        print(f"  {' â†’ '.join(details['execution_order'])}")
        
        # Final outputs
        if details['outputs']:
            print(f"\næœ€ç»ˆè¾“å‡ºæ˜ å°„:")
            for key, ref in details['outputs'].items():
                print(f"  - {key}: {ref}")
        
        print("\n" + "=" * 60)
        print(f"ğŸ’¡ è¿è¡Œ: workflow run-skill-workflow {workflow_id} --inputs '{{\"goal\": \"...\"}}'")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_run_skill_workflow(args):
    """æ‰§è¡ŒæŠ€èƒ½å·¥ä½œæµ"""
    try:
        engine, _, _ = _init_engine(args)
        orchestrator = AgentOrchestrator(engine)
        
        workflow_id = args.workflow_id
        
        # Parse inputs
        inputs = {}
        if args.inputs:
            try:
                inputs = json.loads(args.inputs)
            except json.JSONDecodeError:
                print(f"âŒ æ— æ•ˆçš„ JSON è¾“å…¥: {args.inputs}", file=sys.stderr)
                sys.exit(1)
        
        # Get optional context
        stage_id = args.stage
        role_id = args.role
        
        print(f"\nğŸš€ æ‰§è¡ŒæŠ€èƒ½å·¥ä½œæµ: {workflow_id}")
        print("=" * 60)
        print(f"è¾“å…¥: {json.dumps(inputs, ensure_ascii=False, indent=2)}")
        if stage_id:
            print(f"é˜¶æ®µä¸Šä¸‹æ–‡: {stage_id}")
        if role_id:
            print(f"è§’è‰²ä¸Šä¸‹æ–‡: {role_id}")
        print("-" * 60)
        
        # Execute workflow
        result = orchestrator.execute_skill_workflow(
            workflow_id=workflow_id,
            inputs=inputs,
            stage_id=stage_id,
            role_id=role_id
        )
        
        # Display results
        print(f"\næ‰§è¡ŒçŠ¶æ€: {result.status.upper()}")
        print(f"æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
        
        # Step results
        print(f"\næ­¥éª¤ç»“æœ:")
        for step_id, step_result in result.step_results.items():
            status_icon = "âœ…" if step_result['status'] == 'completed' else (
                "âŒ" if step_result['status'] == 'failed' else "â­ï¸"
            )
            print(f"  {status_icon} {step_id}: {step_result['status']} ({step_result['execution_time']:.2f}s)")
            if step_result.get('error'):
                print(f"      é”™è¯¯: {step_result['error']}")
        
        # Errors
        if result.errors:
            print(f"\nâŒ é”™è¯¯:")
            for error in result.errors:
                print(f"  - {error}")
        
        # Final outputs
        if result.outputs:
            print(f"\nğŸ“¤ æœ€ç»ˆè¾“å‡º:")
            for key, value in result.outputs.items():
                print(f"  - {key}: {value}")
        
        # Summary
        print("\n" + "=" * 60)
        if result.status == "completed":
            print("âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ!")
        elif result.status == "failed":
            print("âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥")
            sys.exit(1)
        else:
            print(f"âš ï¸ å·¥ä½œæµçŠ¶æ€: {result.status}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_show_progress(args):
    """æ˜¾ç¤ºå·¥ä½œæµè¿›åº¦"""
    try:
        engine, _, _ = _init_engine(args)
        from work_by_roles.core.immersive_workflow_display import ImmersiveWorkflowDisplay
        display = ImmersiveWorkflowDisplay(engine.workspace_path)
        print(display.display_workflow_status())
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_show_doc(args):
    """æ˜¾ç¤ºæ–‡æ¡£å†…å®¹"""
    try:
        engine, _, _ = _init_engine(args)
        from work_by_roles.core.immersive_workflow_display import ImmersiveWorkflowDisplay
        display = ImmersiveWorkflowDisplay(engine.workspace_path)
        doc_name = args.document
        full = getattr(args, 'full', False)
        print(display.doc_preview.format_document_for_display(doc_name, show_full=full))
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_list_docs(args):
    """åˆ—å‡ºæ‰€æœ‰ç”Ÿæˆçš„æ–‡æ¡£"""
    try:
        engine, _, _ = _init_engine(args)
        from work_by_roles.core.immersive_workflow_display import ImmersiveWorkflowDisplay
        display = ImmersiveWorkflowDisplay(engine.workspace_path)
        docs = display.doc_preview.list_all_documents()
        
        if not docs:
            print("ğŸ“š **ç”Ÿæˆçš„æ–‡æ¡£**\n\næš‚æ— ç”Ÿæˆçš„æ–‡æ¡£")
            return
        
        print("ğŸ“š **ç”Ÿæˆçš„æ–‡æ¡£**\n")
        for doc in docs:
            print(f"ğŸ“„ **{doc['name']}**")
            print(f"   - è·¯å¾„: `{doc['path']}`")
            print(f"   - å¤§å°: {doc['size_chars']} å­—ç¬¦, {doc['lines']} è¡Œ")
            print(f"   - æœ€åä¿®æ”¹: {doc['last_modified'].strftime('%Y-%m-%d %H:%M:%S')}")
            print()
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_checkpoint_create(args):
    """åˆ›å»ºæ£€æŸ¥ç‚¹"""
    try:
        engine, _, _ = _init_engine(args)
        
        if not engine.workflow:
            print("âŒ æœªåŠ è½½å·¥ä½œæµ", file=sys.stderr)
            sys.exit(1)
        
        checkpoint = engine.create_checkpoint(
            name=args.name,
            description=args.description,
            stage_id=args.stage
        )
        
        print(f"âœ… æ£€æŸ¥ç‚¹å·²åˆ›å»º: {checkpoint.checkpoint_id}")
        print(f"   åç§°: {checkpoint.name}")
        if checkpoint.description:
            print(f"   æè¿°: {checkpoint.description}")
        print(f"   å·¥ä½œæµ: {checkpoint.workflow_id}")
        if checkpoint.stage_id:
            print(f"   é˜¶æ®µ: {checkpoint.stage_id}")
        print(f"   åˆ›å»ºæ—¶é—´: {checkpoint.created_at.strftime('%Y-%m-%d %H:%M:%S')}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_checkpoint_list(args):
    """åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹"""
    try:
        engine, _, _ = _init_engine(args)
        from work_by_roles.core.checkpoint_manager import CheckpointManager
        
        checkpoint_manager = CheckpointManager(engine.workspace_path)
        workflow_id = getattr(args, 'workflow', None)
        
        if engine.workflow and not workflow_id:
            workflow_id = engine.workflow.id
        
        checkpoints = checkpoint_manager.list_checkpoints(workflow_id)
        
        if not checkpoints:
            print("ğŸ“‹ **æ£€æŸ¥ç‚¹åˆ—è¡¨**\n\næš‚æ— æ£€æŸ¥ç‚¹")
            return
        
        print("ğŸ“‹ **æ£€æŸ¥ç‚¹åˆ—è¡¨**\n")
        for cp in checkpoints:
            print(f"ğŸ”– **{cp.name}** (`{cp.checkpoint_id}`)")
            if cp.description:
                print(f"   - æè¿°: {cp.description}")
            print(f"   - å·¥ä½œæµ: {cp.workflow_id}")
            if cp.stage_id:
                print(f"   - é˜¶æ®µ: {cp.stage_id}")
            print(f"   - åˆ›å»ºæ—¶é—´: {cp.created_at.strftime('%Y-%m-%d %H:%M:%S')}")
            if cp.output_files:
                print(f"   - è¾“å‡ºæ–‡ä»¶: {len(cp.output_files)} ä¸ª")
            print()
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_checkpoint_restore(args):
    """ä»æ£€æŸ¥ç‚¹æ¢å¤"""
    try:
        engine, _, _ = _init_engine(args)
        from work_by_roles.core.checkpoint_manager import CheckpointManager
        from work_by_roles.core.immersive_workflow_display import ImmersiveWorkflowDisplay
        
        checkpoint_manager = CheckpointManager(engine.workspace_path)
        checkpoint_id = args.checkpoint_id
        
        # Get checkpoint info
        checkpoint = checkpoint_manager.get_checkpoint(checkpoint_id)
        if not checkpoint:
            print(f"âŒ æ£€æŸ¥ç‚¹ '{checkpoint_id}' ä¸å­˜åœ¨", file=sys.stderr)
            sys.exit(1)
        
        print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤: {checkpoint.name}")
        print(f"   å·¥ä½œæµ: {checkpoint.workflow_id}")
        if checkpoint.stage_id:
            print(f"   é˜¶æ®µ: {checkpoint.stage_id}")
        print(f"   åˆ›å»ºæ—¶é—´: {checkpoint.created_at.strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        # Restore with progress manager if available
        progress_manager = None
        try:
            display = ImmersiveWorkflowDisplay(engine.workspace_path)
            progress_manager = display.progress_manager
        except Exception:
            pass
        
        result = checkpoint_manager.restore_from_checkpoint(
            checkpoint_id=checkpoint_id,
            engine=engine,
            progress_manager=progress_manager
        )
        
        print("âœ… æ£€æŸ¥ç‚¹æ¢å¤æˆåŠŸ")
        print(f"   æ‰§è¡ŒçŠ¶æ€: {'å·²æ¢å¤' if result['execution_state_restored'] else 'æœªæ¢å¤'}")
        print(f"   è¿›åº¦: {'å·²æ¢å¤' if result['progress_restored'] else 'æœªæ¢å¤'}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_checkpoint_delete(args):
    """åˆ é™¤æ£€æŸ¥ç‚¹"""
    try:
        engine, _, _ = _init_engine(args)
        from work_by_roles.core.checkpoint_manager import CheckpointManager
        
        checkpoint_manager = CheckpointManager(engine.workspace_path)
        checkpoint_id = args.checkpoint_id
        
        checkpoint = checkpoint_manager.get_checkpoint(checkpoint_id)
        if not checkpoint:
            print(f"âŒ æ£€æŸ¥ç‚¹ '{checkpoint_id}' ä¸å­˜åœ¨", file=sys.stderr)
            sys.exit(1)
        
        deleted = checkpoint_manager.delete_checkpoint(checkpoint_id)
        if deleted:
            print(f"âœ… æ£€æŸ¥ç‚¹ '{checkpoint_id}' å·²åˆ é™¤")
        else:
            print(f"âš ï¸  æ£€æŸ¥ç‚¹ '{checkpoint_id}' åˆ é™¤å¤±è´¥", file=sys.stderr)
            sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_checkpoint_info(args):
    """æ˜¾ç¤ºæ£€æŸ¥ç‚¹è¯¦æƒ…"""
    try:
        engine, _, _ = _init_engine(args)
        from work_by_roles.core.checkpoint_manager import CheckpointManager
        
        checkpoint_manager = CheckpointManager(engine.workspace_path)
        checkpoint_id = args.checkpoint_id
        
        checkpoint = checkpoint_manager.get_checkpoint(checkpoint_id)
        if not checkpoint:
            print(f"âŒ æ£€æŸ¥ç‚¹ '{checkpoint_id}' ä¸å­˜åœ¨", file=sys.stderr)
            sys.exit(1)
        
        print("ğŸ“‹ **æ£€æŸ¥ç‚¹è¯¦æƒ…**\n")
        print(f"**ID**: `{checkpoint.checkpoint_id}`")
        print(f"**åç§°**: {checkpoint.name}")
        if checkpoint.description:
            print(f"**æè¿°**: {checkpoint.description}")
        print(f"**å·¥ä½œæµ**: {checkpoint.workflow_id}")
        if checkpoint.stage_id:
            print(f"**é˜¶æ®µ**: {checkpoint.stage_id}")
        print(f"**åˆ›å»ºæ—¶é—´**: {checkpoint.created_at.strftime('%Y-%m-%d %H:%M:%S')}")
        
        if checkpoint.execution_state:
            print(f"\n**æ‰§è¡ŒçŠ¶æ€**:")
            print(f"  - å½“å‰é˜¶æ®µ: {checkpoint.execution_state.current_stage or 'æ— '}")
            print(f"  - å½“å‰è§’è‰²: {checkpoint.execution_state.current_role or 'æ— '}")
            print(f"  - å·²å®Œæˆé˜¶æ®µ: {len(checkpoint.execution_state.completed_stages)} ä¸ª")
        
        if checkpoint.progress_data:
            print(f"\n**è¿›åº¦**:")
            progress_pct = checkpoint.progress_data.get('overall_progress', 0.0) * 100
            print(f"  - æ€»ä½“è¿›åº¦: {progress_pct:.1f}%")
            print(f"  - é˜¶æ®µæ•°: {len(checkpoint.progress_data.get('stages', []))}")
        
        if checkpoint.output_files:
            print(f"\n**è¾“å‡ºæ–‡ä»¶**: {len(checkpoint.output_files)} ä¸ª")
            for file in checkpoint.output_files[:5]:
                print(f"  - {file}")
            if len(checkpoint.output_files) > 5:
                print(f"  ... è¿˜æœ‰ {len(checkpoint.output_files) - 5} ä¸ª")
        
        if checkpoint.metadata:
            print(f"\n**å…ƒæ•°æ®**:")
            for key, value in checkpoint.metadata.items():
                print(f"  - {key}: {value}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_skill_workflow_graph(args):
    """ç”ŸæˆæŠ€èƒ½å·¥ä½œæµçš„ä¾èµ–å›¾"""
    try:
        engine, _, _ = _init_engine(args)
        orchestrator = AgentOrchestrator(engine)
        
        workflow_id = args.workflow_id
        workflow = orchestrator.get_skill_workflow(workflow_id)
        
        if not workflow:
            print(f"âŒ å·¥ä½œæµ '{workflow_id}' ä¸å­˜åœ¨", file=sys.stderr)
            sys.exit(1)
        
        # Generate Mermaid graph
        mermaid_lines = [
            "```mermaid",
            "graph TD",
            f"    subgraph {workflow.name}",
        ]
        
        # Add nodes
        for step in workflow.steps:
            skill = engine.role_manager.skill_library.get(step.skill_id)
            skill_name = skill.name if skill else step.skill_id
            mermaid_lines.append(f"        {step.step_id}[\"{step.name}<br/><small>{skill_name}</small>\"]")
        
        mermaid_lines.append("    end")
        
        # Add edges
        for step in workflow.steps:
            for dep in step.depends_on:
                mermaid_lines.append(f"    {dep} --> {step.step_id}")
        
        # Styling
        mermaid_lines.append("")
        mermaid_lines.append("    classDef default fill:#f9f,stroke:#333,stroke-width:2px;")
        mermaid_lines.append("```")
        
        mermaid_code = "\n".join(mermaid_lines)
        
        if args.output:
            output_file = Path(args.output)
            if args.format == "html":
                html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Skill Workflow: {workflow.name}</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({{startOnLoad:true}});</script>
    <style>
        body {{ font-family: sans-serif; margin: 2em; }}
        h1 {{ color: #333; }}
    </style>
</head>
<body>
    <h1>{workflow.name}</h1>
    <p>{workflow.description}</p>
    <div class="mermaid">
{mermaid_code.replace('```mermaid', '').replace('```', '')}
    </div>
</body>
</html>"""
                output_file.write_text(html_content, encoding='utf-8')
            else:
                output_file.write_text(mermaid_code, encoding='utf-8')
            print(f"âœ… å›¾è¡¨å·²ä¿å­˜åˆ°: {output_file}")
        else:
            print(mermaid_code)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def _check_required_outputs_for_stage(stage, workspace_path: Path, workflow_id: Optional[str] = None) -> List[Tuple[str, Path]]:
    """
    Check if all required outputs exist for a stage.
    
    Args:
        stage: Stage definition
        workspace_path: Workspace root path
        workflow_id: Optional workflow ID (defaults to "default" if not provided)
        
    Returns:
        List of tuples (output_name, output_path) for missing required outputs
    """
    missing = []
    if not stage.outputs:
        return missing
    
    # Get workflow_id
    workflow_id = workflow_id or "default"
    
    for output in stage.outputs:
        if not output.required:
            continue
        
        # Get output path using unified path calculation
        if output.type in ("document", "report"):
            # All document and report types go to .workflow/outputs/{workflow_id}/{stage_id}/
            output_path = workspace_path / ".workflow" / "outputs" / workflow_id / stage.id / output.name
        else:
            # Code, tests, and other types go to workspace root
            output_path = workspace_path / output.name
        
        if not output_path.exists():
            missing.append((output.name, output_path))
    
    return missing


def cmd_wfauto(args):
    """
    ä¸€é”®è·‘å®Œæ•´å·¥ä½œæµï¼ˆé¡ºåºæ‰§è¡Œæ‰€æœ‰é˜¶æ®µï¼‰ã€‚
    æ”¯æŒæ™ºèƒ½è·¯ç”±æ¨¡å¼ï¼šæ ¹æ®ç”¨æˆ·è¾“å…¥è‡ªåŠ¨è¯†åˆ«éœ€è¦æ‰§è¡Œçš„é˜¶æ®µã€‚
    
    è¡Œä¸ºï¼š
      1) æ¯æ¬¡æ‰§è¡Œå‰è‡ªåŠ¨é‡ç½®çŠ¶æ€ï¼ˆç¡®ä¿æ¯æ¬¡æ‰§è¡Œéƒ½æ˜¯ç‹¬ç«‹çš„ï¼‰
      2) å¦‚æœæä¾›äº† --intent å‚æ•°ï¼Œè¿›è¡Œæ„å›¾è¯†åˆ«
      3) ä¾æ¬¡ start æ¯ä¸ªé˜¶æ®µï¼ˆä½¿ç”¨é˜¶æ®µå£°æ˜çš„ roleï¼‰
      4) ä¾æ¬¡ complete æ¯ä¸ªé˜¶æ®µï¼ˆæ‰§è¡Œè´¨é‡é—¨ç¦ï¼‰
      5) å·²å®Œæˆé˜¶æ®µè‡ªåŠ¨è·³è¿‡ï¼ˆä½†åœ¨é‡ç½®åä¸ä¼šå‘ç”Ÿï¼‰
    """
    # Initialize failed stages tracking
    failed_stages = []
    
    try:
        engine, _, _ = _init_engine(args)
        workspace = Path(args.workspace or ".")
        
        # åŠ è½½ LLM å®¢æˆ·ç«¯
        llm_client = _load_llm_client(workspace)
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ LLM
        use_llm = getattr(args, 'use_llm', False)
        if use_llm and not llm_client:
            error_msg = (
                "âŒ LLM client not configured. Please:\n"
                "  1. Set environment variable (e.g., OPENAI_API_KEY or ANTHROPIC_API_KEY)\n"
                "  2. Or create .workflow/config.yaml with llm configuration\n"
                "  3. Or remove --use-llm flag to use lightweight mode\n"
                "\n"
                "Example environment variables:\n"
                "  export OPENAI_API_KEY='your-api-key'\n"
                "  export ANTHROPIC_API_KEY='your-api-key'\n"
                "\n"
                "Example config file (.workflow/config.yaml):\n"
                "  llm:\n"
                "    provider: openai\n"
                "    api_key: your-api-key\n"
                "    model: gpt-4\n"
                "    base_url: https://api.openai.com/v1  # å¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰ç«¯ç‚¹"
            )
            print(error_msg, file=sys.stderr)
            raise WorkflowError("LLM client not configured but --use-llm flag is set")
        
        if not engine.workflow:
            print("âŒ æœªåŠ è½½å·¥ä½œæµï¼Œæ£€æŸ¥ workflow æ–‡ä»¶é…ç½®", file=sys.stderr)
            sys.exit(1)
        
        # æ¯æ¬¡æ‰§è¡Œå‰è‡ªåŠ¨é‡ç½®çŠ¶æ€ï¼Œç¡®ä¿æ¯æ¬¡å·¥ä½œæµæ‰§è¡Œéƒ½æ˜¯ç‹¬ç«‹çš„
        # é™¤éç”¨æˆ·æ˜ç¡®æŒ‡å®š --keep-state ä¿ç•™çŠ¶æ€
        keep_state = getattr(args, 'keep_state', False)
        if not keep_state:
            engine.reset_state()
            print("ğŸ”„ å·²é‡ç½®å·¥ä½œæµçŠ¶æ€ï¼Œå¼€å§‹æ–°çš„ç‹¬ç«‹æ‰§è¡Œ\n")
        
        # è™šæ‹Ÿå›¢é˜Ÿå·¥ä½œæµï¼šé»˜è®¤æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
        # åªæœ‰åœ¨ç”¨æˆ·æ˜ç¡®æŒ‡å®šéƒ¨åˆ†é˜¶æ®µæ—¶æ‰ä½¿ç”¨æ™ºèƒ½è·¯ç”±
        stages_to_execute = None
        if hasattr(args, 'intent') and args.intent:
            user_input = args.intent.lower()
            
            # æ£€æµ‹æ˜¯å¦æ˜ç¡®æŒ‡å®šåªæ‰§è¡Œéƒ¨åˆ†é˜¶æ®µ
            explicit_partial_keywords = ["åªåš", "åªè¦", "ä»…", "only", "just", "è·³è¿‡", "ä¸è¦", "ä¸éœ€è¦"]
            is_explicit_partial = any(kw in user_input for kw in explicit_partial_keywords)
            
            # æ£€æµ‹@[team]æˆ–å®Œæ•´æµç¨‹å…³é”®è¯
            team_mention = "@[team]" in args.intent or "@team" in args.intent
            full_workflow_keywords = ["å®Œæ•´", "å…¨éƒ¨", "æ•´ä¸ª", "end-to-end", "e2e", "ä»å¤´", "å…¨æµç¨‹", "wfauto"]
            is_full_workflow = any(kw in user_input for kw in full_workflow_keywords)
            
            # å¦‚æœæ˜¯@[team]æˆ–æ˜ç¡®è¯·æ±‚å®Œæ•´æµç¨‹ï¼Œç›´æ¥æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
            if team_mention or is_full_workflow:
                stages_to_execute = None  # æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
                print("ğŸš€ è™šæ‹Ÿå›¢é˜Ÿå·¥ä½œæµï¼šæ£€æµ‹åˆ°@[team]æˆ–å®Œæ•´æµç¨‹è¯·æ±‚ï¼Œæ‰§è¡Œå®Œæ•´å·¥ä½œæµ\n")
            elif is_explicit_partial:
                # ç”¨æˆ·æ˜ç¡®æŒ‡å®šéƒ¨åˆ†é˜¶æ®µï¼Œä½¿ç”¨æ™ºèƒ½è·¯ç”±
                from work_by_roles.core.engine import IntentRouter
                
                router = IntentRouter(engine, llm_client=llm_client)
                
                # ç¡®å®šæ˜¯å¦ä½¿ç”¨LLM
                use_llm = None
                if hasattr(args, 'use_llm') and args.use_llm:
                    use_llm = True
                elif hasattr(args, 'no_llm') and args.no_llm:
                    use_llm = False
                
                intent_result = router.analyze_intent(args.intent, use_llm=use_llm)
                
                print(f"\nğŸ§  æ„å›¾è¯†åˆ«ç»“æœ ({intent_result['method']}):")
                print(f"   ç±»å‹: {intent_result['intent_type']}")
                print(f"   ç½®ä¿¡åº¦: {intent_result['confidence']:.2%}")
                print(f"   æ¨ç†: {intent_result['reasoning']}")
                print(f"   å°†æ‰§è¡Œé˜¶æ®µ: {', '.join(intent_result['stages'])}")
                
                if intent_result['confidence'] < 0.3:
                    print(f"\nâš ï¸  ç½®ä¿¡åº¦è¾ƒä½ï¼Œä½¿ç”¨å®Œæ•´æµç¨‹")
                    stages_to_execute = None  # ä½¿ç”¨å®Œæ•´æµç¨‹
                else:
                    stages_to_execute = intent_result['stages']
            else:
                # é»˜è®¤è¡Œä¸ºï¼šæ‰§è¡Œå®Œæ•´å·¥ä½œæµï¼ˆè™šæ‹Ÿå›¢é˜Ÿå·¥ä½œæµç‰¹æ€§ï¼‰
                stages_to_execute = None
                print("ğŸš€ è™šæ‹Ÿå›¢é˜Ÿå·¥ä½œæµï¼šé»˜è®¤æ‰§è¡Œå®Œæ•´å·¥ä½œæµåˆ†æéœ€æ±‚ç›®æ ‡\n")
        
        # ç¡®å®šè¦æ‰§è¡Œçš„é˜¶æ®µ
        if stages_to_execute:
            # æ™ºèƒ½è·¯ç”±æ¨¡å¼ï¼šåªæ‰§è¡ŒåŒ¹é…çš„é˜¶æ®µ
            stages = [
                s for s in engine.workflow.stages 
                if s.id in stages_to_execute
            ]
            stages = sorted(stages, key=lambda s: s.order)
            print(f"\nğŸ¯ æ™ºèƒ½è·¯ç”±æ¨¡å¼ï¼šå°†æ‰§è¡Œ {len(stages)}/{len(engine.workflow.stages)} ä¸ªé˜¶æ®µ\n")
        else:
            # å®Œæ•´æµç¨‹æ¨¡å¼ï¼šæ‰§è¡Œæ‰€æœ‰é˜¶æ®µ
            stages = sorted(engine.workflow.stages, key=lambda s: s.order)
            print("ğŸš€ wfauto: å¼€å§‹å…¨æµç¨‹æ‰§è¡Œ\n")
        
        # å°†ç”¨æˆ·æ„å›¾ä¼ é€’åˆ° engine context
        if hasattr(args, 'intent') and args.intent:
            if not engine.context:
                from work_by_roles.core.models import ProjectContext
                engine.context = ProjectContext(workspace_path=engine.workspace_path)
            if not engine.context.specs:
                engine.context.specs = {}
            engine.context.specs["global_goal"] = args.intent
            engine.context.specs["user_intent"] = args.intent
        
        # å°è¯•ä½¿ç”¨ Agent + Skills è‡ªåŠ¨æ‰§è¡Œï¼ˆå¦‚æœå¯ç”¨ï¼‰
        use_agent = _agents_available and getattr(args, 'use_agent', True) and not getattr(args, 'no_agent', False)
        use_parallel = getattr(args, 'parallel', False)
        orchestrator = None
        
        if use_agent:
            try:
                # Initialize immersive display for Cursor IDE conversations
                from work_by_roles.core.immersive_workflow_display import ImmersiveWorkflowDisplay
                immersive_display = ImmersiveWorkflowDisplay(engine.workspace_path)
                
                # Start workflow progress tracking
                immersive_display.progress_manager.start_workflow(engine.workflow.id if engine.workflow else "workflow")
                
                orchestrator = AgentOrchestrator(engine, immersive_display=immersive_display)
                mode_str = "å¹¶è¡Œ" if use_parallel else "é¡ºåº"
                print(f"ğŸ¤– ä½¿ç”¨ Agent + Skills è‡ªåŠ¨æ‰§è¡Œæ¨¡å¼ ({mode_str})\n")
            except Exception as e:
                print(f"âš ï¸  Agent ç³»ç»Ÿä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼: {e}")
                use_agent = False
        
        # å¹¶è¡Œæ‰§è¡Œæ¨¡å¼
        if use_parallel and use_agent and orchestrator:
            stage_ids = [stage.id for stage in stages]
            print(f"ğŸš€ å¹¶è¡Œæ‰§è¡Œæ¨¡å¼: {len(stage_ids)} ä¸ªé˜¶æ®µ\n")
            try:
                results = orchestrator.execute_parallel_stages_sync(
                    stage_ids=stage_ids,
                    inputs={},
                    use_llm=False
                )
                
                # å¤„ç†ç»“æœ
                for stage_id, result in results.items():
                    stage = engine.executor._get_stage_by_id(stage_id) if engine.executor else None
                    if result.get("status") == "failed":
                        print(f"âŒ é˜¶æ®µ {stage_id} æ‰§è¡Œå¤±è´¥: {result.get('error', 'Unknown error')}")
                    else:
                        print(f"âœ… é˜¶æ®µ {stage_id} æ‰§è¡Œå®Œæˆ")
                        # å®Œæˆé˜¶æ®µ
                        try:
                            comp_result = orchestrator.complete_stage(stage_id)
                            if comp_result["quality_gates_passed"]:
                                print(f"âœ… å®Œæˆé˜¶æ®µ: {stage_id}")
                            else:
                                print(f"âš ï¸  é˜¶æ®µ {stage_id} æœ‰è´¨é‡é—¨ç¦è­¦å‘Šï¼ˆå®½æ¾æ¨¡å¼ï¼Œç»§ç»­æ‰§è¡Œï¼‰")
                        except Exception as e:
                            print(f"âš ï¸  å®Œæˆé˜¶æ®µ {stage_id} æ—¶å‡ºé”™: {e}")
            except Exception as e:
                print(f"âš ï¸  å¹¶è¡Œæ‰§è¡Œå¤±è´¥ï¼Œå›é€€åˆ°é¡ºåºæ‰§è¡Œ: {e}")
                use_parallel = False
        
        # é¡ºåºæ‰§è¡Œæ¨¡å¼ï¼ˆé»˜è®¤æˆ–å¹¶è¡Œå¤±è´¥åçš„å›é€€ï¼‰
        if not use_parallel:
            for stage in stages:
                # å¦‚æœä½¿ç”¨ --keep-stateï¼Œè·³è¿‡å·²å®Œæˆé˜¶æ®µ
                if keep_state:
                    status = engine.get_stage_status(stage.id)
                    if status == StageStatus.COMPLETED:
                        print(f"âœ… è·³è¿‡å·²å®Œæˆé˜¶æ®µ: {stage.id} ({stage.name})")
                        continue

                print(f"ğŸ”„ å¯åŠ¨é˜¶æ®µ: {stage.id} ({stage.name})ï¼Œè§’è‰²: {stage.role}")
                try:
                    engine.start_stage(stage.id, stage.role)
                except Exception as e:
                    print(f"âŒ start å¤±è´¥: {e}", file=sys.stderr)
                    sys.exit(1)

                # ä½¿ç”¨ Agent + Skills è‡ªåŠ¨æ‰§è¡Œ
                if use_agent and orchestrator:
                    try:
                        # å‡†å¤‡è¾“å…¥æ•°æ®ï¼ŒåŒ…å«ç”¨æˆ·æ„å›¾
                        stage_inputs = {}
                        if hasattr(args, 'intent') and args.intent:
                            stage_inputs["user_intent"] = args.intent
                            stage_inputs["goal"] = args.intent
                        
                        # è‡ªåŠ¨æ‰§è¡Œé˜¶æ®µï¼ˆåŒ…å«æŠ€èƒ½å·¥ä½œæµï¼‰
                        stage_result = orchestrator.execute_stage_with_workflows(
                            stage_id=stage.id,
                            inputs=stage_inputs,
                            auto_execute_workflows=True
                        )
                        
                        # è¾“å‡ºé˜¶æ®µç»“è®ºåˆ°å¯¹è¯
                        conversation_summary = stage_result.get("conversation_summary")
                        if conversation_summary:
                            print("\n" + "=" * 60)
                            print(f"ğŸ“‹ {stage.name} - æ‰§è¡Œç»“è®º")
                            print("=" * 60)
                            print(conversation_summary)
                            print("=" * 60 + "\n")
                        
                        # è‡ªåŠ¨é€‰æ‹©å¹¶æ‰§è¡Œç›¸å…³æŠ€èƒ½
                        agent = stage_result.get("agent")
                        if agent and agent.context:
                            # æ ¹æ®é˜¶æ®µç›®æ ‡è‡ªåŠ¨é€‰æ‹©æŠ€èƒ½
                            goal = stage.goal_template or f"Complete {stage.name}"
                            selected_skill = orchestrator.skill_selector.select_skill(goal, agent.role)
                            
                            if selected_skill:
                                print(f"  ğŸ¯ è‡ªåŠ¨é€‰æ‹©æŠ€èƒ½: {selected_skill.name}")
                                try:
                                    skill_result = orchestrator.execute_skill(
                                        skill_id=selected_skill.id,
                                        input_data={"goal": goal, "stage": stage.id},
                                        stage_id=stage.id,
                                        role_id=stage.role
                                    )
                                    if skill_result.get("success"):
                                        print(f"  âœ… æŠ€èƒ½æ‰§è¡ŒæˆåŠŸ")
                                except Exception as e:
                                    print(f"  âš ï¸  æŠ€èƒ½æ‰§è¡Œå¤±è´¥ï¼ˆç»§ç»­ï¼‰: {e}")
                        
                        # æ£€æŸ¥å¿…éœ€è¾“å‡ºæ˜¯å¦å·²ç”Ÿæˆï¼ˆLovable å·¥ä½œæµæ¨¡å¼ï¼‰
                        import time
                        workflow_id = engine.workflow.id if engine.workflow else None
                        missing_outputs = _check_required_outputs_for_stage(stage, engine.workspace_path, workflow_id=workflow_id)
                        if missing_outputs:
                            print(f"\nâš ï¸  é˜¶æ®µ {stage.id} çš„å¿…éœ€è¾“å‡ºæœªç”Ÿæˆï¼Œç­‰å¾…ç”Ÿæˆ...")
                            for output_name, output_path in missing_outputs:
                                print(f"  - {output_name} (è·¯å¾„: {output_path.relative_to(engine.workspace_path)})")
                            
                            # ç­‰å¾…è¾“å‡ºç”Ÿæˆï¼ˆæœ€å¤šç­‰å¾…3ç§’ï¼Œæ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰
                            max_wait = 3.0
                            wait_interval = 0.5
                            waited = 0.0
                            while missing_outputs and waited < max_wait:
                                time.sleep(wait_interval)
                                waited += wait_interval
                                missing_outputs = _check_required_outputs_for_stage(stage, engine.workspace_path, workflow_id=workflow_id)
                            
                            # å¦‚æœä»ç„¶ç¼ºå¤±ï¼ŒæŠ¥é”™
                            if missing_outputs:
                                print(f"\nâŒ å¿…éœ€è¾“å‡ºç”Ÿæˆå¤±è´¥ï¼Œæ— æ³•å®Œæˆé˜¶æ®µ {stage.id}")
                                for output_name, output_path in missing_outputs:
                                    print(f"  - {output_name} (è·¯å¾„: {output_path.relative_to(engine.workspace_path)})")
                                print(f"\nğŸ’¡ æç¤º: è¯·æ£€æŸ¥æŠ€èƒ½æ‰§è¡Œæ˜¯å¦æˆåŠŸï¼Œæˆ–æ‰‹åŠ¨ç”Ÿæˆå¿…éœ€è¾“å‡º")
                                sys.exit(1)
                            else:
                                print(f"âœ… å¿…éœ€è¾“å‡ºå·²ç”Ÿæˆ")
                        
                        # å®Œæˆé˜¶æ®µï¼ˆå¿…éœ€è¾“å‡ºæ£€æŸ¥å·²é€šè¿‡ï¼‰
                        comp_result = orchestrator.complete_stage(stage.id)
                        if comp_result["quality_gates_passed"]:
                            print(f"âœ… å®Œæˆé˜¶æ®µ: {stage.id}")
                        else:
                            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…éœ€è¾“å‡ºç¼ºå¤±çš„é”™è¯¯ï¼ˆè¿™äº›æ˜¯ä¸¥æ ¼æ£€æŸ¥ï¼Œä¸èƒ½å¿½ç•¥ï¼‰
                            strict_errors = [err for err in comp_result.get("errors", []) 
                                           if "å¿…éœ€è¾“å‡º" in err or "required output" in err.lower()]
                            if strict_errors:
                                print(f"âŒ é˜¶æ®µ {stage.id} æœªé€šè¿‡å¿…éœ€è¾“å‡ºæ£€æŸ¥:", file=sys.stderr)
                                for err in strict_errors:
                                    print(f"  - {err}", file=sys.stderr)
                                sys.exit(1)
                            
                            # å®½æ¾æ¨¡å¼ï¼šè­¦å‘Šä½†ä¸é˜»å¡ï¼ˆéå¿…éœ€è¾“å‡ºçš„é”™è¯¯ï¼‰
                            print(f"âš ï¸  é˜¶æ®µ {stage.id} æœ‰è´¨é‡é—¨ç¦è­¦å‘Šï¼ˆå®½æ¾æ¨¡å¼ï¼Œç»§ç»­æ‰§è¡Œï¼‰:")
                            for err in comp_result.get("errors", []):
                                if "[å®½æ¾æ¨¡å¼]" in err:
                                    print(f"  - {err}")
                                elif "å¿…éœ€è¾“å‡º" not in err and "required output" not in err.lower():
                                    print(f"  - {err}")
                    except Exception as e:
                        print(f"âš ï¸  Agent æ‰§è¡Œå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼: {e}")
                        # å›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼
                        passed, errors = engine.complete_stage(stage.id)
                        if passed:
                            print(f"âœ… å®Œæˆé˜¶æ®µ: {stage.id}")
                        else:
                            print(f"âŒ é˜¶æ®µ {stage.id} æœªé€šè¿‡è´¨é‡é—¨ç¦:", file=sys.stderr)
                            for err in errors:
                                print(f"  - {err}", file=sys.stderr)
                            # è®°å½•é˜¶æ®µå¤±è´¥ï¼Œä½†ä¸ç«‹å³é€€å‡ºï¼Œç»§ç»­æ£€æŸ¥å…¶ä»–é˜¶æ®µ
                            failed_stages.append(stage.id)
                else:
                    # ä¼ ç»Ÿæ¨¡å¼ï¼šåªæ£€æŸ¥è´¨é‡é—¨ç¦
                    passed, errors = engine.complete_stage(stage.id)
                    if passed:
                        print(f"âœ… å®Œæˆé˜¶æ®µ: {stage.id}")
                    else:
                        print(f"âŒ é˜¶æ®µ {stage.id} æœªé€šè¿‡è´¨é‡é—¨ç¦:", file=sys.stderr)
                        for err in errors:
                            print(f"  - {err}", file=sys.stderr)
                        # è®°å½•é˜¶æ®µå¤±è´¥ï¼Œä½†ä¸ç«‹å³é€€å‡ºï¼Œç»§ç»­æ£€æŸ¥å…¶ä»–é˜¶æ®µ
                        failed_stages.append(stage.id)
        
        # Check execution results
        if engine.executor and engine.workflow:
            completed = engine.executor.get_completed_stages()
            all_stages = {s.id for s in engine.workflow.stages}
            
            if failed_stages:
                print("\n" + "=" * 60)
                print("âŒ wfauto: æ‰§è¡Œå®Œæˆï¼Œä½†æœ‰é˜¶æ®µå¤±è´¥")
                print("=" * 60)
                print(f"å¤±è´¥é˜¶æ®µ: {', '.join(failed_stages)}")
                print(f"å®Œæˆé˜¶æ®µ: {len(completed)}/{len(all_stages)}")
                sys.exit(1)
            elif completed == all_stages:
                print("\n" + "=" * 60)
                print("ğŸ‰ wfauto: æ‰€æœ‰é˜¶æ®µæ‰§è¡Œå®Œæˆ")
                print("=" * 60)
                # æŠ€èƒ½æ²‰æ·€æ˜¯å¯é€‰çš„ï¼Œä¸é˜»å¡å·¥ä½œæµå®Œæˆ
                # åªæœ‰åœ¨éè‡ªåŠ¨åŒ–æ¨¡å¼ä¸‹æ‰è¯¢é—®ï¼ˆé¿å…åœ¨ @team è§¦å‘æ—¶é˜»å¡ï¼‰
                if not use_agent:
                    workspace = Path(engine.workspace_path)
                    _prompt_skill_accumulation(engine, workspace)
                else:
                    print("\nğŸ’¡ æç¤º: å¦‚éœ€å°†æœ¬æ¬¡èƒ½åŠ›æ²‰æ·€ä¸ºæŠ€èƒ½ï¼Œå¯è¿è¡Œ 'workflow skill-accumulate'")
            else:
                print("\n" + "=" * 60)
                print("âš ï¸  wfauto: æ‰§è¡Œå®Œæˆï¼Œä½†éƒ¨åˆ†é˜¶æ®µæœªå®Œæˆ")
                print("=" * 60)
                print(f"å®Œæˆé˜¶æ®µ: {len(completed)}/{len(all_stages)}")
                pending = all_stages - completed
                if pending:
                    print(f"å¾…å®Œæˆé˜¶æ®µ: {', '.join(pending)}")
        else:
            if failed_stages:
                print("\nâŒ wfauto: æ‰§è¡Œå®Œæˆï¼Œä½†æœ‰é˜¶æ®µå¤±è´¥")
                sys.exit(1)
            else:
                print("\nâš ï¸  wfauto: æ‰§è¡Œå®Œæˆï¼ˆå·¥ä½œæµçŠ¶æ€æœªçŸ¥ï¼‰")
    except Exception as e:
        print(f"âŒ wfauto æ‰§è¡Œå¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_intent(args):
    """åˆ†æç”¨æˆ·æ„å›¾å¹¶è¿”å›éœ€è¦æ‰§è¡Œçš„é˜¶æ®µï¼ˆIDEé›†æˆï¼‰"""
    try:
        engine, _, _ = _init_engine(args)
        workspace = Path(args.workspace or ".")
        
        user_input = getattr(args, 'input', None) or getattr(args, 'intent', None)
        if not user_input:
            print("âŒ è¯·æä¾›ç”¨æˆ·è¾“å…¥", file=sys.stderr)
            print("ç”¨æ³•: workflow intent '<ç”¨æˆ·è¾“å…¥>' æˆ– workflow intent --intent '<ç”¨æˆ·è¾“å…¥>'", file=sys.stderr)
            sys.exit(1)
        
        # åŠ è½½LLMå®¢æˆ·ç«¯
        llm_client = _load_llm_client(workspace)
        
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨LLM
        use_llm = None
        if hasattr(args, 'use_llm') and args.use_llm:
            use_llm = True
            if not llm_client:
                error_msg = (
                    "âŒ LLM client not configured. Please:\n"
                    "  1. Set environment variable (e.g., OPENAI_API_KEY or ANTHROPIC_API_KEY)\n"
                    "  2. Or create .workflow/config.yaml with llm configuration\n"
                    "  3. Or remove --use-llm flag to use rule-based mode\n"
                    "\n"
                    "Example environment variables:\n"
                    "  export OPENAI_API_KEY='your-api-key'\n"
                    "  export ANTHROPIC_API_KEY='your-api-key'\n"
                    "\n"
                    "Example config file (.workflow/config.yaml):\n"
                    "  llm:\n"
                    "    provider: openai\n"
                    "    api_key: your-api-key\n"
                    "    model: gpt-4"
                )
                print(error_msg, file=sys.stderr)
                raise WorkflowError("LLM client not configured but --use-llm flag is set")
        elif hasattr(args, 'no_llm') and args.no_llm:
            use_llm = False
        
        from work_by_roles.core.engine import IntentRouter
        router = IntentRouter(engine, llm_client=llm_client)
        
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨LLM
        use_llm = None
        if hasattr(args, 'use_llm') and args.use_llm:
            use_llm = True
        elif hasattr(args, 'no_llm') and args.no_llm:
            use_llm = False
        
        # åˆ†ææ„å›¾
        result = router.analyze_intent(user_input, use_llm=use_llm)
        
        # è¾“å‡ºæ ¼å¼
        if hasattr(args, 'json') and args.json:
            import json
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print(f"\nğŸ§  æ„å›¾è¯†åˆ«ç»“æœ ({result['method']}):")
            print(f"   ç±»å‹: {result['intent_type']}")
            print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2%}")
            print(f"   æ¨ç†: {result['reasoning']}")
            print(f"   å°†æ‰§è¡Œé˜¶æ®µ: {', '.join(result['stages'])}")
            
            if result['stages']:
                if len(result['stages']) == len(engine.workflow.stages):
                    command = "workflow wfauto"
                else:
                    command = f"workflow wfauto --intent '{user_input}'"
                print(f"\nå»ºè®®å‘½ä»¤: {command}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Multi-Role Skills Workflow å‘½ä»¤è¡Œå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s start requirements product_analyst
  %(prog)s complete requirements
  %(prog)s status
  %(prog)s validate product_analyst define_requirements
  %(prog)s list-stages
  %(prog)s list-roles
        """
    )
    
    parser.add_argument("--workspace", "-w", help="å·¥ä½œç©ºé—´è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)")
    parser.add_argument("--roles", "-r", help="è§’è‰²å®šä¹‰æ–‡ä»¶ (é»˜è®¤: role_schema.yaml)")
    parser.add_argument("--workflow", "-f", help="å·¥ä½œæµå®šä¹‰æ–‡ä»¶ (é»˜è®¤: workflow_schema.yaml)")
    parser.add_argument("--skills", "-k", help="æŠ€èƒ½åº“ç›®å½• (é»˜è®¤: skills)")
    parser.add_argument("--context", "-c", help="é¡¹ç›®ä¸Šä¸‹æ–‡æ–‡ä»¶ (é»˜è®¤: .workflow/project_context.yaml)")
    parser.add_argument("--state", "-s", help="å·¥ä½œæµçŠ¶æ€æ–‡ä»¶ (é»˜è®¤: .workflow/state.yaml)")
    parser.add_argument("--team", "-t", help="æŒ‡å®šä½¿ç”¨çš„å›¢é˜Ÿï¼ˆè¦†ç›–å½“å‰å›¢é˜Ÿï¼‰")
    parser.add_argument("--no-restore-state", action="store_true", help="ç¦ç”¨è‡ªåŠ¨æ¢å¤çŠ¶æ€")
    parser.add_argument("--no-auto-save", action="store_true", help="ç¦ç”¨è‡ªåŠ¨ä¿å­˜çŠ¶æ€")
    
    subparsers = parser.add_subparsers(dest="command", help="å‘½ä»¤")
    
    # setup å‘½ä»¤ï¼ˆä¸€é”®æ¥å…¥ï¼‰
    setup_parser = subparsers.add_parser("setup", help="ä¸€é”®æ¥å…¥ï¼šè‡ªåŠ¨è®¾ç½®é¡¹ç›®ï¼Œè®©ç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨è§’è‰²ï¼ˆæ¨èæ–°é¡¹ç›®ä½¿ç”¨ï¼‰")
    setup_parser.set_defaults(func=cmd_setup)
    
    # init å‘½ä»¤
    init_parser = subparsers.add_parser("init", help="åˆå§‹åŒ–é¡¹ç›®ä¸Šä¸‹æ–‡å¹¶æ‰«æç»“æ„")
    init_parser.add_argument("--quick", "-q", action="store_true", help="å¿«é€Ÿæ¨¡å¼ï¼šä½¿ç”¨vibe-codingæ¨¡æ¿ï¼Œæœ€å°åŒ–æ–‡æ¡£è¦æ±‚")
    init_parser.add_argument("--template", "-t", help="æŒ‡å®šä½¿ç”¨çš„æ¨¡æ¿åç§°ï¼ˆå¦‚ï¼švibe-coding, standard-deliveryï¼‰")
    init_parser.set_defaults(func=cmd_init)
    
    # start å‘½ä»¤
    start_parser = subparsers.add_parser("start", help="å¯åŠ¨é˜¶æ®µï¼ˆå¯è‡ªåŠ¨æ¨æ–­ï¼‰")
    start_parser.add_argument("stage", nargs="?", help="é˜¶æ®µIDï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨æ¨æ–­ä¸‹ä¸€é˜¶æ®µï¼‰")
    start_parser.add_argument("role", nargs="?", help="è§’è‰²IDï¼ˆå¯é€‰ï¼Œä»é˜¶æ®µè‡ªåŠ¨æ¨æ–­ï¼‰")
    start_parser.add_argument("--as", dest="role_alt", help="æŒ‡å®šè§’è‰²ï¼ˆæ›¿ä»£ä½ç½®å‚æ•°ï¼‰")
    start_parser.add_argument("--status", "-s", action="store_true", help="æ˜¾ç¤ºçŠ¶æ€")
    start_parser.set_defaults(func=cmd_start)
    
    # complete å‘½ä»¤
    complete_parser = subparsers.add_parser("complete", help="å®Œæˆé˜¶æ®µ")
    complete_parser.add_argument("stage", nargs="?", help="é˜¶æ®µIDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºå½“å‰æ´»åŠ¨é˜¶æ®µï¼‰")
    complete_parser.add_argument("--status", "-s", action="store_true", help="æ˜¾ç¤ºçŠ¶æ€")
    complete_parser.set_defaults(func=cmd_complete)
    
    # status å‘½ä»¤
    status_parser = subparsers.add_parser("status", help="æ˜¾ç¤ºå·¥ä½œæµçŠ¶æ€")
    status_parser.set_defaults(func=cmd_status)
    
    # validate å‘½ä»¤
    validate_parser = subparsers.add_parser("validate", help="éªŒè¯è§’è‰²åŠ¨ä½œ")
    validate_parser.add_argument("role", help="è§’è‰²ID")
    validate_parser.add_argument("action", help="åŠ¨ä½œåç§°")
    validate_parser.set_defaults(func=cmd_validate)
    
    # generate-skill å‘½ä»¤
    generate_skill_parser = subparsers.add_parser(
        "generate-skill", help="ç”ŸæˆæŠ€èƒ½æ¨¡æ¿"
    )
    generate_skill_parser.add_argument("skill_id", help="æŠ€èƒ½IDï¼ˆå¦‚: python_devï¼‰")
    generate_skill_parser.add_argument("name", help="æŠ€èƒ½åç§°ï¼ˆå¦‚: Python Developmentï¼‰")
    generate_skill_parser.add_argument("-o", "--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    generate_skill_parser.set_defaults(func=cmd_generate_skill)

    # validate-skills å‘½ä»¤
    validate_skills_parser = subparsers.add_parser(
        "validate-skills", help="éªŒè¯æŠ€èƒ½åº“å®šä¹‰"
    )
    validate_skills_parser.add_argument("file", help="æŠ€èƒ½åº“ YAML æ–‡ä»¶è·¯å¾„")
    validate_skills_parser.add_argument("--quiet", action="store_true", help="åªè¾“å‡ºé”™è¯¯")
    validate_skills_parser.set_defaults(func=cmd_validate_skills)

    # list-skills å‘½ä»¤
    list_skills_parser = subparsers.add_parser(
        "list-skills", help="åˆ—å‡ºå·²åŠ è½½çš„æŠ€èƒ½"
    )
    list_skills_parser.set_defaults(func=cmd_list_skills)

    # interactive-skill å‘½ä»¤
    interactive_skill_parser = subparsers.add_parser(
        "interactive-skill", help="äº¤äº’å¼åˆ›å»ºæŠ€èƒ½å®šä¹‰"
    )
    interactive_skill_parser.set_defaults(func=cmd_interactive_skill)
    
    # skill-trace å‘½ä»¤
    skill_trace_parser = subparsers.add_parser(
        "skill-trace", help="æŸ¥çœ‹æŠ€èƒ½æ‰§è¡Œå†å²"
    )
    skill_trace_parser.add_argument("skill_id", help="æŠ€èƒ½ ID")
    skill_trace_parser.set_defaults(func=cmd_skill_trace)
    
    # skill-stats å‘½ä»¤
    skill_stats_parser = subparsers.add_parser(
        "skill-stats", help="æŸ¥çœ‹æ‰€æœ‰æŠ€èƒ½çš„ç»Ÿè®¡ä¿¡æ¯"
    )
    skill_stats_parser.set_defaults(func=cmd_skill_stats)
    
    # export-trace å‘½ä»¤
    export_trace_parser = subparsers.add_parser(
        "export-trace", help="å¯¼å‡ºå®Œæ•´è¿½è¸ªæ•°æ®"
    )
    export_trace_parser.add_argument("--format", "-f", choices=["json", "yaml"], default="json", help="è¾“å‡ºæ ¼å¼")
    export_trace_parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    export_trace_parser.set_defaults(func=cmd_export_trace)
    
    # benchmark-skill å‘½ä»¤
    benchmark_skill_parser = subparsers.add_parser(
        "benchmark-skill", help="åŸºå‡†æµ‹è¯•æŠ€èƒ½"
    )
    benchmark_skill_parser.add_argument("skill_id", help="æŠ€èƒ½ ID")
    benchmark_skill_parser.add_argument("--test-cases", required=True, help="æµ‹è¯•ç”¨ä¾‹ YAML æ–‡ä»¶è·¯å¾„")
    benchmark_skill_parser.add_argument("--report", action="store_true", help="ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š")
    benchmark_skill_parser.add_argument("--models", nargs="+", help="å¤šæ¨¡å‹å¯¹æ¯”ï¼ˆP2ä¼˜åŒ–ï¼‰")
    benchmark_skill_parser.set_defaults(func=cmd_benchmark_skill)
    
    # import-sop å‘½ä»¤ (P2 optimization)
    import_sop_parser = subparsers.add_parser(
        "import-sop", help="ä» SOP æ–‡æ¡£å¯¼å…¥å¹¶ç”Ÿæˆ roles/skills/workflow é…ç½®"
    )
    import_sop_parser.add_argument("sop_file", help="SOP æ–‡æ¡£è·¯å¾„ (Markdown)")
    import_sop_parser.add_argument("--output", "-o", help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: .workflow/ï¼‰")
    import_sop_parser.add_argument("--overwrite", action="store_true", help="è¦†ç›–å·²å­˜åœ¨çš„é…ç½®æ–‡ä»¶")
    import_sop_parser.set_defaults(func=cmd_import_sop)
    
    # skill-test å‘½ä»¤ (P0 optimization)
    skill_test_parser = subparsers.add_parser(
        "skill-test", help="æµ‹è¯•å•ä¸ªæŠ€èƒ½ï¼ˆæ”¯æŒ snapshot å¯¹æ¯”å’Œ schema æ ¡éªŒï¼‰"
    )
    skill_test_parser.add_argument("skill_id", help="æŠ€èƒ½ ID")
    skill_test_parser.add_argument("--input", "-i", help="è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„ (JSON/YAML)")
    skill_test_parser.add_argument("--expect", "-e", help="æœŸæœ›è¾“å‡ºæ–‡ä»¶è·¯å¾„ (JSON/YAMLï¼Œç”¨äº snapshot å¯¹æ¯”)")
    skill_test_parser.add_argument("--schema", "-s", help="æœŸæœ› Schema æ–‡ä»¶è·¯å¾„ (JSON/YAMLï¼Œç”¨äº schema æ ¡éªŒ)")
    skill_test_parser.add_argument("--snapshot", help="Snapshot æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæä¾›ï¼Œä¼šä¿å­˜/åŠ è½½ snapshotï¼‰")
    skill_test_parser.set_defaults(func=cmd_skill_test)
    
    # workflow replay å‘½ä»¤ (P1 optimization)
    replay_parser = subparsers.add_parser(
        "replay", help="ä»äº‹ä»¶æ—¥å¿—å›æ”¾å·¥ä½œæµ"
    )
    replay_parser.add_argument("event_log", help="äº‹ä»¶æ—¥å¿—æ–‡ä»¶è·¯å¾„ (JSON/YAML)")
    replay_parser.set_defaults(func=cmd_replay_workflow)
    
    # workflow dry-run å‘½ä»¤ (P1 optimization)
    dry_run_parser = subparsers.add_parser(
        "dry-run", help="å¹²è¿è¡Œé˜¶æ®µï¼ˆæ¨¡æ‹Ÿæ‰§è¡Œï¼Œä¸å®é™…è°ƒç”¨æŠ€èƒ½ï¼‰"
    )
    dry_run_parser.add_argument("stage_id", help="é˜¶æ®µ ID")
    dry_run_parser.set_defaults(func=cmd_dry_run_stage)

    # list-stages å‘½ä»¤
    list_stages_parser = subparsers.add_parser("list-stages", help="åˆ—å‡ºæ‰€æœ‰é˜¶æ®µ")
    list_stages_parser.set_defaults(func=cmd_list_stages)
    
    # list-roles å‘½ä»¤
    list_roles_parser = subparsers.add_parser("list-roles", help="åˆ—å‡ºæ‰€æœ‰è§’è‰²")
    list_roles_parser.set_defaults(func=cmd_list_roles)

    # export-graph å‘½ä»¤
    export_graph_parser = subparsers.add_parser("export-graph", help="å¯¼å‡ºå·¥ä½œæµå›¾è¡¨ (Mermaid/HTML)")
    export_graph_parser.add_argument("--format", "-f", choices=["mermaid", "html"], default="mermaid", help="è¾“å‡ºæ ¼å¼ (é»˜è®¤: mermaid)")
    export_graph_parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    export_graph_parser.add_argument("--no-roles", action="store_true", help="ä¸åŒ…å«è§’è‰²ç»§æ‰¿å›¾")
    export_graph_parser.set_defaults(func=cmd_export_graph)
    
    # check-team å‘½ä»¤
    check_team_parser = subparsers.add_parser("check-team", help="æ‰§è¡Œå›¢é˜Ÿä¸å·¥ä½œæµå¥åº·æ£€æŸ¥")
    check_team_parser.set_defaults(func=cmd_check_team)
    
    # team å‘½ä»¤ç»„
    team_parser = subparsers.add_parser("team", help="ç®¡ç†è™šæ‹Ÿå›¢é˜Ÿ")
    team_subparsers = team_parser.add_subparsers(dest="team_command", help="å›¢é˜Ÿå‘½ä»¤")
    
    # team list
    team_list_parser = team_subparsers.add_parser("list", help="åˆ—å‡ºæ‰€æœ‰å›¢é˜Ÿ")
    team_list_parser.set_defaults(func=cmd_team_list)
    
    # team switch
    team_switch_parser = team_subparsers.add_parser("switch", help="åˆ‡æ¢åˆ°æŒ‡å®šå›¢é˜Ÿ")
    team_switch_parser.add_argument("team_id", help="å›¢é˜Ÿ ID")
    team_switch_parser.set_defaults(func=cmd_team_switch)
    
    # team create
    team_create_parser = team_subparsers.add_parser("create", help="åˆ›å»ºæ–°å›¢é˜Ÿ")
    team_create_parser.add_argument("team_id", help="å›¢é˜Ÿ ID")
    team_create_parser.add_argument("--name", help="å›¢é˜Ÿåç§°")
    team_create_parser.add_argument("--description", help="å›¢é˜Ÿæè¿°")
    team_create_parser.add_argument("--template", help="ä½¿ç”¨çš„æ¨¡æ¿åç§°")
    team_create_parser.add_argument("--dir", help="å›¢é˜Ÿç›®å½•åç§°ï¼ˆé»˜è®¤: .workflow-<team_id>ï¼‰")
    team_create_parser.set_defaults(func=cmd_team_create)
    
    # team current
    team_current_parser = team_subparsers.add_parser("current", help="æ˜¾ç¤ºå½“å‰æ´»åŠ¨å›¢é˜Ÿ")
    team_current_parser.set_defaults(func=cmd_team_current)
    
    # team delete
    team_delete_parser = team_subparsers.add_parser("delete", help="åˆ é™¤å›¢é˜Ÿ")
    team_delete_parser.add_argument("team_id", help="å›¢é˜Ÿ ID")
    team_delete_parser.add_argument("--force", action="store_true", help="ä¸è¯¢é—®ç¡®è®¤")
    team_delete_parser.add_argument("--remove-files", action="store_true", help="åŒæ—¶åˆ é™¤å›¢é˜Ÿæ–‡ä»¶")
    team_delete_parser.set_defaults(func=cmd_team_delete)
    
    # team templates
    team_templates_parser = team_subparsers.add_parser("templates", help="åˆ—å‡ºå¯ç”¨çš„å›¢é˜Ÿé…ç½®æ¨¡æ¿")
    team_templates_parser.set_defaults(func=cmd_team_templates)
    
    # analyze å‘½ä»¤
    analyze_parser = subparsers.add_parser("analyze", help="åˆ†æå½“å‰é˜¶æ®µçš„å·¥ä½œæµçŠ¶æ€å’Œéœ€æ±‚")
    analyze_parser.set_defaults(func=cmd_analyze)

    # wfauto å‘½ä»¤ï¼ˆè‡ªåŠ¨ä¾æ¬¡æ‰§è¡Œæ‰€æœ‰é˜¶æ®µï¼‰
    wfauto_parser = subparsers.add_parser("wfauto", help="ä¸€é”®é¡ºåºæ‰§è¡Œæ‰€æœ‰é˜¶æ®µï¼ˆè‡ªåŠ¨ä½¿ç”¨ Agent + Skillsï¼‰")
    wfauto_parser.add_argument("--intent", "-i", help="ç”¨æˆ·æ„å›¾æè¿°ï¼ˆå¯ç”¨æ™ºèƒ½è·¯ç”±æ¨¡å¼ï¼Œè‡ªåŠ¨è¯†åˆ«éœ€è¦æ‰§è¡Œçš„é˜¶æ®µï¼‰")
    wfauto_parser.add_argument("--use-llm", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨LLMè¿›è¡Œæ„å›¾è¯†åˆ«")
    wfauto_parser.add_argument("--no-llm", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨è§„åˆ™å¼•æ“ï¼ˆèŠ‚çœtokenï¼‰")
    wfauto_parser.add_argument("--no-agent", action="store_true", help="ç¦ç”¨ Agent + Skills è‡ªåŠ¨æ‰§è¡Œï¼ˆä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼ï¼‰")
    wfauto_parser.add_argument("--keep-state", action="store_true", help="ä¿ç•™ä¹‹å‰çš„å·¥ä½œæµçŠ¶æ€ï¼ˆé»˜è®¤æ¯æ¬¡æ‰§è¡Œå‰ä¼šé‡ç½®çŠ¶æ€ï¼‰")
    wfauto_parser.add_argument("--parallel", action="store_true", help="å¹¶è¡Œæ‰§è¡Œæ— ä¾èµ–çš„é˜¶æ®µï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼‰")
    wfauto_parser.set_defaults(func=cmd_wfauto, use_agent=True)
    
    # intent å‘½ä»¤ï¼ˆIDEé›†æˆï¼‰
    intent_parser = subparsers.add_parser("intent", help="åˆ†æç”¨æˆ·æ„å›¾ï¼ˆIDEé›†æˆï¼‰")
    intent_parser.add_argument("input", nargs="?", help="ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€")
    intent_parser.add_argument("--intent", "-i", help="ç”¨æˆ·è¾“å…¥ï¼ˆæ›¿ä»£ä½ç½®å‚æ•°ï¼‰")
    intent_parser.add_argument("--json", action="store_true", help="è¾“å‡ºJSONæ ¼å¼")
    intent_parser.add_argument("--use-llm", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨LLM")
    intent_parser.add_argument("--no-llm", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨è§„åˆ™å¼•æ“")
    intent_parser.set_defaults(func=cmd_intent)
    
    # agent-execute å‘½ä»¤ï¼ˆç±»ä¼¼ MetaGPTï¼‰
    if _agents_available:
        agent_execute_parser = subparsers.add_parser("agent-execute", help="ä½¿ç”¨ Agent æ‰§è¡Œå·¥ä½œæµé˜¶æ®µï¼ˆç±»ä¼¼ MetaGPTï¼‰")
        agent_execute_parser.add_argument("stage", nargs="?", help="é˜¶æ®µIDï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨æ¨æ–­ï¼‰")
        agent_execute_parser.add_argument("--no-llm", action="store_true", help="ç¦ç”¨LLMï¼Œåªè¿›è¡Œçº¦æŸæ£€æŸ¥ï¼ˆè½»é‡æ¨¡å¼ï¼Œé»˜è®¤ï¼‰")
        agent_execute_parser.add_argument("--use-llm", action="store_true", help="å¯ç”¨LLMæ‰§è¡Œï¼ˆéœ€è¦é…ç½®llm_clientï¼‰")
        agent_execute_parser.add_argument("--collaborate", action="store_true", help="å¯ç”¨åä½œæ¨¡å¼ï¼ˆAgent é—´æ¶ˆæ¯ä¼ é€’å’Œåé¦ˆï¼‰")
        agent_execute_parser.set_defaults(func=cmd_agent_execute)
        
        # team-collaborate å‘½ä»¤ï¼ˆå¤š Agent åä½œï¼‰
        team_collab_parser = subparsers.add_parser("team-collaborate", help="å¯åŠ¨å¤š Agent åä½œæ¨¡å¼æ‰§è¡Œä»»åŠ¡")
        team_collab_parser.add_argument("goal", help="è¦å®Œæˆçš„ç›®æ ‡æè¿°")
        team_collab_parser.add_argument("--roles", nargs="+", help="æŒ‡å®šå‚ä¸çš„è§’è‰²IDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æ‰€æœ‰è§’è‰²ï¼‰")
        team_collab_parser.add_argument("--use-llm", action="store_true", help="ä½¿ç”¨LLMè¿›è¡Œä»»åŠ¡åˆ†è§£")
        team_collab_parser.set_defaults(func=cmd_team_collaborate)
        
        # decompose-task å‘½ä»¤ï¼ˆä»»åŠ¡åˆ†è§£ï¼‰
        decompose_parser = subparsers.add_parser("decompose-task", help="åˆ†è§£ç›®æ ‡ä¸ºå­ä»»åŠ¡")
        decompose_parser.add_argument("goal", help="è¦åˆ†è§£çš„ç›®æ ‡æè¿°")
        decompose_parser.add_argument("--roles", nargs="+", help="æŒ‡å®šå¯ç”¨çš„è§’è‰²IDï¼ˆå¯é€‰ï¼‰")
        decompose_parser.add_argument("--use-llm", action="store_true", help="ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†è§£")
        decompose_parser.add_argument("--json", action="store_true", help="è¾“å‡ºJSONæ ¼å¼")
        decompose_parser.set_defaults(func=cmd_decompose_task)
        
        agent_complete_parser = subparsers.add_parser("agent-complete", help="å®Œæˆ Agent æ‰§è¡Œçš„ä»»åŠ¡")
        agent_complete_parser.add_argument("stage", nargs="?", help="é˜¶æ®µIDï¼ˆå¯é€‰ï¼Œå½“å‰é˜¶æ®µï¼‰")
        agent_complete_parser.set_defaults(func=cmd_agent_complete)
    
    # add-role å‘½ä»¤
    add_role_parser = subparsers.add_parser("add-role", help="äº¤äº’å¼æ·»åŠ æ–°è§’è‰²")
    add_role_parser.add_argument("--role-id", help="è§’è‰² ID (å¯é€‰ï¼Œå¦åˆ™äº¤äº’å¼è¾“å…¥)")
    add_role_parser.add_argument("--name", help="è§’è‰²åç§° (å¯é€‰)")
    add_role_parser.add_argument("--description", help="è§’è‰²æè¿° (å¯é€‰)")
    add_role_parser.set_defaults(func=cmd_add_role)
    
    # add-stage å‘½ä»¤
    add_stage_parser = subparsers.add_parser("add-stage", help="äº¤äº’å¼æ·»åŠ æ–°é˜¶æ®µ")
    add_stage_parser.add_argument("--stage-id", help="é˜¶æ®µ ID (å¯é€‰ï¼Œå¦åˆ™äº¤äº’å¼è¾“å…¥)")
    add_stage_parser.add_argument("--name", help="é˜¶æ®µåç§° (å¯é€‰)")
    add_stage_parser.add_argument("--role", help="è§’è‰² ID (å¯é€‰)")
    add_stage_parser.set_defaults(func=cmd_add_stage)
    
    # ========================================================================
    # Migration Commands - è¿ç§»å‘½ä»¤
    # ========================================================================
    
    migrate_skills_parser = subparsers.add_parser(
        "migrate-skills",
        help="è¿ç§» skill_library.yaml åˆ° Anthropic æ ‡å‡†æ ¼å¼"
    )
    migrate_skills_parser.add_argument("yaml_file", help="skill_library.yaml æ–‡ä»¶è·¯å¾„ï¼ˆå°†è¢«è¿ç§»ï¼‰")
    migrate_skills_parser.add_argument(
        "--output", "-o",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: skillsï¼‰"
    )
    migrate_skills_parser.set_defaults(func=cmd_migrate_skills)
    
    # ========================================================================
    # Role Execute Command - ç®€åŒ–çš„è§’è‰²æ‰§è¡Œï¼ˆæ— éœ€workflowï¼‰
    # ========================================================================
    
    if _agents_available:
        role_execute_parser = subparsers.add_parser(
            "role-execute",
            help="ä½¿ç”¨æŒ‡å®šè§’è‰²å¤„ç†éœ€æ±‚ï¼ˆç®€åŒ–æ¨¡å¼ï¼Œæ— éœ€workflowï¼‰"
        )
        role_execute_parser.add_argument("role_id", help="è§’è‰²ID")
        role_execute_parser.add_argument("requirement", help="ç”¨æˆ·éœ€æ±‚æè¿°")
        role_execute_parser.add_argument(
            "--inputs", "-i",
            help="è¾“å…¥æ•°æ® (JSONæ ¼å¼)"
        )
        role_execute_parser.add_argument(
            "--use-llm",
            action="store_true",
            help="ä½¿ç”¨LLMç”Ÿæˆå“åº”ï¼ˆéœ€è¦é…ç½®llm_clientï¼‰"
        )
        role_execute_parser.set_defaults(func=cmd_role_execute)
    
    # ========================================================================
    # Skill Workflow Commands - å¤šæŠ€èƒ½å·¥ä½œæµå‘½ä»¤
    # ========================================================================
    
    # list-skill-workflows å‘½ä»¤
    list_skill_workflows_parser = subparsers.add_parser(
        "list-skill-workflows", 
        help="åˆ—å‡ºæ‰€æœ‰æŠ€èƒ½å·¥ä½œæµ"
    )
    list_skill_workflows_parser.set_defaults(func=cmd_list_skill_workflows)
    
    # skill-workflow-detail å‘½ä»¤
    skill_workflow_detail_parser = subparsers.add_parser(
        "skill-workflow-detail",
        help="æ˜¾ç¤ºæŠ€èƒ½å·¥ä½œæµè¯¦æƒ…"
    )
    skill_workflow_detail_parser.add_argument("workflow_id", help="å·¥ä½œæµ ID")
    skill_workflow_detail_parser.set_defaults(func=cmd_skill_workflow_detail)
    
    # run-skill-workflow å‘½ä»¤
    run_skill_workflow_parser = subparsers.add_parser(
        "run-skill-workflow",
        help="æ‰§è¡ŒæŠ€èƒ½å·¥ä½œæµ"
    )
    run_skill_workflow_parser.add_argument("workflow_id", help="å·¥ä½œæµ ID")
    run_skill_workflow_parser.add_argument(
        "--inputs", "-i",
        help="å·¥ä½œæµè¾“å…¥ (JSON æ ¼å¼)"
    )
    run_skill_workflow_parser.add_argument(
        "--stage", "-s",
        help="é˜¶æ®µä¸Šä¸‹æ–‡ (å¯é€‰)"
    )
    run_skill_workflow_parser.add_argument(
        "--role", "-r",
        help="è§’è‰²ä¸Šä¸‹æ–‡ (å¯é€‰)"
    )
    run_skill_workflow_parser.set_defaults(func=cmd_run_skill_workflow)
    
    # skill-workflow-graph å‘½ä»¤
    skill_workflow_graph_parser = subparsers.add_parser(
        "skill-workflow-graph",
        help="ç”ŸæˆæŠ€èƒ½å·¥ä½œæµä¾èµ–å›¾"
    )
    skill_workflow_graph_parser.add_argument("workflow_id", help="å·¥ä½œæµ ID")
    skill_workflow_graph_parser.add_argument(
        "--format", "-f",
        choices=["mermaid", "html"],
        default="mermaid",
        help="è¾“å‡ºæ ¼å¼"
    )
    skill_workflow_graph_parser.add_argument(
        "--output", "-o",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„"
    )
    skill_workflow_graph_parser.set_defaults(func=cmd_skill_workflow_graph)
    
    # Checkpoint commands
    checkpoint_parser = subparsers.add_parser('checkpoint', help='æ£€æŸ¥ç‚¹ç®¡ç†')
    checkpoint_subparsers = checkpoint_parser.add_subparsers(dest='checkpoint_command', help='æ£€æŸ¥ç‚¹å­å‘½ä»¤')
    
    checkpoint_create_parser = checkpoint_subparsers.add_parser('create', help='åˆ›å»ºæ£€æŸ¥ç‚¹')
    checkpoint_create_parser.add_argument('--name', help='æ£€æŸ¥ç‚¹åç§°')
    checkpoint_create_parser.add_argument('--description', help='æ£€æŸ¥ç‚¹æè¿°')
    checkpoint_create_parser.add_argument('--stage', help='é˜¶æ®µID')
    checkpoint_create_parser.set_defaults(func=cmd_checkpoint_create)
    
    checkpoint_list_parser = checkpoint_subparsers.add_parser('list', help='åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹')
    checkpoint_list_parser.add_argument('--workflow', help='å·¥ä½œæµIDï¼ˆå¯é€‰ï¼‰')
    checkpoint_list_parser.set_defaults(func=cmd_checkpoint_list)
    
    checkpoint_restore_parser = checkpoint_subparsers.add_parser('restore', help='ä»æ£€æŸ¥ç‚¹æ¢å¤')
    checkpoint_restore_parser.add_argument('checkpoint_id', help='æ£€æŸ¥ç‚¹ID')
    checkpoint_restore_parser.set_defaults(func=cmd_checkpoint_restore)
    
    checkpoint_delete_parser = checkpoint_subparsers.add_parser('delete', help='åˆ é™¤æ£€æŸ¥ç‚¹')
    checkpoint_delete_parser.add_argument('checkpoint_id', help='æ£€æŸ¥ç‚¹ID')
    checkpoint_delete_parser.set_defaults(func=cmd_checkpoint_delete)
    
    checkpoint_info_parser = checkpoint_subparsers.add_parser('info', help='æ˜¾ç¤ºæ£€æŸ¥ç‚¹è¯¦æƒ…')
    checkpoint_info_parser.add_argument('checkpoint_id', help='æ£€æŸ¥ç‚¹ID')
    checkpoint_info_parser.set_defaults(func=cmd_checkpoint_info)
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    # Handle team subcommands
    if args.command == "team" and hasattr(args, 'team_command') and args.team_command:
        # Team subcommand is already set via set_defaults(func=...)
        pass
    
    # Handle checkpoint subcommands
    if args.command == "checkpoint" and hasattr(args, 'checkpoint_command') and args.checkpoint_command:
        # Checkpoint subcommand is already set via set_defaults(func=...)
        pass
    
    args.func(args)


if __name__ == "__main__":
    main()

