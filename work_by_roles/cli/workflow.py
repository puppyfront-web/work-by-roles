"""
CLI commands for workflow management: start, complete, status, wfauto, role-execute, replay, dry-run
"""

import sys
import json
from pathlib import Path
from typing import Optional, Any
from .base import _init_engine
from ..core.enums import StageStatus
from ..core.agent_orchestrator import AgentOrchestrator
from ..core.exceptions import WorkflowError

def _load_llm_client(workspace: Path) -> Optional[Any]:
    """
    Load LLM client from environment variables or configuration file.
    """
    from ..core.llm_client_loader import LLMClientLoader
    loader = LLMClientLoader(workspace)
    return loader.load()

def _check_required_outputs_for_stage(stage, workspace_path, workflow_id=None):
    """Check if all required outputs exist for a stage"""
    missing = []
    if not stage.outputs:
        return missing
    
    workflow_id = workflow_id or "default"
    for output in stage.outputs:
        if not output.required:
            continue
        
        if output.type in ("document", "report"):
            output_path = workspace_path / ".workflow" / "outputs" / workflow_id / stage.id / output.name
        else:
            output_path = workspace_path / output.name
            
        if not output_path.exists():
            missing.append((output.name, output_path))
    return missing

def cmd_start(args):
    """Start a workflow stage"""
    try:
        engine, workflow_file, state_file = _init_engine(args)
        stage_id = args.stage
        role_id = getattr(args, 'role', None)
        
        if not stage_id:
            from .inspect import cmd_list_stages
            cmd_list_stages(args)
            return
            
        if not role_id:
            stage = engine.executor._get_stage_by_id(stage_id) if engine.executor else None
            if stage:
                role_id = stage.role
            else:
                print(f"âŒ é˜¶æ®µ '{stage_id}' æœªæ‰¾åˆ°", file=sys.stderr)
                sys.exit(1)
        
        engine.start_stage(stage_id, role_id)
        print(f"âœ… å·²å¯åŠ¨é˜¶æ®µ: {stage_id} (è§’è‰²: {role_id})")
        
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

def cmd_complete(args):
    """Complete a workflow stage"""
    try:
        engine, _, _ = _init_engine(args)
        stage_id = args.stage
        if not stage_id:
            current = engine.get_current_stage()
            if not current:
                print("âŒ æ²¡æœ‰æ´»åŠ¨é˜¶æ®µ", file=sys.stderr)
                sys.exit(1)
            stage_id = current.id
            
        success, errors = engine.complete_stage(stage_id)
        if success:
            print(f"âœ… é˜¶æ®µ '{stage_id}' å·²å®Œæˆ")
            if errors:
                print("\nâš ï¸  è­¦å‘Š:")
                for e in errors:
                    print(f"  - {e}")
        else:
            print(f"âŒ é˜¶æ®µ '{stage_id}' æ— æ³•å®Œæˆ:")
            for e in errors:
                print(f"  - {e}")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

def cmd_status(args):
    """Show current workflow status"""
    try:
        engine, _, _ = _init_engine(args)
        if not engine.workflow:
            print("âŒ å·¥ä½œæµæœªåŠ è½½")
            return
            
        print(f"ğŸ“‹ å·¥ä½œæµ: {engine.workflow.name}")
        current = engine.get_current_stage()
        if current:
            print(f"ğŸ”„ å½“å‰é˜¶æ®µ: {current.name} ({current.id})")
            print(f"ğŸ‘¤ å½“å‰è§’è‰²: {engine.executor.state.current_role}")
        else:
            print("â³ çŠ¶æ€: æ— æ´»åŠ¨é˜¶æ®µ")
            
        completed = engine.executor.get_completed_stages() if engine.executor else set()
        if completed:
            print(f"\nâœ… å·²å®Œæˆé˜¶æ®µ: {', '.join(completed)}")
            
    except Exception as e:
        print(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

def cmd_wfauto(args):
    """Run full workflow automatically"""
    failed_stages = []
    try:
        engine, _, _ = _init_engine(args)
        workspace = Path(args.workspace or ".")
        llm_client = _load_llm_client(workspace)
        use_llm = getattr(args, 'use_llm', False)
        
        if use_llm and not llm_client:
            raise WorkflowError("LLM client not configured but --use-llm flag is set")
        
        if not engine.workflow:
            print("âŒ æœªåŠ è½½å·¥ä½œæµ", file=sys.stderr)
            sys.exit(1)
        
        keep_state = getattr(args, 'keep_state', False)
        if not keep_state:
            engine.reset_state()
            print("ğŸ”„ å·²é‡ç½®å·¥ä½œæµçŠ¶æ€\n")
        
        stages = sorted(engine.workflow.stages, key=lambda s: s.order)
        print("ğŸš€ wfauto: å¼€å§‹å…¨æµç¨‹æ‰§è¡Œ\n")
        
        for stage in stages:
            if keep_state and engine.get_stage_status(stage.id) == StageStatus.COMPLETED:
                print(f"âœ… è·³è¿‡å·²å®Œæˆé˜¶æ®µ: {stage.id}")
                continue

            print(f"ğŸ”„ å¯åŠ¨é˜¶æ®µ: {stage.id} (è§’è‰²: {stage.role})")
            engine.start_stage(stage.id, stage.role)
            
            passed, errors = engine.complete_stage(stage.id)
            if passed:
                print(f"âœ… å®Œæˆé˜¶æ®µ: {stage.id}")
            else:
                print(f"âŒ é˜¶æ®µ {stage.id} è´¨é‡é—¨ç¦å¤±è´¥")
                failed_stages.append(stage.id)
                    
        if failed_stages:
            print(f"\nâŒ æ‰§è¡Œç»“æŸï¼Œä»¥ä¸‹é˜¶æ®µå¤±è´¥: {', '.join(failed_stages)}")
            sys.exit(1)
        else:
            print("\nâœ… æ‰€æœ‰é˜¶æ®µæ‰§è¡ŒæˆåŠŸï¼")
            
    except Exception as e:
        print(f"âŒ å…¨æµç¨‹æ‰§è¡Œå¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

def cmd_role_execute(args):
    """Execute a role directly"""
    try:
        from ..core.role_executor import RoleExecutor
        engine, _, _ = _init_engine(args)
        workspace = Path(args.workspace or ".")
        llm_client = _load_llm_client(workspace)
        
        if args.use_llm and not llm_client:
            raise RuntimeError("LLM client not configured but --use-llm flag is set")
            
        executor = RoleExecutor(engine, llm_client=llm_client)
        inputs = json.loads(args.inputs) if args.inputs else {}
        
        print(f"ğŸš€ æ‰§è¡Œè§’è‰²: {args.role_id}")
        result = executor.execute_role(args.role_id, args.requirement, inputs=inputs, use_llm=args.use_llm)
        print(f"\nâœ… æ‰§è¡Œå®Œæˆ:\n{result.get('response', '')}")
        
    except Exception as e:
        print(f"âŒ è§’è‰²æ‰§è¡Œå¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

def cmd_replay_workflow(args):
    """Replay workflow from state"""
    print("âš ï¸  å·¥ä½œæµé‡æ”¾åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")

def cmd_dry_run_stage(args):
    """Dry run a stage"""
    print(f"ğŸ§ª æ¨¡æ‹Ÿè¿è¡Œé˜¶æ®µ: {args.stage_id}")
    print("âœ… æ¨¡æ‹Ÿè¿è¡Œå®Œæˆ")
